---
output:
  html_document: default
editor_options: 
  markdown: 
    wrap: 80
---
# Modelos de Regressão Linear {#modreg}
<div style="text-align: justify">

O problema considerado neste capítulo é o de estimar os parâmetros num modelo de regressão linear normal especificado para um subconjunto das variáveis da pesquisa. O procedimento de máxima pseudoverossimilhança, descrito na Seção \@ref(secC5N4), é aplicado. Os resultados são derivados considerando pesos básicos dados pelo inverso das probabilidades de inclusão das unidades na amostra. Resultados mais gerais considerando outros tipos de pesos (tais como os derivados de estimadores de razão ou regressão, por exemplo) estão discutidos em @Silva1996, Cap. 6.

## Especificação do Modelo
<div style="text-align: justify">

Vamos supor que os dados da $i$-ésima unidade da população pesquisada incluam um vetor $\mathbf{z}_i = \left( z_{i1}, \ldots, z_{iP} \right)^{\prime}$ de dimensão $P \times 1$ com os valores de variáveis $\mathbf{z}$, que são *explicativas* ou *preditoras* num modelo de regressão $M$. Este modelo tem o objetivo de predizer ou explicar os valores de uma variável da pesquisa $y$, que é considerada como variável *resposta*. 

Denotemos por $Y_i$ e $\mathbf{Z}_i$ a variável e o vetor aleatórios que geram $y_i$ e $\mathbf{z}_i$, para $i \in U$. Sem perda de generalidade, suponhamos também que a primeira componente do vetor $\mathbf{z}_i$ de variáveis preditoras é sempre igual a $1$, de modo a incluir sempre um termo de intercepto nos modelos de regressão linear considerados (tal hipótese não é essencial, mas será adotada no restante deste capítulo). Suponhamos agora que $\left( Y_i, \mathbf{Z}_i^{\prime} \right)^{\prime}, \; i\in U$, são vetores aleatórios independentes e identicamente distribuídos - IID - tais que a densidade da distribuição condicional da resposta dadas as variáveis preditoras é dada por:

$$
f \left( \left. y_i \right| \mathbf{z}_i; \boldsymbol{\beta}, \sigma_e \right) = \left( 2 \pi \sigma_e \right)^{-1/2} \exp \left[ - \frac{1}{2} \frac{\left( y_i - \mathbf{z}_i^{\prime} \boldsymbol{\beta} \right)^2} {\sigma_e} \right] \quad (\#eq:eqC6N1)
$$

onde $\boldsymbol{\beta} = \left( \beta_1, \ldots, \beta_{P} \right)^{\prime}$ e $\sigma_e > 0$ são os parâmetros desconhecidos do modelo.

Observe que \@ref(eq:eqC6N1) constitui-se numa especificação (parcial) de um modelo marginal para um conjunto de variáveis da pesquisa, e não faz nenhuma referência direta à forma como elas se relacionam com variáveis auxiliares $\mathbf{x}$ que eventualmente possam estar disponíveis. A atenção é focalizada na estimação de $\boldsymbol{\beta}$ e $\sigma_e$ e sua interpretação com respeito ao modelo agregado \@ref(eq:eqC6N1).

Modelos como \@ref(eq:eqC6N1) já foram considerados por vários autores, por exemplo @holt1980b, @NH1980, pág. 81 de @Sk1989b, @chambers1986, @chambers1995. Eles são simples, mesmo assim frequentemente usados por analistas de dados, pelo menos como uma primeira aproximação. Além disto, eles satisfazem todas as condições padrões de regularidade. Assim eles são adequados a uma aplicação de procedimentos de máxima pseudoverossimilhança descritos na Seção \@ref(secC5N4).

As funções escores para $\boldsymbol{\beta}$ e $\sigma_e$ correspondentes ao modelo \@ref(eq:eqC6N1) podem ser facilmente obtidas como

$$
\begin{eqnarray}
\partial \log \left[ f \left( \left. y_i \right| \mathbf{z}_i; \boldsymbol{\beta}, \sigma_e \right) \right] / \partial \boldsymbol{\beta} &=& \mathbf{z}_i \left( y_i - \mathbf{z}_i^{\prime} \boldsymbol{\beta} \right) / \sigma_e \\ & \propto & \mathbf{z}_i \left( y_i - \mathbf{z}_i^{\prime } \boldsymbol{\beta } \right) = \mathbf{u}_i \left( \boldsymbol{\beta} \right)  \quad(\#eq:eqC6N2) 
\end{eqnarray}
$$

e 

$$
\begin{eqnarray}
\partial \log \left[ f \left( \left. y_i \right| \mathbf{z}_i; \boldsymbol{\beta}, \sigma_e \right) \right] / \partial \sigma_e &=& \left[ \left( y_i - \mathbf{z}_i^{\prime} \boldsymbol{\beta} \right)^{2} - \sigma_e \right] / 2 \sigma_e^2 \\ & \propto & \left( y_i - \mathbf{z}_i^{\prime} \boldsymbol{\beta} \right)^2 - \sigma_e = u_i \left( \sigma_e \right) \quad (\#eq:eqC6N3) 
\end{eqnarray}
$$

## Pseudo-parâmetros do Modelo
<div style="text-align: justify">

Se todas as unidades da população tivessem sido pesquisadas, os EMVs de $\boldsymbol{\beta}$ e $\sigma_e$ do censo, denotados por $\mathbf{B}$ e $S_e$ respectivamente, poderiam ser facilmente obtidos como soluções das equações de verossimilhança do censo dadas por 

$$
\begin{equation}
\sum \limits_{i \in U} \mathbf{u}_i \left( \mathbf{B} \right) = \sum \limits_{i \in U} \mathbf{z}_i \left( y_i - \mathbf{z}_i^{\prime} \mathbf{B} \right) = \mathbf{z}_U^{\prime} \mathbf{y}_U - \left( \mathbf{z}_U^{\prime} \mathbf{z}_U \right) \mathbf{B} = \mathbf{0} \quad (\#eq:eqC6N4)
\end{equation}
$$
e 

$$
\begin{equation}
\sum \limits_{i \in U} u_i \left( S_e \right) = \sum \limits_{i \in U} \left[ \left( y_i - \mathbf{z}_i^{\prime} \mathbf{B} \right)^2 - S_e \right] = \left( \mathbf{y}_U - \mathbf{z}_U^{\prime} \mathbf{B} \right)^{\prime} \left( \mathbf{y}_U - \mathbf{z}_U^{\prime} \mathbf{B} \right) - N S_e = 0 \quad (\#eq:eqC6N5)
\end{equation}
$$

onde $\mathbf{z}_U = \left( \mathbf{z}_1, \ldots, \mathbf{z}_N \right)^{\prime}$ e $\mathbf{y}_U = \left( y_1, \ldots, y_N \right)^{\prime}$.

Se $\mathbf{z}_U^{\prime} \mathbf{z}_U$ for não-singular, as soluções para estas equações são facilmente obtidas como 

$$
\begin{equation}
 \mathbf{B} = \left( \mathbf{z}_U^{\prime} \mathbf{z}_U \right)^{-1} \mathbf{z}_U^{\prime} \mathbf{y}_U \quad (\#eq:eqC6N6)
\end{equation}
$$
e 

$$
\begin{equation}
S_e = N^{-1} \sum \limits_{i \in U} \left( y_i - \mathbf{z}_i^{\prime} \mathbf{B} \right)^{2} = N^{-1} \left( \mathbf{y}_U - \mathbf{z}_U^{\prime} \mathbf{B} \right)^{\prime} \left( \mathbf{y}_U - \mathbf{z}_U^{\prime} \mathbf{B} \right) \quad (\#eq:eqC6N7)
\end{equation}
$$

Com uma parametrização que isole o termo correspondente ao intercepto (primeira coluna do vetor $\mathbf{z}_i$) do modelo de regressão \@ref(eq:eqC6N1), pode ser facilmente mostrado, @Silva1996, p. 142, que os EMV de $\boldsymbol{\beta}_{2}$ (igual a $\boldsymbol{\beta}$ excluído o primeiro componente), $\beta_1$ e $\sigma_e$ são dados respectivamente por:

$$
\begin{equation}
\mathbf{B}_2 = \mathbf{S}_{\mathbf{z}}^{-1} \mathbf{S}_{\mathbf{z}y} \quad (\#eq:eqC6N8)
\end{equation}
$$

$$
\begin{equation}
B_1 = \bar{Y} - \mathbf{\bar{Z}}^{\prime} \mathbf{B}_2 \quad (\#eq:eqC6N9)
\end{equation}
$$
e 

$$
\begin{equation}
S_e = N^{-1 }\sum \limits_{i \in U} \left( y_i - B_1 - \mathbf{z}_i^{\prime} \mathbf{B}_2 \right)^2 = N^{-1} \sum \limits_{i \in U} e_i^2 \quad (\#eq:eqC6N10)
\end{equation}
$$

onde $\bar{Y} = N^{-1} \sum \limits_{i \in U} y_i$, $\mathbf{\bar{Z}} = N^{-1} \sum \limits_{i \in U} \mathbf{z}_i$, $\mathbf{S}_{\mathbf{z}} = N^{-1} \sum \limits_{i \in U} \left( \mathbf{z}_i - \mathbf{\bar{Z}} \right) \left( \mathbf{z}_i - \mathbf{\bar{Z}} \right)^{\prime}$, $\mathbf{S}_{\mathbf{z}y} = N^{-1} \sum \limits_{i \in U} \left( \mathbf{z}_i - \mathbf{\bar{Z}} \right) \left( y_i - \bar{Y} \right)$ e $e_i = y_i - B_1 - \mathbf{z}_i^{\prime} \mathbf{B}_2 = \left( y_i - \bar{Y} \right) - \left( \mathbf{z}_i - \mathbf{\bar{Z}} \right)^{\prime} \mathbf{B}_2$, sendo neste trecho os vetores de variáveis preditoras $\mathbf{z}$ tomados sem o termo constante referente ao intercepto.

Os EMVs do censo dados em \@ref(eq:eqC6N1) a \@ref(eq:eqC6N10) coincidem com os estimadores de mínimos quadrados ordinários, sob as hipóteses mais fracas do modelo de superpopulação dadas por \@ref(eq:eqC6N11) a seguir (ver Nathan e Holt, 1980), onde se dispensou a hipótese de normalidade dos erros, isto é 

$$
\begin{eqnarray}
E_M \left( \left. Y_i \right| \mathbf{Z}_i = \mathbf{z}_i \right) &=& \beta_1 + \mathbf{z}_i^{\prime} \boldsymbol{\beta}_2 \quad (\#eq:eqC6N11) \\ V_M \left( \left. Y_i \right| \mathbf{Z}_i = \mathbf{z}_i \right) &=& \sigma_e \nonumber \\ COV_M \left( \left. Y_i, Y_j \right| \mathbf{Z}_i = \mathbf{z}_i, \mathbf{Z}_j = \mathbf{z}_j \right) &=& 0\ \quad \forall i \neq j \in U \nonumber
\end{eqnarray}
$$

XXX PAREI AQUI

### Estimadores de MPV dos Parâmetros do Modelo
<div style="text-align: justify">

Quando apenas uma amostra de unidades da população é observada,
são usados pesos $w_i$ para obter estimadores de máxima
pseudo-verossimilhança de $\boldsymbol{\beta}$ e $\sigma_e$, ou
alternativamente de $\mathbf{B}$ e $S_e$, se as quantidades descritivas
populacionais correspondentes forem escolhidas para alvo da inferência.
Se os pesos $w_i$ satisfizerem às condições de regularidade
discutidas na Seção \@ref(modpar3), será imediato obter as equações de pseudo-verossimilhança correspondentes ao modelo \@ref(eq:eqC6N1) como 
\begin{eqnarray}
\sum\limits_{i\in s}w_i\mathbf{u}_i\left( \mathbf{\hat{B}}_{w}\right)
&=&\sum\limits_{i\in s}w_i\mathbf{z}_i\left( y_i-\mathbf{z}
_i^{\prime }\mathbf{\hat{B}}_{w}\right)  (\#eq:eqC6N12) \\
&=&\mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{y}_{s}-\left( \mathbf{z}
_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{y}_{s}\right) \mathbf{\hat{B}}_{w}=
\mathbf{0}  \nonumber
\end{eqnarray}
e 
\begin{eqnarray}
\sum\limits_{i\in s}w_iu_i\left( s_e^{w}\right) &=&\sum\limits_{i\in
s}w_i\left[ \left( y_i-\mathbf{z}_i^{\prime }\mathbf{\hat{B}}
_{w}\right) ^{2}-s_e^{w}\right]  (\#eq:eqC6N13) \\
&=&\left( \mathbf{y}_{s}-\mathbf{z}_{s}\mathbf{\hat{B}}_{w}\right)
^{^{\prime }}\mathbf{W}_{s}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\mathbf{\hat{B
}}_{w}\right) -\left( \mathbf{1}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{1}
_{s}\right) s_e^{w}=0  \nonumber
\end{eqnarray}
onde $\mathbf{z}_{s}$ e $\mathbf{y}_{s}$ são os análogos amostrais
de $\mathbf{z}_U$ e $\mathbf{y}_U$, respectivamente, 
$\mathbf{W}_{s}=diag\left[ \left( w_{i_{1}},\ldots ,w_{i_{n}}\right) \right]$ é
uma matriz diagonal $n\times n$ com os pesos dos elementos da amostra na
diagonal principal, e $\mathbf{\hat{B}}_{w}$ e $s_e^{w}$ são
estimadores MPV de $\boldsymbol{\beta}$ e $\sigma_e$ respectivamente.

Supondo que $\mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{z}_{s}$ é
não-singular e resolvendo \@ref(eq:eqC6N12) e \@ref(eq:eqC6N13) em $\mathbf{\hat{B}
}_{w}$ e $s_e^{w}$ obtemos as seguintes expressões para os estimadores
MPV dos parâmetros do modelo: 
\begin{equation}
\widehat{\mathbf{B}}_{w}=\left( \mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}
\mathbf{z}_{s}\right) ^{-1}\mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{y
}_{s}  (\#eq:eqC6N14)
\end{equation}
e 

\begin{eqnarray}
s_e^{w} &=&\left( \mathbf{1}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{1}
_{s}\right) ^{-1}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\widehat{\mathbf{B}}
_{w}\right) ^{^{\prime }}\mathbf{W}_{s}\left( \mathbf{y}_{s}-\mathbf{z}_{s}
\widehat{\mathbf{B}}_{w}\right)  (\#eq:eqC6N15) \\
&=&\left( \mathbf{1}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{1}_{s}\right)
^{-1}\mathbf{y}_{s}^{^{\prime }}\left[ \mathbf{W}_{s}-\mathbf{W}_{s}\mathbf{z
}_{s}\left( \mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{z}_{s}\right)
^{-1}\mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\right] \mathbf{y}_{s} 
\nonumber
\end{eqnarray}
sendo a segunda expressão para $s_e^{w}$ obtida mediante substituição do valor de $\widehat{\mathbf{B}}_{w}$ em \@ref(eq:eqC6N14) na primeira
linha de \@ref(eq:eqC6N15).

Observe que a hipótese de não-singularidade de $\mathbf{z}
_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{z}_{s}$ não seria satisfeita se 
$w_i=0$ para algum $i\in s$. Para evitar que se percam de vista as
questões principais com relação à estimação dos
parâmetros do modelo, admitiremos de agora em diante que $\mathbf{z}
_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{z}_{s}$ é não-singular.

Estimadores pontuais dos parâmetros do modelo podem ser derivados a
partir de \@ref(eq:eqC6N14) e \@ref(eq:eqC6N15) para vários esquemas de pondera\c{c
}ão de interesse pela simples substituição da matriz apropriada
de ponderação $\mathbf{W}_{s}$. Se todos os elementos da pesquisa
têm o mesmo peso (como no caso de planos amostrais autoponderados), ou
seja, $w_i=\bar{w}$ e $\mathbf{W}_{s}=\bar{w}\mathbfi_{n}$, os
estimadores pontuais não dependem do valor $\bar{w}$ dos pesos. Neste
caso, eles ficam reduzidos às expressões correspondentes dos
estimadores de mínimos quadrados ordinários (que são também
estimadores de máxima verossimilhança sob normalidade) dos
parâmetros do modelo, dados por: 
\begin{equation}
\widehat{\mathbf{B}}=\left( \mathbf{z}_{s}^{^{\prime }}\mathbf{z}_{s}\right)
^{-1}\mathbf{z}_{s}^{^{\prime }}\mathbf{y}_{s}  (\#eq:eqC6N16)
\end{equation}
e

\begin{equation}
s_e=n^{-1}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\widehat{\mathbf{B}}\right)
^{^{\prime }}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\widehat{\mathbf{B}}\right)
\;.  (\#eq:eqC6N17)
\end{equation}

Substituindo $\mathbf{W}_{s}$ em \@ref(eq:eqC6N14) e \@ref(eq:eqC6N15) por $diag\left(
\pi _i:i\in s\right) =\mathbf{\Pi }_{s}^{-1}$, onde os $\pi _i$ em geral
não são todos iguais, obtemos estimadores, chamados de mínimos
quadrados $\pi -$ponderados, dados por: 
\begin{equation}
\widehat{\mathbf{B}}_{\pi }=\left( \mathbf{z}_{s}^{^{\prime }}\mathbf{\Pi }
_{s}^{-1}\mathbf{z}_{s}\right) ^{-1}\mathbf{z}_{s}^{^{\prime }}\mathbf{\Pi }
_{s}^{-1}\mathbf{y}_{s}  (\#eq:eqC6N18)
\end{equation}
e

\begin{equation}
s_e^{\pi }=\left( \mathbf{1}_{s}^{^{\prime }}\mathbf{\Pi }_{s}^{-1}\mathbf{
1}_{s}\right) ^{-1}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\widehat{\mathbf{B}}
_{\pi }\right) ^{^{\prime }}\mathbf{\Pi }_{s}^{-1}\left( \mathbf{y}_{s}-
\mathbf{z}_{s}\widehat{\mathbf{B}}_{\pi }\right) \;.  (\#eq:eqC6N19)
\end{equation}

### Estimação da Variância de Estimadores de MPV
<div style="text-align: justify">
O exercício de ajustar um modelo não estará completo sem a 
avaliação da precisão e significância das estimativas dos
parâmetros. Para isto é necessária a estimação das
variâncias correspondentes. Nesta seção concentramos nossa atenção na estimação das variâncias dos estimadores de MPV
dos coeficientes de regressão $\mathbf{\beta}$. As expressões a
seguir são obtidas por aplicação direta dos resultados gerais
fornecidos na Seção \@ref(modpar3), observando-se que os escores
correspondentes a $\mathbf{\beta}$ no *ajuste do censo* do modelo \@ref(eq:eqC6N1) são dados por 
$\mathbf{u}_i\left( \mathbf{B}\right) =\mathbf{z}_i\left( y_i-\mathbf{z}_i^{\prime }\mathbf{B}\right) =\mathbf{z}
_ie_i$ , 
onde $e_i=\left( y_i-\bar{Y}\right) -\left( \mathbf{z}_i-\mathbf{\bar{Z}}\right) ^{^{\prime }}\mathbf{B}$ para $i\in U$, com o
Jacobiano correspondente dado por

\begin{eqnarray}
J\left( \mathbf{B}\right) &=&\left. \sum\nolimits_{i\in U}\partial \mathbf{z}
_i\left( y_i-\mathbf{z}_i^{\prime }\boldsymbol{\beta}\right) /\partial 
\boldsymbol{\beta}\right| _{\boldsymbol{\beta}=\mathbf{B}}  (\#eq:eqC6N20) \\
&=&\left. \partial \left( \mathbf{z}_U^{\prime }\mathbf{y}_U-\mathbf{z}
_U^{\prime }\mathbf{z}_U\boldsymbol{\beta}\right) /\partial \boldsymbol{\beta}
\right| _{\boldsymbol{\beta}=\mathbf{B}}=-\mathbf{z}_U^{\prime }\mathbf{z}
_U\;\;.  \nonumber
\end{eqnarray}

Substituindo em \@ref(eq:eqC6N8) e \@ref(eq:eqC6N9)  os valores dos escores, do
jacobiano e dos estimadores $\pi$-ponderados correspondentes, obtemos as
seguintes expressões para a variância assintótica de aleatorização do estimador de MPV padrão $\widehat{\mathbf{B}}_{\pi}$ e
seu estimador consistente, dadas por

\begin{equation}
V_{p}\left( \widehat{\mathbf{B}}_{\pi }\right) =\left( \mathbf{z}
_U^{\prime }\mathbf{z}_U\right) ^{-1}V_{p}\left( \sum\limits_{i\in s}\pi
_i^{-1}\mathbf{z}_ie_i\right) \left( \mathbf{z}_U^{\prime }\mathbf{z}
_U\right) ^{-1}  (\#eq:eqC6N21)
\end{equation}
e 

\begin{equation}
\hat{V}_{p}\left( \widehat{\mathbf{B}}_{\pi }\right) =\left( \mathbf{z}
_{s}^{\prime }\mathbf{\Pi }_{s}^{-1}\mathbf{z}_{s}\right) ^{-1}\hat{V}
_{p}\left( \sum\limits_{i\in s}\pi _i^{-1}\mathbf{z}_ie_i\right)
\left( \mathbf{z}_{s}^{\prime }\mathbf{\Pi }_{s}^{-1}\mathbf{z}_{s}\right)
^{-1}\;,  (\#eq:eqC6N22)
\end{equation}
onde

\begin{equation}
V_{p}\left( \sum\limits_{i\in s}\pi _i^{-1}\mathbf{z}_ie_i\right)
=\sum\limits_{i\in U}\sum\limits_{j\in U}\frac{\pi _{ij}-\pi _i\pi _{j}}{
\pi _i\pi _{j}}e_i\mathbf{z}_i\mathbf{z}_{j}^{\prime }e_{j}\;\;,
(\#eq:eqC6N23)
\end{equation}

\begin{equation}
\hat{V}_{p}\left( \sum\limits_{i\in s}\pi _i^{-1}\mathbf{z}_i\hate
_i\right) =\sum\limits_{i\in s}\sum\limits_{j\in s}\left( \pi _i^{-1}\pi
_{j}^{-1}-\pi _{ij}^{-1}\right) \hate_i\mathbf{z}_i\mathbf{z}
_{j}^{\prime }\hate_{j}\;\;,  (\#eq:eqC6N24)
\end{equation}
e $\hate_i=y_i-\mathbf{z}_i^{\prime }\widehat{\mathbf{B}}_{\pi }$
para $i\in s$.

Isto completa a especificação de um procedimento de máxima
pseudo-verossimilhança para ajustar modelos normais de regressão
como \@ref(eq:eqC6N1). Este procedimento é bastante flexível e
aplicável numa ampla gama de planos amostrais.




## Teste de Hipóteses
<div style="text-align: justify">
Nas Seções \@ref(modlinear) e \@ref(modlogist) discutimos formas de introduzir pesos e plano
amostral em procedimentos de estimação pontual e de variâncias
ao ajustar modelos com dados de pesquisas amostrais complexas. Neste
contexto, procedimentos estatísticos de teste de hipóteses devem,
também, sofrer adaptações. Nesta seção, esse problema
será abordado de forma sucinta, para modelos de regressão.

De modo geral, testes de hipóteses em regressão surgem inicialmente
na seleção de modelos e também para fornecer evidência
favorável ou contrária a indagações levantadas pelo
pesquisador.

Denotemos por $\boldsymbol{\beta}=\left( \beta _{1},\ldots ,\beta _{P}\right)
^{\prime }$ o vetor de parâmetros num modelo de regressão. Como
é sabido, para testar a hipótese $H_{0}:\beta _{j}=0$, para algum 
$j\in \left\{ 1,\ldots ,P\right\} \mathbf{,}$ usamos um teste $t,$ e para
para testar a hipótese $H_{0}:\left( \beta _{j_{1}},\ldots ,\beta
_{j_{R}}\right) ^{\prime }=\mathbf{0}_{R}$, onde $\left( j_{1},\ldots
,j_{R}\right) \subset \left( 1,\ldots ,P\right)$ e $\mathbf{0}_{R}$ é o
vetor zero $R$-dimensional, usamos um teste $\mathbf{F}$. Tais testes $t$ e 
$\mathbf{F}$, sob as hipóteses do modelo clássico de regressão
com erros normais, são testes da Razão de Máxima Verossimilhança.

é pois natural tentar adaptar testes de Razão de Máxima
Verossimilhança para pesquisas amostrais complexas, tal como
foi feito na derivação de estimadores de MPV a partir de estimadores
de Máxima Verossimilhança. A principal dificuldade é que no
contexto de pesquisas complexas, devido aos pesos distintos das observações e ao plano amostral utilizado, a função de verossimilhança usual não representa a distribuição conjunta das observações. Apesar desta dificuldade ter sido contornada na derivação
de estimadores de MPV, a adaptação fica bem mais difícil no caso
de testes da Razão de Máxima Verossimilhança.

Por essa causa, é mais fácil basear os testes na estatística
Wald, que mede a distância entre uma estimativa pontual e o valor
hipotético do parâmetro numa métrica definida pela matriz de
covariância do estimador. Pesos e plano amostral podem ser incorporados
facilmente nessa estatística, bastando para isto utilizar estimativas
apropriadas (consistentes sob aleatorização) dos parâmetros e da
matriz de covariância, tais como as que são geradas pelo método
de MPV. é essa abordagem que vamos adotar aqui.

Considere o problema de testar a hipótese linear geral 
\begin{equation}
H_{0}:\mathbf{C\beta }=\mathbf{c},  (\#eq:eqC6N30)
\end{equation}
onde $\mathbf{C}$ é uma matriz de dimensão $R\times P$ de posto
pleno $R=P-Q$ e $\mathbf{c}$ é um vetor $R$ $\times 1.$

Um caso particular de interesse é testar a hipótese aninhada 
$H_{0}:\boldsymbol{\beta}_{2}=\mathbf{0}_{R}\mathbf{,}$ onde 
$\boldsymbol{\beta}^{\prime}=\left( \boldsymbol{\beta}_{1}^{\prime },\boldsymbol{\beta}_{2}^{\prime }\right)$
, com $\boldsymbol{\beta}_{1}$ de dimensão  $Q\times 1$ e $\mathbf{\beta}_{2}$ de dimensão $R\times 1$, 

$\mathbf{C}= \left[\begin{array}{lll}\mathbf{0}_{R\times Q} &  & \mathbfi_{R}\end{array}\right]$ e 
$c=\mathbf{0}_{R}$ , sendo $\mathbf{0}_{R\times Q}$ matriz de
zeros de dimensão $R\times Q$ e $\mathbfi_{R}$ a matriz identidade de
ordem $R$.

A estatística de Wald clássica para testar a hipótese nula \@ref(eq:eqC6N30) é definida por

\begin{equation}
X_{W}^{2}=\left( \mathbf{C}\widehat{\boldsymbol{\beta}}-\mathbf{c}\right)
^{\prime }\left( \mathbf{C}\widehat{\mathbf{V}}\left( \mathbf{\hat{\beta}}
\right) \mathbf{C}^{\prime }\right) ^{-1}\left( \mathbf{C}\widehat{\mathbf{
\beta }}\mathbf{-c}\right),  (\#eq:eqC6N31)
\end{equation}
onde os estimadores $\widehat{\boldsymbol{\beta}}$ e 
$\widehat{\mathbf{V}}\left( \mathbf{\hat{\beta}}\right)$ são obtidos pela teoria de
mínimos quadrados ordinários. Sob $H_{0}$, a distribuição
assintótica da estatística $X_{W}^{2}$ é $\chi ^{2}\left(R\right)$.

Quando os dados são obtidos através de pesquisas amostrais
complexas, a estatística $X_{W}^{2}$ deixa de ter distribuição
assintótica $\chi ^{2}\left( R\right)$, e usar esta última como
distribuição de referência implica na obtenção de testes
com níveis de significância incorretos. Esse problema é
solucionado substituindo-se na expressão de 
$X_{W}^{2}$, $\mathbf{\hat{\beta}}$ pela estimativa MPV 
$\widehat{\mathbf{B}}_{\pi }$ de $\mathbf{\beta}$ dada em \@ref(eq:eqC6N18), e $\widehat{\mathbf{V}}\left( \mathbf{\hat{\beta}}\right)$pela estimativa da matriz de covariância do estimador de MPV $\hat{V}_{p}\left( \widehat{\mathbf{B}}_{\pi }\right)$ dada em \@ref(eq:eqC6N22).
Tais estimativas consideram os pesos diferentes das observações e o
plano amostral efetivamente utilizado. A normalidade assintótica do
estimador de MPV de $\mathbf{\beta}$ e a consistência do estimador da
matriz de covariância correspondente (Binder, 1983) implicam que 
\[
X_{W}^{2}\sim \chi^{2}\left( R\right)\mbox{, sob }H_{0}.
\]

Esta aproximação não leva em conta o erro amostral na estimação de $\mathbf{V}\left( \mathbf{\hat{\beta}}\right) .$ Uma alternativa
é usar a aproximação 
\[
X_{W}^{2}/R\sim \mathbf{F}(R,\upsilon),
\]
onde $\upsilon =$ $m-H$ é o número de UPAs da amostra menos o
número de estratos considerados no plano amostral para seleção
das UPAs, que fornece uma medida de graus de liberdade apropriada para
amostras complexas quando o método do conglomerado primário é
empregado para estimar variâncias.

Com a finalidade de melhorar a aproximação da distribuição
da estatística de teste, podem ser utilizados ajustes e correções da estatística $X_{W}^{2}$, que são apresentados com mais
detalhes nos Capítulos \@ref(testqualajust) e \@ref(testetab2) para o caso da análise de dados
categóricos.

A especificação de um procedimento para testar hipóteses sobre
os parâmetros de um modelo de regressão completa a abordagem para
ajuste de modelos desse tipo partindo de dados amostrais complexos.
Entretanto, uma das partes importantes da teoria clássica para modelagem
é a que trata do diagnóstico dos modelos ajustados, muitas vezes
empregando recursos gráficos. Nessa parte a abordagem baseada em MPV e
em estatísticas de Wald deixa a desejar, pois não é possível
adaptar de maneira simples as técnicas clássicas de diagnóstico.
Por exemplo, é difícil considerar pesos ao plotar os resíduos do
ajuste dum modelo via MPV. Essa é questão que ainda merece maior
investigação e por enquanto é uma desvantagem da abordagem aqui
preconizada.

## Laboratório de R
<div style="text-align: justify">
Usar exemplo da amolim ou conseguir exemplo melhor?
Reproduzir usando a survey os resultados do Exemplo 6.1???


```{r}
library(survey)
library(anamco)
names(pnadrj90)
```
Preparação dos dados: Variáveis explicativas são fatores.
Ver tipo de variável:
```{r}
unlist(lapply(pnadrj90, mode))
```
Transformar variáveis para fatores e mudar o nível básico do fator (último)
```{r}
pnadrj90$sx<-as.factor(pnadrj90$sx)
pnadrj90$sx<-relevel(pnadrj90$sx,ref="2")
pnadrj90$id<-as.factor(pnadrj90$id)
pnadrj90$id<-relevel(pnadrj90$id,ref="4")
pnadrj90$ae<-as.factor(pnadrj90$ae)
pnadrj90$ae<-relevel(pnadrj90$ae,ref="3")
pnadrj90$ht<-as.factor(pnadrj90$ht)
pnadrj90$ht<-relevel(pnadrj90$ht,ref="3")
pnadrj90$re<-as.factor(pnadrj90$re)
pnadrj90$re<-relevel(pnadrj90$re,ref="3")
##transformar variável de resposta para 0,1:
pnadrj90$informal<-ifelse(pnadrj90$informal==1,1,0)
```

Cria objeto de desenho

```{r}
pnad.des<-svydesign(id=~psu,strata=~stra,weights=~pesopes,data=pnadrj90,nest=TRUE)
```

Ajusta modelo de regressão logística na Tabela \@ref(tab:logit)
Comparar resultado com o da página 106 de Pessoa e Silva (1998)

```{r, message=FALSE, warning=FALSE}
inf.logit<-svyglm(informal~sx+ae+ht+id+re+sx*id+sx*ht+ae*ht+ht*id+ht*re,
  design=pnad.des, family=quasibinomial())
```


```{r, results='asis'}
knitr::kable(summary(inf.logit)$coefficients,booktabs=TRUE, digits= c(3,3,3,2))
```



Teste de Wald para a hipótese $H_0: ht:re=0$

```{r}
regTermTest(inf.logit,"ht:re")
```











