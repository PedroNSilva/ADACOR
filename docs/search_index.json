[["index.html", "Análise de Dados Amostrais com R Bem-vindo Agradecimentos", " Análise de Dados Amostrais com R Djalma Galvão Carneiro Pessoa e Pedro Luis do Nascimento Silva Editores Pedro Luis do N. Silva, Antonio José R. Dias, Zélia M. Bianchini e Sonia Albieri 23 de fevereiro de 2022, 15:42:10 Bem-vindo Uma preocupação básica de toda instituição produtora de informações estatísticas é com a utilização correta de seus dados. Isso pode ser interpretado de várias formas, algumas delas com reflexos até na confiança do público e na própria sobrevivência do órgão. Do nosso ponto de vista, enfatizamos um aspecto técnico particular, mas nem por isso menos importante para os usuários dos dados. A revolução da informática, com a resultante facilidade de acesso ao computador, criou condições extremamente favoráveis à utilização de dados estatísticos produzidos por órgãos como o IBGE. Algumas vezes esses dados são utilizados para fins puramente descritivos. Outras vezes, porém, sua utilização é feita para fins analíticos, envolvendo a construção de modelos, quando o objetivo é extrair conclusões aplicáveis também a populações distintas daquela da qual se extraiu a amostra. Neste caso, é comum empregar, sem grandes preocupações, pacotes computacionais padrões disponíveis para a seleção e ajuste de modelos. É neste ponto que entra a nossa preocupação com o uso adequado dos dados produzidos pelo IBGE. O que torna tais dados especiais para quem pretende usá-los para fins analíticos? Esta é a questão básica que é amplamente discutida ao longo deste texto. A mensagem principal que pretendemos transmitir é que certos cuidados precisam ser tomados para utilização correta dos dados de pesquisas amostrais como as que o IBGE realiza. O que torna especiais dados como os produzidos pelo IBGE é que estes são obtidos através de pesquisas amostrais complexas de populações finitas que envolvem: probabilidades distintas de seleção, estratificação e conglomeração das unidades, ajustes para compensar não resposta e outros ajustes. Os sistemas tradicionais de análise ignoram estes aspectos, podendo produzir estimativas incorretas tanto dos parâmetros como para as variâncias destas estimativas. Quando utilizamos a amostra para estudos analíticos, as opções disponíveis nos pacotes estatísticos usuais para levar em conta os pesos distintos das observações são apropriadas somente para observações independentes e identicamente distribuídas - IID. Além disso, a variabilidade dos pesos produz impactos tanto na estimação pontual quanto na estimação das variâncias dessas estimativas, que sofre ainda influência da estratificação e conglomeração. O objetivo deste livro é analisar o impacto das simplificações feitas ao utilizar procedimentos e pacotes usuais de análise de dados e apresentar os ajustes necessários desses procedimentos de modo a incorporar na análise, de forma apropriada, os aspectos aqui ressaltados. Para isto são apresentados exemplos de análises de dados obtidos em pesquisas amostrais complexas, usando pacotes clássicos e também pacotes estatísticos especializados. A comparação dos resultados das análises feitas das duas formas permite avaliar o impacto de ignorar o plano amostral na análise dos dados resultantes de pesquisas amostrais complexas. Agradecimentos A elaboração de um texto como esse não se faz sem a colaboração de muitas pessoas. Em primeiro lugar, agradecemos à Comissão Organizadora do SINAPE por ter propiciado a oportunidade ao selecionar nossa proposta de minicurso. Agradecemos também ao IBGE por ter proporcionado as condições e os meios usados para a produção da monografia, bem como o acesso aos dados detalhados e identificados que utilizamos em vários exemplos. No plano pessoal, agradecemos a Zélia Bianchini pela revisão do manuscrito e sugestões que o aprimoraram. Agradecemos a Marcos Paulo de Freitas e Renata Duarte pela ajuda com a computação de vários exemplos. Agradecemos a Waldecir Bianchini, Luiz Pessoa e Marinho Persiano pela colaboração na utilização do processador de textos. Aos demais colegas do Departamento de Metodologia do IBGE, agradecemos o companheirismo e solidariedade nesses meses de trabalho na preparação do manuscrito. Finalmente, agradecemos a nossas famílias pela aceitação resignada de nossas ausências e pelo incentivo à conclusão da empreitada. "],["lista-de-figuras.html", "Lista de Figuras", " Lista de Figuras Figura Descrição Figura 2.1 Representação esquemática da Modelagem Clássica Figura 2.2 Representação esquemática da Amostragem Probabilística Figura 2.3 Representação esquemática da Modelagem de Superpopulação Figura 4.1 Valores de \\(EPA\\) e \\(EPA\\) de Kish para conglomeração "],["lista-de-siglas.html", "Lista de Siglas", " Lista de Siglas Sigla Descrição AAS Amostragem Aleatória Simples Sem Reposição AASC Amostragem Aleatória Simples Com Reposição AC2 Amostragem Conglomerada em dois estágios AC2S AC2 com AAS nos 2 estágios AC2PC AC2 com PPT com reposição no primeiro estágio e AAS no segundo estágio AES Amostragem Estratificada Simples CD80 Censo Demográfico 1980 CPI Consumer Price Index do US Bureau of Labour Statistics EMPV Estimadores de Máxima Pseudo Verossimilhança EPA Efeito do Plano Amostral EMPA Efeito Multivariado do Plano Amostral HT Horvitz-Thompson IBGE Instituto Brasileiro de Geografia e Estatística IID Independentes e Identicamente Distribuídas MCP Método do Conglomerado Primário MINITAB Minitab Statistical Software MPV Método de Máxima Pseudo Verossimilhança MQO Mínimos Quadrados Ordinários MQP Mínimos Quadrados Ponderados MV Método de Máxima Verossimilhança MPV Método de Máxima Pseudo-Verossimilhança NIC.br Núcleo de Informação e Coordenação do Ponto BR PME Pesquisa Mensal de Emprego PNAD Pesquisa Nacional por Amostra de Domicílios PNAD Contínua Pesquisa Nacional por Amostra de Domicílios Contínua PO Pessoal ocupado em 31/12/1994 PPT Probabilidades Proporcionais ao Tamanho QDP Quantidade Descritiva Populacional QDPC Quantidade Descritiva Populacional Correspondente R Software Estatístico R REC Receita no ano de 1994 PO Pessoal Ocupado em 31/12/1994 RM Região Metropolitana SAL Salários pagos no ano de 1994 SAS Statistical Analysis System SIS Amostragem Sistemática com Probabilidades Proporcionais ao Tamanho SINAPE Simpósio Nacional de Probabilidade e Estatística SM Salários Mínimos SPSS Statistical Package for the Social Science STATA Software for Statistics and Data Science TCL Teorema Central do Limite TIC Tecnologias de Informação e Comunicação TICDOM Pesquisa sobre o uso das Tecnologias de Informação e Comunicação nos domicílios brasileiros TRI Teoria da Resposta ao Item UF Unidade da Federação UPA Unidade Primária de Amostragem USA Unidade Secundária de Amostragem "],["lista-de-tabelas.html", "Lista de Tabelas", " Lista de Tabelas Tabela Descrição Tabela 1.1 Tamanhos da amostra de setores e domicílios por macrorregião Tabela 1.2 Resumos da distribuição dos pesos de domicílios por macrorregião Tabela 1.3 Estimativas de parâmetros populacionais e EPAs Tabela 2.1 Representação esquemática da abordagem Modelagem Clássica Tabela 2.2 Representação esquemática da abordagem Amostragem Probabilística Tabela 2.3 Representação esquemática da Modelagem de Superpopulação Tabela 2.4 Distribuição de probabilidades conjunta na população \\(P( Y_i = y ; X_i = x )\\) Tabela 2.5 Distribuição de probabilidades condicional de \\(y\\) dado \\(x\\) na população - \\(P( Y_i = y | X_i = x )\\) Tabela 2.6 Distribuição de probabilidades conjunta na população \\(f_U( x ; y )\\) Tabela 2.7 Distribuição de probabilidades condicional de \\(Y\\) dado \\(X\\) na população - \\(f_U( y | x )\\) Tabela 2.8 Distribuição de probabilidades marginal de \\(Y\\) na população e na amostra - \\(f_U(y)\\) e \\(f_s(y)\\) Tabela 4.1 Efeitos do plano amostral de Kish para variáveis selecionadas Região Metropolitana do Rio de Janeiro Tabela 4.2 Definição da estratificação da população de empresas Tabela 4.3 Propriedades dos estimadores da média das variáveis de pesquisa Tabela 4.4 Propriedades dos estimadores de variância do estimador ponderado da média Tabela 4.5 Estimativas da variância e do efeito do plano amostral para as médias dos salários e receitas Tabela 4.6 Probabilidades de cobertura para níveis nominais de 0,95 e 0,99 Tabela 4.7 Níveis de significância verdadeiros, em porcentagem, do teste \\(T^2\\) para o nível nominal de 5 por cento assumindo autovalores iguais a \\(\\delta\\) Tabela 5.1 Probabilidades de seleção da amostra da PNAD da década de 1990 segundo regiões "],["introduc.html", "Capítulo 1 Introdução 1.1 Motivação 1.2 Objetivos do livro 1.3 Estrutura do livro", " Capítulo 1 Introdução 1.1 Motivação Este livro trata de questões e ideias de grande importância para os analistas de dados obtidos através de pesquisas amostrais, tais como as conduzidas por agências produtoras de informações estatísticas oficiais ou públicas. Tais dados são comumente utilizados em análises descritivas envolvendo a obtenção de estimativas para totais, médias, proporções e razões. Nessas análises, em geral, são devidamente incorporados os pesos distintos das observações e a estrutura do plano amostral empregado para obter os dados considerados. Nas últimas décadas tornou-se muito mais frequente um outro tipo de uso de dados de pesquisas amostrais. Tal uso, denominado secundário e/ou analítico, envolve a construção e ajuste de modelos, geralmente feito por analistas que trabalham fora das agências produtoras dos dados. Neste caso, o foco da análise busca estabelecer a natureza de relações ou associações entre variáveis ou testar hipóteses. Para tais fins, a estatística clássica conta com um vasto arsenal de ferramentas de análise, já incorporadas aos principais sistemas estatísticos disponíveis (tais como MINITAB, R, SAS, SPSS, etc). Muitas ferramentas de análise convencionais disponíveis nesses sistemas estatísticos geralmente partem de hipóteses básicas sobre as amostras disponíveis que só são válidas quando os dados foram obtidos através de Amostras Aleatórias Simples Com Reposição - AASC. Por exemplo, a hipótese de observações Independentes e Identicamente Distribuídas - IID corresponde justamente ao caso de observações selecionadas por AASC de uma população especificada. Tais hipóteses são geralmente inadequadas para modelar observações provenientes de pesquisas amostrais de populações finitas, pois desconsideram os seguintes aspectos relevantes dos planos amostrais usualmente empregados nessas pesquisas: probabilidades desiguais de seleção das unidades; conglomeração das unidades; estratificação; calibração ou imputação para não resposta e outros ajustes. Em amostragem de populações finitas, a abordagem probabilística emprega pesos para as observações amostrais que dependem das probabilidades de seleção das unidades, que podem ser desiguais. Em consequência, as estimativas pontuais de parâmetros descritivos da população ou mesmo de parâmetros de modelos são influenciadas por pesos distintos das observações. Além disso, as estimativas de variância (ou da precisão dos estimadores) são influenciadas pela conglomeração, estratificação e pesos ou, no caso de não resposta, também por eventual imputação de dados faltantes ou reponderação das observações disponíveis para compensar a não resposta. Ao ignorar estes aspectos, as ferramentas convencionais dos sistemas estatísticos tradicionais de análise podem produzir estimativas incorretas das variâncias das estimativas pontuais. O Exemplo 1.1 considera o uso de dados de uma pesquisa amostral real, realizada pelo Núcleo de Informação e Coordenação do Ponto BR - NIC.br, para ilustrar como os pontos i) a iv) acima mencionados afetam a inferência sobre quantidades descritivas populacionais tais como totais, médias, proporções e razões. Exemplo 1.1 Pesquisa TIC Domicílios 2019 do NIC.br Os dados deste exemplo são relativos à distribuição dos pesos de domicílios na amostra da Pesquisa TIC Domicílios 2019 do NIC.br - TICDOM 2019. NIC.br (2020) apresenta os resultados da pesquisa e seu capítulo intitulado Relatório Metodológico descreve os métodos e o plano amostral empregado na pesquisa, que foi estratificado e conglomerado em múltiplos estágios, com alocação desproporcional da amostra nos estratos. As Unidades Primárias de Amostragem - UPAs foram municípios ou setores censitários da Base Operacional Geográfica do IBGE conforme usada para o Censo Demográfico de 2010. A seleção de municípios quando estes eram UPAs foi feita usando Amostragem Sistemática com Probabilidades Proporcionais ao Tamanho - SIS - ver a Seção 10.6 de P. L. N. Silva et al. (2020). A seleção dos setores dentro de cada município também foi feita com AS-PPT. Dentro de cada setor censitário selecionado, quinze domicílios foram selecionados por amostragem aleatória simples sem reposição, após a atualização do cadastro de domicílios do setor. A amostra da pesquisa foi planejada e dimensionada visando ao fornecimento de estimativas com precisão adequada para as cinco macrorregiões do Brasil. Os tamanhos da amostra planejada de setores e domicílios para as macrorregiões são apresentados na Tabela 1.1. Tabela 1.1: \\(\\text{Tamanhos da amostra de setores e domicílios por macrorregião}\\) Macrorregião Setores Domicílios Norte 201 3.015 Nordeste 617 9.255 Sudeste 863 12.945 Sul 337 5.055 Centro-Oeste 196 2.940 Total 2.214 33.210 A Tabela 1.2 apresenta um resumo das distribuições dos pesos amostrais dos domicílios pesquisados na TICDOM 2019 para as macrorregiões separadamente e, também, para o conjunto da amostra da pesquisa. Tabela 1.2: \\(\\text{Resumos da distribuição dos pesos de domicílios por macrorregião}\\) Macrorregião Mínimo Quartil1 Mediana Quartil3 Máximo Norte 1,8 1.957 2.898 4.359 82.627 Nordeste 103,8 1.283 2.057 3.314 40.118 Sudeste 36,0 1.814 2.583 3.583 27.993 Sul 20,0 1.028 1.756 2.706 118.715 Centro-Oeste 140,8 1.153 2.401 3.640 29.029 Total 1,8 1.546 2.470 3.636 118.715 No cálculo dos pesos amostrais foram consideradas as probabilidades de inclusão dos domicílios na amostra, bem como as correções de calibração para compensar a não resposta. Contudo, a grande variabilidade dos pesos amostrais da TICDOM 2019 é devida, principalmente, à variabilidade das probabilidades de inclusão na amostra, ilustrando desta forma o ponto i) citado anteriormente nesta seção. Tal variabilidade é devida à alocação desproporcional da amostra entre os estratos geográficos e ao emprego de contagens defasadas de domicílios nos setores para definir probabilidades de seleção dos mesmos. Nas análises de dados desta pesquisa, deve-se considerar que há domicílios com pesos muito diferentes. Por exemplo, dividindo-se o maior peso pelo menor encontra-se uma razão da ordem de 66 mil. Os pesos também variam bastante entre as regiões, sendo a razão entre as medianas dos pesos das regiões Norte e Sul igual a 1,65 em função da alocação desproporcional da amostra nas regiões. Os maiores pesos são também muito maiores que os pesos medianos, com essa razão sendo 48 para o conjunto da amostra. Tais pesos são utilizados para expandir os dados, multiplicando-se cada observação pelo seu respectivo peso. Assim, por exemplo, para estimar quantos domicílios da população pertencem a determinado conjunto (domínio), basta somar os pesos dos domicílios da amostra que pertencem a este conjunto. É possível ainda incorporar os pesos, de maneira simples e natural, quando se quer estimar medidas descritivas simples da população, tais como totais, médias, proporções, razões, etc. Os métodos para estimação de parâmetros descritivos da população como os aqui citados são cobertos com maior detalhe em P. L. N. Silva et al. (2020). Por outro lado, quando se quer utilizar a amostra para estudos analíticos, as opções padrão disponíveis nos sistemas estatísticos usuais para levar em conta os pesos distintos das observações são apropriadas somente para observações IID. Por exemplo, os procedimentos padrão disponíveis para estimar a média populacional permitem utilizar pesos distintos das observações amostrais, mas tratariam tais pesos como se fossem frequências de observações repetidas na amostra e, portanto, interpretariam a soma dos pesos como tamanho amostral, situação que, na maioria das vezes, geraria inferências incorretas sobre a precisão das estimativas resultantes. Isto ocorre porque o tamanho da amostra é muito menor que a soma dos pesos amostrais usualmente encontrados nos arquivos de microdados de pesquisas disseminados por agências de estatísticas oficiais ou públicas, como é o caso da pesquisa TICDOM 2019 aqui considerada. Em tais pesquisas, a opção mais frequente é disseminar pesos que, quando somados, estimam o total de unidades da população. Além disso, a variabilidade dos pesos para distintas observações amostrais produz impactos tanto na estimação pontual quanto na estimação das variâncias dessas estimativas, que sofre ainda influência da conglomeração e da estratificação - pontos ii) e iii) mencionados anteriormente. Para exemplificar o impacto de ignorar os pesos e o plano amostral ao estimar quantidades descritivas populacionais, tais como totais e proporções, calculamos estimativas de quantidades desses diferentes tipos usando a amostra da TICDOM 2019 juntamente com estimativas das respectivas variâncias. Tais estimativas de variância foram calculadas sob duas estratégias: considerando Amostragem Aleatória Simples - AAS e, portanto, ignorando o plano amostral efetivamente adotado na pesquisa; e considerando o plano amostral da pesquisa e os pesos diferentes das unidades. Na Tabela 1.3 apresentamos as estimativas dos seguintes parâmetros populacionais: porcentagem de domicílios com computador de mesa; porcentagem de domicílios com notebook; porcentagem de domicílios com tablete; porcentagem de domicílios com algum computador (de mesa, notebook ou tablete); total de domicílios com algum computador (de mesa, notebook ou tablete); número médio de computadores por domicílio que tem computador. A razão entre as estimativas de variância obtidas sob o plano amostral verdadeiro (de fato usado na pesquisa) e sob AAS foi estimada para cada uma das estimativas consideradas usando o pacote survey do R (Lumley, 2021). Essa razão fornece uma medida do efeito de ignorar o plano amostral. Os resultados das estimativas pontuais (Est_por_AAS e Est_Verd para as estimativas considerando AAS e o plano amostral verdadeiro, respectivamente), do desvio padrão da estimativa considerando o plano amostral verdadeiro (DP_Est_Verd) e do Efeito do Plano Amostral - \\(EPA\\) são apresentados na Tabela 1.3. Tabela 1.3: \\(\\text{Estimativas de parâmetros populacionais e EPAs}\\) Parâmetro Est_por_AAS Est_Verd DP_Est_Verd EPA Porcentagem de domicílios com computador de mesa 14,21 16,17 0,46 3,64 Porcentagem de domicílios com notebook 22,84 26,05 0,66 5,30 Porcentagem de domicílios com tablete 11,24 12,95 0,36 2,64 Porcentagem de domicílios com computador 35,34 39,36 0,67 4,38 Total de domicílios com computador (milhões) 25,10 27,95 1,37 36,90 Número médio de computadores por domicílio que tem computador 1,55 1,63 0,02 3,73 Os resultados mostram que há diferenças entre as estimativas pontuais dos parâmetros considerados, com uma tendência de subestimar quando se ignoram os pesos e o plano amostral efetivamente usado na pesquisa. As estimativas dos \\(EPAs\\) variam entre 2,64 e 5,30, se deixarmos de fora o \\(EPA\\) maior que 30 observado para a estimativa da contagem de domicílios com computador. Estes valores indicam que ignorar o plano amostral na estimação da precisão levaria também à subestimação dos erros padrão. Note que as variáveis e parâmetros cujas estimativas foram apresentadas na Tabela 1.3 não foram escolhidas de forma a acentuar os efeitos ilustrados, mas tão somente para representar distintos parâmetros (totais, médias, proporções) e variáveis de interesse. Os resultados apresentados para as estimativas de \\(EPA\\) ilustram bem o cenário típico em pesquisas amostrais complexas: o impacto do plano amostral sobre a inferência varia conforme a variável e o tipo de parâmetro de interesse. Note ainda que todas as estimativas de \\(EPA\\) apresentaram valores superiores a 2. 1.2 Objetivos do livro Este livro tem três objetivos principais: Apresentar uma coleção de métodos e recursos computacionais disponíveis no R para análise de dados de pesquisas amostrais, equipando o analista para trabalhar com tais dados, reduzindo assim o risco de inferências incorretas. Ilustrar e analisar o impacto das simplificações feitas ao utilizar pacotes usuais de análise de dados quando estes são provenientes de pesquisas amostrais complexas. Ilustrar o potencial analítico de muitas das pesquisas produzidas por agências de estatísticas públicas para responder questões de interesse, mediante uso de ferramentas de análise estatística agora já bastante difundidas, aumentando assim o valor adicionado destas pesquisas. Para alcançar tais objetivos, adotamos uma abordagem fortemente ancorada na apresentação de exemplos de análises de dados obtidos em pesquisas amostrais, usando os recursos do sistema estatístico R, http://www.r-project.org/. A comparação dos resultados de análises feitas das duas formas (considerando ou ignorando o plano amostral) permite avaliar o impacto de não se considerar os pontos i) a iv) anteriormente citados. O ponto iv) não é tratado de forma completa neste texto. O leitor interessado na análise de dados sujeitos a não resposta pode consultar Kalton (1983a), Little e Rubin (2002), Rubin (1987), Särndal et al. (1992), ou Schafer (1997), por exemplo. 1.3 Estrutura do livro O livro está organizado em duas partes. A primeira parte representa uma segunda edição atualizada e revisada do conteúdo do livro publicado em 1998, Djalma G. C. Pessoa e Silva (1998). A segunda parte é uma coletânea de textos reunidos para cobrir temas não tratados no livro anterior, que foram produzidos por autores convidados, como forma de prestar homenagem ao Prof. Djalma Pessoa. A parte 1 é composta por nove capítulos. Este primeiro capítulo discute a motivação para estudar o assunto e apresenta uma ideia geral dos objetivos e da estrutura do livro. No Capítulo 2, procuramos dar uma visão das diferentes abordagens utilizadas na análise estatística de dados de pesquisas amostrais. Apresentamos um referencial para inferência com ênfase no Modelo de Superpopulação que incorpora, de forma natural, tanto uma estrutura estocástica para descrever a geração dos dados populacionais (modelo) como o plano amostral efetivamente utilizado para obter os dados amostrais (plano amostral). As referências básicas para seguir este capítulo são o Capítulo 2 em P. L. N. Silva et al. (2020), o Capítulo 1 em Skinner et al. (1989) e os Capítulos 1 e 2 em Chambers e Skinner (2003). Esse referencial tem evoluído ao longo dos anos como uma forma de permitir a incorporação de ideias e procedimentos de análise e inferência usualmente associados à Estatística Clássica à prática da análise e interpretação de dados provenientes de pesquisas amostrais. Apesar dessa evolução, sua adoção não é livre de controvérsia e uma breve revisão dessa discussão é apresentada no Capítulo 2. No Capítulo 3 apresentamos uma revisão sucinta, para recordação, de alguns resultados básicos da Teoria de Amostragem, requeridos nas partes subsequentes do livro. São discutidos os procedimentos básicos para estimação de totais considerando o plano amostral e, em seguida, revistas algumas técnicas para estimação de variâncias que são necessárias e úteis para o caso de estatísticas complexas, tais como razões e outras estatísticas requeridas na inferência analítica com dados amostrais. As referências centrais para este capítulo são os Capítulos 2 e 3 em Särndal et al. (1992), P. L. N. Silva et al. (2020), Wolter (1985) e Cochran (1977). No Capítulo 4 introduzimos o conceito de Efeito do Plano Amostral - EPA, que permite avaliar o impacto de ignorar a estrutura dos dados populacionais ou do plano amostral sobre a estimativa da variância de um estimador. Para isso, comparamos o estimador da variância apropriado para dados obtidos por Amostragem Aleatória Simples (hipótese de AAS) com o valor esperado deste mesmo estimador sob a distribuição de aleatorização induzida pelo plano amostral efetivamente utilizado (plano amostral verdadeiro). Aqui a referência principal foi o livro Skinner et al. (1989), complementado com o texto de Lehtonen e Pahkinen (1995). No Capítulo 5 estudamos a questão do uso de pesos ao analisar dados provenientes de pesquisas amostrais complexas e introduzimos um método geral, denominado Método de Máxima Pseudo Verossimilhança - MPV, para incorporar os pesos e o plano amostral na obtenção não só de estimativas de parâmetros dos modelos de interesse mais comuns, como também das variâncias dessas estimativas. As referências básicas utilizadas nesse capítulo foram Skinner et al. (1989), Pfeffermann (1993), Binder (1983) e o Capítulo 6 em P. L. N. Silva et al. (2020). O Capítulo ?? trata da obtenção de Estimadores de Máxima Pseudo Verossimilhança - EMPV e da respectiva matriz de covariância para os parâmetros em modelos de regressão linear quando os dados vêm de pesquisas amostrais complexas. Apresentamos alguns exemplos de aplicação desse método ilustrando o uso do pacote survey, Lumley (2021), para ajustar modelos de regressão linear. As referências centrais são o Capítulo 6 em P. L. N. Silva et al. (2020) e Binder (1983). O Capítulo ?? trata da obtenção de Estimadores de Máxima Pseudo Verossimilhança - EMPV e da respectiva matriz de covariância para os parâmetros em modelos de regressão logística quando os dados vêm de pesquisas amostrais complexas. Apresentamos alguns exemplos de aplicação desse método ilustrando o uso do pacote survey, Lumley (2021), para ajustar modelos de regressão logística. As referências centrais são o Capítulo 6 em P. L. N. Silva et al. (2020) e Binder (1983). Os Capítulos ?? e ?? tratam da análise de dados categóricos, dando ênfase à adaptação dos testes clássicos para proporções, de independência e de homogeneidade em tabelas de contingência, para lidar com dados provenientes de pesquisas amostrais complexas. Apresentamos correções das estatísticas clássicas e também a estatística de Wald baseada no plano amostral. As referências básicas usadas nesses capítulos foram o Capítulo 4 em Skinner et al. (1989) e o Capítulo 7 em Lehtonen e Pahkinen (1995). Também são apresentadas as ideias básicas de como efetuar ajuste de modelos log-lineares a dados de frequências em tabelas de múltiplas entradas. A parte 2 é composta por mais doze capítulos, todos escritos por autores convidados. Todos estes temas foram objeto de avanços importantes tanto no desenvolvimento de métodos como no de ferramentas computacionais para sua implementação no ambiente do sistema R, desde que foi publicado o livro inicial. A seguir, a lista dos capítulos da parte 2. Capítulo 10 - Gráficos Capítulo 11 - Estimação de funções de densidade Capítulo 12 - Estimação de funções de distribuição e quantis Capítulo 13 - Estimação de medidas de desigualdade e pobreza Capítulo 14 - Estimação de fluxos Capítulo 15 - Modelos multiníveis Capítulo 16 - Modelos para dados longitudinais Capítulo 17 - Modelos de teoria da resposta ao item Capítulo 18 - Modelos de séries temporais Capítulo 19 - Modelos de redes neurais Capítulo 20 - Modelos log-lineares para tabelas Capítulo 21 - Aplicações O Capítulo ?? aborda a elaboração de alguns tipos de gráficos de uso frequente quando os dados elementares provêm de pesquisas amostrais. Entre os gráficos cobertos estão histogramas, boxplots, diagramas de dispersão e gráficos tipo quantil-quantil (qq-plots). O Capítulo ?? trata da estimação de densidades, ferramenta que tem assumido importância cada dia maior com a maior disponibilidade de microdados de pesquisas amostrais para analistas fora das agências produtoras. Também é apresentada ferramenta para elaboração de gráficos das densidades estimadas. O Capítulo ?? trata da estimação de funções de distribuição empíricas e também de quantis. Também é apresentada ferramenta para elaboração de gráficos das funções de distribuição estimadas. O Capítulo ?? trata da estimação de medidas de desigualdade e pobreza, enfatizando o uso destas em análises baseadas na renda de domicílios ou pessoas. Apresenta os recursos do pacote convey (inserir referência). O Capítulo ?? trata da estimação de fluxos em pesquisas repetidas sujeitas a não resposta. Apresenta os recursos do pacote surf (inserir referência). O Capítulo ?? trata da estimação e ajuste de modelos hierárquicos ou multiníveis considerando o plano amostral. Modelos hierárquicos têm sido bastante utilizados para explorar situações em que as relações entre variáveis de interesse em uma certa população de unidades elementares (por exemplo, crianças em escolas, pacientes em hospitais, empregados em empresas, moradores em regiões, etc.) são afetadas por efeitos de grupos determinados ao nível de unidades conglomeradas (os grupos). Ajustar e interpretar tais modelos é tarefa mais difícil que o mero ajuste de modelos lineares, mesmo em casos onde os dados são obtidos de forma exaustiva ou por AAS, e ainda mais complicada quando se trata de dados obtidos através de pesquisas com planos amostrais complexos. Diferentes abordagens estão disponíveis para ajuste de modelos hierárquicos nesse caso, e este capítulo apresenta uma revisão de tais abordagens, ilustrando com aplicações a dados de pesquisas amostrais de escolares. O Capítulo ?? trata do ajuste de modelos para dados longitudinais. O Capítulo ?? trata do ajuste de modelos da Teoria da Resposta ao Item - TRI. O Capítulo ?? trata do ajuste de modelos séries temporais a dados de pesquisas amostrais repetidas. O Capítulo ?? trata do ajuste de modelos de redes neurais. O Capítulo ?? trata do ajuste de modelos log-lineares a dados de tabelas de contingência. O Capítulo ?? apresenta algumas aplicações de modelos e métodos descritos em capítulos anteriores no contexto de pesquisas sobre TICs no Brasil. Uma das características que procuramos dar ao livro foi o emprego de exemplos com dados reais, retirados principalmente da experiência do IBGE com pesquisas amostrais complexas. Sem prejuízo na concentração de exemplos que se utilizam de dados de pesquisas do IBGE, incluímos também exemplos que consideram aplicações a dados de pesquisas realizadas por outras instituições. Nas duas décadas desde a primeira edição deste livro foram muitas as iniciativas de realizar pesquisas por amostragem em várias áreas, tendo a educação e a saúde como as mais proeminentes. Para facilitar a localização e replicação dos exemplos pelos leitores, estes foram em sua maioria introduzidos em seções denominadas Laboratório ao final de cada um dos capítulos. Os códigos em R dos exemplos são todos fornecidos, o que torna simples a replicação dos mesmos pelos leitores. Optamos pelo emprego do sistema R que, por ser de acesso livre e gratuito, favorece o amplo acesso aos interessados em replicar nossas análises e também em usar as ferramentas disponíveis para implementar suas próprias análises de interesse com outros conjuntos de dados. Embora a experiência de fazer inferência analítica com dados de pesquisas amostrais complexas já tenha alguma difusão no Brasil, acreditamos ser fundamental difundir ainda mais essas ideias para alimentar um processo de melhoria do aproveitamento dos dados das inúmeras pesquisas realizadas pelo IBGE e instituições congêneres, que permita ir além da tradicional estimação de totais, médias, proporções e razões. Esperamos com esse livro fazer uma contribuição a esse processo. Uma dificuldade em escrever um livro como este vem do fato de que não é possível começar do zero: é preciso assumir algum conhecimento prévio de ideias e conceitos necessários à compreensão do material tratado. Procuramos tornar o livro acessível para um estudante de fim de curso de graduação em Estatística. Por essa razão, optamos por não apresentar provas de resultados e, sempre que possível, apresentar os conceitos e ideias de maneira intuitiva, juntamente com uma discussão mais formal para dar solidez aos resultados apresentados. As provas de vários dos resultados aqui discutidos se restringem a material disponível apenas em artigos em periódicos especializados estrangeiros e, portanto, são de acesso mais difícil. Ao leitor em busca de maior detalhamento e rigor, sugerimos consultar diretamente as inúmeras referências incluídas ao longo do texto. Para um tratamento mais profundo do assunto, os livros de Skinner et al. (1989) e Chambers e Skinner (2003) são as referências centrais a consultar. Para aqueles querendo um tratamento ainda mais prático que o nosso, os livros de Lehtonen e Pahkinen (1995) e Heeringa et al. (2010) podem ser opções interessantes, sendo que este último apresenta os recursos do sistema STATA para análise de dados amostrais. "],["refinf.html", "Capítulo 2 Referencial para Inferência 2.1 Modelagem - Primeiras ideias 2.2 Abordagem 1 - Modelagem Clássica 2.3 Abordagem 2 - Amostragem Probabilística 2.4 Discussão das abordagens 1 e 2 2.5 Abordagem 3 - Modelagem de Superpopulação 2.6 Fontes de variação 2.7 Modelos de Superpopulação 2.8 Plano amostral 2.9 Planos amostrais informativos e ignoráveis", " Capítulo 2 Referencial para Inferência 2.1 Modelagem - Primeiras ideias Com o objetivo de dar uma primeira ideia sobre o assunto a ser tratado neste livro vamos considerar, em situações simples, algumas abordagens alternativas para modelagem e análise estatística. A ideia é apresentar a principal abordagem que vamos considerar, a de Modelagem de Superpopulação, em contraste com as alternativas que poderiam ser consideradas, mas que tornariam difícil incorporar adequadamente as características que diferenciam dados obtidos com amostras complexas de outros que se queira analisar. 2.2 Abordagem 1 - Modelagem Clássica Seja \\(y\\) uma variável de pesquisa (ou de interesse), e sejam \\(n\\) observações desta variável para uma amostra de unidades de pesquisa denotadas por \\(y_1, \\ldots ,y_n\\). Em Inferência Estatística, a abordagem que aqui chamamos de Modelagem Clássica considera \\(y_1, \\ldots, y_n\\) como valores (realizações) de variáveis aleatórias \\(Y_1, \\ldots, Y_n\\). Podemos formular modelos bastante sofisticados para a distribuição conjunta destas variáveis aleatórias, mas para simplificar a discussão, vamos inicialmente supor que \\(Y_1, \\ldots, Y_n\\) são variáveis aleatórias independentes e identicamente distribuídas - IID - com a mesma distribuição caracterizada pela função de densidade ou de frequência \\(f(y; \\boldsymbol{\\theta})\\), onde \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\) é o parâmetro (um vetor de dimensão \\(K \\times 1\\)) indexador da distribuição \\(f\\), e \\(\\boldsymbol{\\Theta}\\) é o espaço paramétrico. A partir das observações \\(y_1, \\ldots, y_n\\), são feitas inferências a respeito do parâmetro \\(\\boldsymbol{\\theta}\\), de modo a ajustar o modelo aos dados disponíveis. Uma representação gráfica esquemática dessa abordagem é apresentada na Figura 2.1, e uma descrição esquemática resumida é apresentada na Tabela 2.1. Figura 2.1: \\(\\text{Representação esquemática da } \\textit{Modelagem Clássica}\\) Tabela 2.1: \\(\\text{Representação esquemática da abordagem }\\textit{Modelagem Clássica}\\) Dados Amostrais (observações) \\(y_1, \\dots, y_n\\) Modelo Paramétrico/ Hipóteses \\(Y_1, \\dots, Y_n \\text{ variáveis aleatórias IID com distribuição } f(y,\\boldsymbol{\\theta}) \\text{ onde } \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\) Objetivo \\(\\text{Inferir sobre } \\boldsymbol{\\theta} \\text{ usando as observações } y_1, \\dots, y_n\\) Do ponto de vista matemático, o parâmetro \\(\\boldsymbol{\\theta}\\) serve para indexar os elementos da família de distribuições \\(\\left\\{f\\left( y; \\boldsymbol{\\theta} \\right); \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta} \\right\\}\\). Na prática, as questões relevantes da pesquisa são traduzidas em termos de perguntas sobre o valor ou região a que pertence o parâmetro \\(\\boldsymbol{\\theta}\\), e a inferência sobre \\(\\boldsymbol{\\theta}\\) a partir dos dados ajuda a responder tais questões. Esta abordagem é útil em estudos analíticos tais como, por exemplo, na investigação da natureza da associação entre variáveis (modelos de regressão linear ou logística, modelos log-lineares etc.). Vários exemplos discutidos ao longo dos Capítulos ??, ?? e ?? ilustram situações deste tipo. No Capítulo ?? o foco é a estimação não paramétrica da forma da função \\(f(y; \\boldsymbol{\\theta})\\). Inferência sob modelos do tipo descrito nesta seção forma o conteúdo de um curso introdutório de inferência estatística. Mais detalhes podem ser consultados, por exemplo, em Casella e Berger (2010) e Magalhães e Lima (2015). Exemplo 2.1 Estimação da proporção de sucessos em ensaios de Bernoulli Para dar um exemplo concreto de modelagem do tipo descrito aqui, considere uma sequência de \\(n\\) ensaios de Bernoulli, em que a cada ensaio a resposta é o indicador de ocorrência de um evento de interesse - por exemplo, o indivíduo amostrado já foi vacinado contra uma doença especificada. Se considerarmos que os resultados desses ensaios podem ser modelados como uma sequência de variáveis aleatórias \\(Y_1, \\ldots, Y_n\\) IID, com distribuição de Bernoulli dada por \\(f(y; \\theta) = \\theta^y \\times (1 - \\theta)^{(1-y)}\\), com um único parâmetro \\(\\theta \\in (0;1)\\), podemos usar a amostra observada \\(y_1, \\ldots, y_n\\) para fazer inferência sobre \\(\\theta\\). Sob o modelo especificado, é fácil deduzir que \\(T = \\sum_{i=1}^n Y_i\\) tem distribuição Binomial de parâmetros \\((n, \\theta)\\). Logo, \\(\\overline{T} = T/n\\) tem média \\(\\theta\\). Portanto, considerando o método dos momentos, \\(\\overline{T}\\) pode ser usado para estimar o parâmetro de interesse \\(\\theta\\). Ademais, como \\(n\\) é conhecido, sabemos que a variância da sua distribuição de probabilidades é dada por \\(\\theta \\times (1 - \\theta) / n\\), podendo ser estimada sem viés usando \\(\\overline{T} \\times (1 - \\overline{T}) / (n-1)\\). Para amostras de tamanho grande (\\(n \\rightarrow \\infty\\)), podemos usar o Teorema Central do Limite - TCL - para obter intervalos de confiança de nível especificado para \\(\\theta\\) e também testar hipóteses sobre regiões de interesse. 2.3 Abordagem 2 - Amostragem Probabilística A abordagem adotada pelos praticantes de Amostragem Probabilística (amostristas) considera uma população finita \\(U = \\{1, \\ldots, N\\}\\), da qual é selecionada uma amostra \\(s = \\left\\{ i_{1}, \\ldots, i_{n} \\right\\}\\), segundo um plano amostral caracterizado por \\(p(s)\\), probabilidade de ser selecionada a amostra \\(s\\), suposta calculável para todas as possíveis amostras. Os valores \\(y_{1}, \\ldots, y_{N}\\) da variável de interesse \\(y\\) na população finita são considerados fixos, porém desconhecidos. A partir dos valores observados na amostra \\(s\\), denotados por \\(y_{i_1}, \\ldots, y_{i_n}\\), são feitas inferências a respeito de funções dos valores populacionais, digamos \\(g \\left( y_{1}, \\ldots, y_{N}\\right)\\). Os valores de tais funções são quantidades descritivas populacionais - QDPs - também denominadas parâmetros da população finita pelos amostristas. Em geral, o objetivo desta abordagem é fazer estudos descritivos utilizando funções \\(g\\) particulares, tais como totais \\(g \\left( y_{1}, \\ldots, y_{N} \\right) = \\sum_{i=1}^{N} y_{i}\\), médias \\(g \\left( y_{1}, \\ldots, y_{N} \\right) = N^{-1} \\sum_{i=1}^{N} y_{i}\\), proporções, razões etc. Uma descrição esquemática resumida dessa abordagem é apresentada na Tabela 2.2, e uma representação gráfica resumida na Figura 2.2. Tabela 2.2: \\(\\text{Representação esquemática da abordagem }\\textit{Amostragem Probabilística}\\) Dados Amostrais \\(y_{i_1}, \\ldots, y_{i_n}\\) Modelo / Hipóteses \\(\\text{Dados extraídos de }y_1, \\ldots, y_N \\text{ segundo }p(s)\\) Objetivo \\(\\text{Inferir sobre funções }g(y_1, \\ldots , y_N)\\text{ usando }y_{i_1}, \\ldots, y_{i_n}\\) Figura 2.2: \\(\\text{Representação esquemática da }\\textit{Amostragem Probabilística}\\) Esta abordagem é largamente empregada na produção de estatísticas públicas e oficiais, por agências e instituições de muitos países. Uma das alegadas vantagens dessa abordagem é o fato de que as distribuições de referência usadas para inferência são controladas pelos amostristas que planejam as pesquisas por amostragem e, portanto, a inferência pode ser considerada não paramétrica e não dependente de modelos que precisariam ser especificados pelo analista. Uma revisão detalhada da amostragem probabilística pode ser encontrada em P. L. N. Silva et al. (2020). Nessa abordagem, a inferência é geralmente guiada também por distribuições dos estimadores aproximadas usando o TCL. Exemplo 2.2 Estimação do total com amostragem estratificada simples Considere o cenário de uma população \\(U\\) que foi estratificada em \\(H\\) grupos com base numa variável de estratificação \\(x\\). Dos estratos formados, foram selecionadas de forma independente amostras aleatórias simples de tamanhos \\(n_1, \\ldots, n_h, \\ldots, n_H\\). Nessa população, denotando por \\(U_h\\) o \\(h\\)-ésimo estrato, de tamanho \\(N_h\\), o total populacional da variável de pesquisa \\(y\\) pode ser escrito como: \\[ T_y = \\sum_{h=1}^H \\sum_{i \\in U_h} y_i \\tag{2.1} \\] O estimador padrão (tipo Horvitz-Thompson) para este parâmetro na amostragem estratificada simples é dado por: \\[ \\widehat{T}_y = \\sum_{h=1}^H \\frac{N_h}{n_h} \\sum_{i \\in s_h} y_i \\quad \\tag{2.2} \\] onde \\(s_h\\) é a amostra das unidades do estrato \\(h, h=1, 2, \\dots, H\\). Este estimador pode ser usado para fazer inferência sobre o total populacional, como descrito, por exemplo, na Seção 11.2 de P. L. N. Silva et al. (2020). A distribuição do estimador \\(\\widehat{T}_y\\) obtida considerando o plano amostral \\(p(s)\\) é denominada de distribuição de aleatorização e é geralmente aproximada usando o TCL para viabilizar a inferência. 2.4 Discussão das abordagens 1 e 2 A primeira abordagem (Modelagem Clássica), nos termos descritos, foi inicialmente proposta para dados de medidas na Física e Astronomia, onde em geral o pesquisador tem relativo controle sobre os experimentos, e onde faz sentido falar em replicação ou repetição do experimento. Neste contexto, a ideia de aleatoriedade é geralmente introduzida para modelar os erros (não controláveis) do processo de medição, e as distribuições de estatísticas de interesse são derivadas a partir da distribuição do modelo especificado. A segunda abordagem (Amostragem Probabilística) é utilizada principalmente no contexto de estudos socioeconômicos observacionais, para levantamento de dados por agências produtoras de informações estatísticas públicas ou oficiais. Nesta abordagem, a aleatoriedade é introduzida pelo pesquisador no processo conduzido para obtenção dos dados, através do plano amostral \\(p(s)\\) utilizado para selecionar as unidades de uma população finita \\(U\\) para observação ou medição. As distribuições das estatísticas de interesse usadas para inferência são derivadas a partir dessa distribuição de aleatorização. Os planos amostrais podem ser complexos, gerando observações afetadas pelas características i) a iv) mencionadas no Capítulo 1. Os dados obtidos são utilizados principalmente para descrição da população finita, mediante o cálculo de estimativas de parâmetros descritivos usuais tais como totais, médias, proporções, razões etc. Sob a abordagem de Amostragem Probabilística, os pontos i) a iv) do Capítulo 1 são devidamente considerados tanto na estimação dos parâmetros descritivos como, também, na estimação de variâncias dos estimadores, permitindo a inferência pontual e por intervalos de confiança baseada na distribuição assintótica normal dos estimadores habitualmente considerados. A abordagem de Amostragem Probabilística é essencialmente não paramétrica, pois não supõe uma distribuição paramétrica particular para as observações da amostra. Por outro lado, essa abordagem tem a desvantagem de fazer inferências restritas à particular população finita considerada. Apesar da abordagem de Amostragem Probabilística ter sido inicialmente concebida e aplicada para problemas de inferência descritiva sobre populações finitas, é cada vez mais comum, porém, a utilização dos dados obtidos através de pesquisas amostrais complexas para fins analíticos, com a aplicação de métodos de análise desenvolvidos e apropriados para a abordagem de Modelagem Clássica. Nesse contexto, é relevante considerar algumas questões de interesse: É adequado aplicar métodos de análise da Modelagem Clássica, concebidos para observações de variáveis aleatórias IID, aos dados obtidos através de pesquisas amostrais complexas? Em caso negativo, seria possível corrigir estes métodos, tornando-os aplicáveis para tratar dados amostrais complexos? Ou seria mais adequado fazer uso analítico dos dados dentro da abordagem de Amostragem Probabilística? E neste caso, como fazer isto, visto que nesta abordagem não é especificado um modelo para a distribuição das variáveis de pesquisa na população? Além destas questões, também é de interesse a questão da robustez da inferência, traduzida nas seguintes perguntas: O que acontece quando o modelo adotado na Modelagem Clássica não é verdadeiro? Neste caso, qual a interpretação dos parâmetros na Modelagem Clássica? Ainda neste caso, as quantidades descritivas populacionais da Amostragem Probabilística poderiam ter alguma utilidade ou interpretação? O objeto deste livro é exatamente discutir respostas para as questões aqui enumeradas. Para isso, vamos considerar uma abordagem que propõe um modelo parametrizado como na Modelagem Clássica, mas formulado para descrever os dados da população, e não os da amostra. Essa abordagem incorpora na análise os pontos i) a iii) do Capítulo 1 mediante aproveitamento da estrutura do plano amostral, como feito habitualmente na Amostragem Probabilística. Essa abordagem, denominada de Modelagem de Superpopulação, foi primeiro proposta em Brewer (1963) e Royall (1970), e é bem descrita, por exemplo, em Binder (1983) e Valliant et al. (2000). 2.5 Abordagem 3 - Modelagem de Superpopulação Nesta abordagem, os valores \\(y_{1}, \\ldots, y_{N}\\) da variável de interesse \\(y\\) na população finita \\(U\\) são considerados observações ou realizações das variáveis aleatórias \\(Y_{1}, \\ldots, Y_{N}\\), supostas IID com distribuição \\(f(y; \\boldsymbol{\\theta})\\), onde \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\). Este modelo é denominado Modelo de Superpopulação. Note que, em contraste com o que se faz na Modelagem Clássica, o modelo probabilístico é aqui especificado para descrever o mecanismo aleatório que gera a população, não a amostra. Na maioria das aplicações práticas, a população de interesse, embora considerada finita, jamais é observada por inteiro. Não obstante, ao formular o modelo para descrever propriedades da população, nossas perguntas e respostas descritas em termos de valores ou regiões para o parâmetro \\(\\boldsymbol{\\theta}\\) passam a se referir à população de interesse ou a populações similares, quer existam ao mesmo tempo, quer se refiram a estados futuros (ou passados) da mesma população. Vale realçar também que pesquisas por amostragem consistem em selecionar parte de uma população para observar, de modo que seja possível estimar alguma coisa sobre toda a população, conforme Thompson (1992). Utilizando um plano amostral definido por \\(p(s)\\), obtemos os valores das variáveis de pesquisa na amostra \\(y_{i_1}, \\ldots, y_{i_n}\\). A partir de \\(y_{i_1}, \\ldots, y_{i_n}\\), em geral não considerados como observações de variáveis aleatórias IID, queremos fazer inferência sobre o parâmetro \\(\\boldsymbol{\\theta}\\), considerando os pontos i) a iii) do Capítulo 1. Ver uma representação gráfica resumida desta abordagem na Figura 2.3. Figura 2.3: \\(\\text{Representação esquemática da }\\textit{Modelagem de Superpopulação}\\) Adotando o Modelo de Superpopulação e considerando métodos usuais disponíveis na Modelagem Clássica, podemos utilizar funções de \\(y_{1}, \\ldots, y_{N}\\) , digamos \\(g( y_{1}, \\ldots, y_{N})\\), para fazer inferência sobre \\(\\boldsymbol{\\theta}\\). Desta forma, definimos estatísticas \\(g \\left( y_{1}, \\ldots, y_{N} \\right)\\) (no sentido da Modelagem Clássica) que são quantidades descritivas populacionais - parâmetros populacionais no contexto da Amostragem Probabilística - que passam a ser os novos parâmetros-alvo. O passo seguinte é utilizar métodos disponíveis na Amostragem Probabilística para fazer inferência sobre \\(g\\left( y_{1}, \\ldots, y_{N} \\right)\\) com base nas observações (dados amostrais) \\(y_{i_1}, \\ldots, y_{i_n}\\). Note que não é possível basear a inferência nos valores populacionais \\(y_{1}, \\ldots, y_{N}\\), já que estes não são todos conhecidos ou observados. Este último passo adiciona a informação sobre o plano amostral utilizado, contida em \\(p(s)\\), à informação estrutural contida no modelo \\(\\left\\{ f\\left( y; \\boldsymbol{\\theta} \\right) ; \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta} \\right\\}\\). Uma representação esquemática dessa abordagem é apresentada na Tabela 2.3. Tabela 2.3: \\(\\text{Representação esquemática da } \\textit{Modelagem de Superpopulação}\\) Dados Amostrais \\(y_{i_1}, \\ldots, y_{i_n}\\) População e esquema de seleção \\(\\text{Selecionados de } y_1, \\dots, y_N \\text{ segundo } p(s)\\) Modelo para população \\(Y_1, \\dots, Y_N \\text{ variáveis aleatórias IID com distribuição } f(y, \\boldsymbol{\\theta}),\\text { onde } \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\) Parâmetro-alvo \\(\\text{Associar } \\boldsymbol{\\theta} \\Leftrightarrow g\\left (Y_{1},\\ldots,Y_{N}\\right)\\) Objetivo \\(\\text{Inferir sobre }g\\left( y_{1}, \\ldots , y_{N} \\right) \\text{ partir de } y_{i_1}, \\ldots, y_{i_n} \\text{ usando } p(s)\\) A descrição da abordagem adotada neste livro foi apresentada de maneira propositalmente simplificada nesta seção, mas é aprofundada ao longo do texto. Admitimos que o leitor esteja familiarizado com a Modelagem Clássica e com as noções básicas da Amostragem Probabilística. A título de recordação, são apresentados na Seção 2.8 alguns resultados básicos da Amostragem Probabilística. A ênfase do texto, porém, é a apresentação da Modelagem de Superpopulação, sendo para isto apresentados os elementos indispensáveis das abordagens de Modelagem Clássica e da Amostragem Probabilística. Ao construir e ajustar modelos a partir de dados de pesquisas amostrais complexas, tais como as executadas pelo IBGE e outras instituições similares, o usuário precisará incorporar as informações sobre pesos e sobre a estrutura dos planos amostrais utilizados para obtenção dos dados. Em geral, ao publicar os resultados das pesquisas, os pesos são considerados, sendo possível produzir estimativas pontuais corretas utilizando sistemas computacionais tradicionais. Por outro lado, para construir intervalos de confiança e testar hipóteses sobre parâmetros de modelos, é necessário conhecer estimativas de variâncias e covariâncias das estimativas, obtidas levando em conta a estrutura do plano amostral utilizado. Para isto, os procedimentos padrões disponíveis adotando hipóteses tais como observações IID não são adequados. Mesmo conhecendo o plano amostral, geralmente não é simples incorporar pesos e plano amostral na análise sem o uso de pacotes especializados, ou de rotinas específicas já agora disponíveis em alguns dos pacotes mais comumente utilizados (por exemplo, SAS, STATA, SPSS, ou R entre outros). Tais pacotes especializados ou rotinas específicas utilizam, em geral, métodos aproximados para estimar matrizes de covariância. Entre esses métodos, destacam-se o de Máxima Pseudo-Verossimilhança, a Linearização de Taylor, o método do Conglomerado Primário e métodos de reamostragem, que são descritos mais adiante. Em outras palavras, o uso dos sistemas e procedimentos padrões de inferência para analisar dados produzidos por pesquisas com planos amostrais complexos, tal como o uso de muitos remédios, pode ter contraindicações. Cabe ao usuário ler a bula e identificar situações em que o uso de tais sistemas pode ser inadequado e buscar opções de rotinas específicas ou de pacotes especializados capazes de incorporar adequadamente a estrutura do plano amostral nas análises. Ao longo deste livro fazemos uso intensivo do pacote survey e outros disponíveis no sistema R, mas o leitor pode encontrar funcionalidade semelhante em alguns outros sistemas. Nossa escolha se deveu a dois fatores principais: primeiro ao fato do sistema R ser aberto, livre e gratuito, dispensando o usuário de custos de licenciamento, bem como possibilitando aos interessados o acesso ao código fonte e à capacidade de modificar as rotinas de análise, caso necessário. O segundo fator é de natureza mais técnica, porém transitória. No presente momento, o pacote survey do R é a coleção de rotinas mais completa e genérica existente para análise de dados amostrais complexos, dispondo de funções capazes de ajustar os modelos usuais, mas também de ajustar modelos não convencionais, mediante a maximização numérica de verossimilhanças especificadas pelo usuário. Sabemos, entretanto, que muitos usuários habituados à facilidade de uso de sistemas com interfaces gráficas do tipo aponte e clique terão dificuldade adicional de adaptar-se à linguagem de comandos utilizada pelo sistema R, mas acreditamos que os benefícios do aprendizado desta nova ferramenta compensarão largamente os custos adicionais do aprendizado. Além disso, a disponibilidade de ambientes como os do RStudio ou similares facilita bastante o uso do R, oferecendo ferramentas que apoio à elaboração, teste e execução de programas para obtenção dos resultados desejados e inclusive sua incorporação a relatórios ou textos. O emprego de ferramentas de análise como o pacote survey permite aos usuários focar sua atenção mais na seleção, análise e interpretação dos modelos ajustados do que nas dificuldades técnicas envolvidas nos cálculos correspondentes. É com este espírito que escrevemos este texto, que busca apresentar os métodos, ilustrando seu uso com exemplos reais e orientando sobre o uso adequado das ferramentas de modelagem e análise disponíveis no sistema R. 2.6 Fontes de variação Esta seção estabelece o referencial para inferência em pesquisas amostrais que é usado no restante deste texto. Cassel et al. (1977) sugerem que um referencial para inferência poderia considerar três fontes de aleatoriedade (incerteza, variação), incluindo: Modelo de Superpopulação, que descreve o processo subjacente que, por hipótese, gera as medidas verdadeiras para todas as unidades da população considerada; Processo de Medição, que diz respeito aos instrumentos e métodos usados para obter as medidas de qualquer unidade da população; Plano Amostral, que estabelece o mecanismo pelo qual unidades da população são selecionadas para participar da amostra da pesquisa ou estudo. Uma quarta fonte de incerteza que precisa ser acrescentada às anteriores é o Mecanismo de resposta, ou seja, o mecanismo que controla se valores de medições de unidades selecionadas para a amostra são obtidos / observados ou não. Para concentrar o foco nas questões de maior interesse deste texto, as fontes (2) e (4) não são consideradas no referencial adotado aqui. O tratamento de erros de medida é explorado em Wayne A. Fuller (1987), e as questões ligadas a não resposta em diversos textos, entre os quais Little e Rubin (2002). Assim sendo, exceto onde explicitamente indicado, de agora em diante admitiremos que não há erros de medição, implicando que os valores observados de quaisquer variáveis de interesse são considerados valores corretos ou verdadeiros. Admitimos ainda que há resposta completa, implicando que os valores de quaisquer variáveis de interesse estão disponíveis para todos os elementos da amostra selecionada depois que a pesquisa foi realizada. Hipóteses semelhantes são adotadas, por exemplo, em Binder (1983) e Montanari (1987). Portanto, o referencial aqui adotado considera apenas duas fontes de variação: o Modelo de Superpopulação (1) e o Plano Amostral (3). Estas fontes de variação, descritas nesta seção apenas de forma esquemática, são discutidas com maiores detalhes a seguir. A fonte de variação (1) é considerada porque usos analíticos das pesquisas são amplamente discutidos neste texto, os quais só têm sentido quando é especificado um modelo estocástico para o processo subjacente que gera as medidas na população. A fonte de variação (3) é considerada porque a atenção é focalizada na análise de dados obtidos através de pesquisas amostrais complexas. Aqui a discussão se restringe a planos amostrais aleatorizados ou de Amostragem Probabilística, não sendo considerados métodos intencionais ou outros métodos não aleatórios algumas vezes usados para seleção de amostras. 2.7 Modelos de Superpopulação Seja \\(\\{1, \\ldots, N\\}\\) um conjunto de rótulos que identificam univocamente os \\(N\\) elementos distintos de uma população-alvo finita \\(U\\). Sem perda de generalidade tomemos \\(U = \\{1, \\ldots, N\\}\\). Uma pesquisa cobrindo \\(n\\) elementos distintos numa amostra \\(s\\), \\(s = \\{i_{1}, \\ldots, i_{n}\\} \\subset U\\), é realizada para medir os valores de \\(Q\\) variáveis de interesse da pesquisa, doravante denominadas simplesmente variáveis da pesquisa. Denotemos por \\(\\mathbf{y}_i = (y_{i1},\\ldots, y_{iQ})^{\\prime }\\) um vetor \\(Q \\times 1\\) de valores das variáveis da pesquisa e por \\(\\mathbf{x}_{i} = (x_{i1}, \\ldots, x_{iA})^{\\prime }\\) um vetor \\(A \\times 1\\) de variáveis auxiliares da \\(i\\)-ésima unidade da população, respectivamente, para \\(i = 1, \\ldots, N\\). Aqui as variáveis auxiliares são consideradas como variáveis contendo a informação requerida para o plano amostral e a estimação a partir da amostra, como se discute com mais detalhes adiante. Denotemos por \\(\\mathbf{y}_{U}\\) a matriz \\(N \\times Q\\) formada empilhando os vetores transpostos das observações das variáveis de pesquisa correspondentes a todas as unidades da população, e por \\(\\mathbf{Y}_{U}\\) a correspondente matriz de vetores aleatórios geradores das observações na população. Quando se supõe que \\(\\mathbf{y}_1 , \\ldots, \\mathbf{y}_N\\) são a realização conjunta de vetores aleatórios \\(\\mathbf{Y}_1, \\ldots, \\mathbf{Y}_N\\), a distribuição conjunta de probabilidade de \\(\\mathbf{Y}_1, \\ldots, \\mathbf{Y}_N\\) é um Modelo de Superpopulação (marginal), que doravante denotaremos simplesmente por \\(f(\\mathbf{y}_U; \\boldsymbol{\\theta})\\), ou de forma abreviada, por \\(M\\). Esperança e variância definidas com respeito à distribuição do modelo \\(M\\) são denotadas \\(E_M\\) e \\(V_M\\) respectivamente. Analogamente, \\(\\mathbf{x}_1, \\ldots, \\mathbf{x}_N\\) pode ser considerada uma realização conjunta de vetores aleatórios \\(\\mathbf{X}_1, \\ldots, \\mathbf{X}_N\\). As matrizes \\(N \\times A\\) formadas empilhando os vetores transpostos das observações das variáveis auxiliares correspondentes a todas as unidades da população, \\(\\mathbf{x}_{U}\\), e a correspondente matriz \\(\\mathbf{X}_{U}\\) de vetores aleatórios geradores das variáveis auxiliares na população são definidas de forma análoga às matrizes \\(\\mathbf{y}_{U}\\) e \\(\\mathbf{Y}_{U}\\). O referencial aqui adotado permite a especificação da distribuição conjunta combinada das variáveis da pesquisa e das variáveis auxiliares. Representamos por \\(f( \\mathbf{y}_U , \\mathbf{x}_U ; \\boldsymbol{\\eta} )\\) a função de densidade de probabilidade conjunta de \\(( \\mathbf{Y}_U , \\mathbf{X}_U )\\), onde \\(\\boldsymbol{\\eta}\\) é um vetor de parâmetros. Um tipo importante de modelo de superpopulação é obtido quando os vetores aleatórios correspondentes às observações de unidades diferentes da população são supostos independentes e identicamente distribuídos - IID. Neste caso, o modelo de superpopulação pode ser escrito como: \\[ \\begin{eqnarray} f \\left( \\mathbf{y}_U , \\mathbf{x}_U ; \\boldsymbol{\\eta} \\right) &amp;=&amp; \\prod_{i\\in U} f\\left(\\mathbf{y}_i , \\mathbf{x}_i ; \\boldsymbol{\\eta} \\right) \\nonumber \\\\ &amp;=&amp; \\prod_{i\\in U} f\\left( \\mathbf{y}_i \\mathbf{|x}_i ; \\boldsymbol{\\lambda} \\right) f\\left( \\mathbf{x}_i ; \\boldsymbol{\\phi} \\right) \\quad \\tag{2.3} \\end{eqnarray} \\] onde \\(\\boldsymbol{\\lambda}\\) e \\(\\boldsymbol{\\phi}\\) são vetores de parâmetros. Sob (2.3), o modelo marginal correspondente das variáveis da pesquisa seria obtido integrando nas variáveis auxiliares: \\[ f(\\mathbf{y}_U ; \\boldsymbol{\\theta}) = f(\\mathbf{y}_1 ,\\ldots ,\\mathbf{y}_N ; \\boldsymbol{\\theta}) = \\prod_{i\\in U} \\int f\\left( \\mathbf{y}_i \\mathbf{|x}_i ; \\boldsymbol{\\lambda} \\right) f\\left( \\mathbf{x}_i ; \\boldsymbol{\\phi} \\right) \\mathbf{dx}_i = \\prod_{i\\in U} f\\left( \\mathbf{y}_i ; \\boldsymbol{\\theta} \\right) \\quad \\tag{2.4} \\] onde \\(f\\left( \\mathbf{y}_i ; \\boldsymbol{\\theta} \\right) = \\int f\\left( \\mathbf{y}_i | \\mathbf{x}_i ; \\boldsymbol{\\lambda} \\right) f\\left( \\mathbf{x}_i ; \\boldsymbol{\\phi} \\right) \\mathbf{dx}_i\\) e \\(\\boldsymbol{\\theta} = h \\left( \\boldsymbol{\\lambda} , \\boldsymbol{\\phi} \\right)\\) é função de \\(\\boldsymbol{\\lambda}\\) e \\(\\boldsymbol{\\phi}\\). Outro tipo especial de modelo de superpopulação é o modelo de população fixa, que supõe que os valores numa população finita são fixos mas desconhecidos. Este modelo pode ser descrito por: \\[ P\\left[ \\left( \\mathbf{Y}_U , \\mathbf{X}_U \\right) = \\left( \\mathbf{y}_U , \\mathbf{x}_U \\right) \\right] = 1 \\quad \\tag{2.5} \\] ou seja, uma distribuição degenerada é especificada para \\(\\left( \\mathbf{Y}_U , \\mathbf{X}_U \\right)\\). Este modelo foi considerado em Cassel et al. (1977), que o chamaram de abordagem de população fixa, e afirmaram ser esta a abordagem subjacente ao desenvolvimento da teoria da Amostragem Probabilística encontrada nos livros clássicos de amostragem, tais como Cochran (1977) e outros. Aqui esta abordagem é chamada de abordagem baseada no plano amostral ou abordagem de aleatorização, pois neste caso a única fonte de variação (aleatoriedade) é proveniente do plano amostral usado para obtenção dos dados. Em geral, a distribuição conjunta de \\(\\left( \\mathbf{Y}_U , \\mathbf{X}_U \\right)\\) não precisa ser degenerada como especificada em (2.5), embora o referencial aqui adotado seja suficientemente geral para permitir considerar esta possibilidade. Se todas as unidades da população \\(U\\) fossem pesquisadas (ou seja, se fosse executado um censo), os dados observados seriam \\((\\mathbf{y}_1 , \\mathbf{x}_1), \\ldots, (\\mathbf{y}_N , \\mathbf{x}_N)\\). Sob a hipótese de resposta completa, a única fonte de incerteza seria devida ao fato de que \\((\\mathbf{y}_1 , \\mathbf{x}_1), \\ldots, (\\mathbf{y}_N , \\mathbf{x}_N)\\) é uma realização de \\(\\left( \\mathbf{Y}_1, \\mathbf{X}_1 \\right), \\ldots, \\left( \\mathbf{Y}_N, \\mathbf{X}_N \\right)\\). Os dados observados poderiam então ser usados para fazer inferências sobre \\(\\boldsymbol{\\eta}, \\boldsymbol{\\phi}, \\boldsymbol{\\lambda}\\) ou \\(\\boldsymbol{\\theta}\\) usando procedimentos padrões. Inferência sobre quaisquer dos parâmetros \\(\\boldsymbol{\\eta}, \\boldsymbol{\\phi}, \\boldsymbol{\\lambda}\\) ou \\(\\boldsymbol{\\theta}\\) do modelo de superpopulação é chamada inferência analítica. Este tipo de inferência só faz sentido quando o modelo de superpopulação não é degenerado como no caso do modelo de população fixa especificado em (2.5). Usualmente seu objetivo é explicar a relação entre variáveis não apenas para a população finita sob análise, mas também para outras populações que poderiam ter sido geradas pelo modelo de superpopulação adotado. Vários exemplos de inferência analítica são discutidos ao longo deste livro. Se o objetivo da inferência é estimar quantidades que fazem sentido somente para a população finita sob análise, tais como funções \\(g\\left( \\mathbf{y}_1, \\ldots, \\mathbf{y}_N \\right)\\) dos valores das variáveis da pesquisa, o modelo de superpopulação não é estritamente necessário, embora possa ser útil. Inferência para tais quantidades, chamadas parâmetros da população finita ou quantidades descritivas populacionais - QDPs - é chamada aqui de inferência descritiva. Vale notar que a especificação aqui proposta para o modelo de superpopulação serve tanto para o caso da abordagem clássica para inferência, como também para o caso da abordagem Bayesiana. Neste caso, a especificação do modelo \\(M\\) precisaria ser complementada mediante a especificação de distribuições a priori para os parâmetros do modelo. 2.8 Plano amostral Embora censos sejam algumas vezes realizados para coletar dados sobre certas populações, a vasta maioria das pesquisas realizadas é de pesquisas amostrais, nas quais apenas uma amostra de elementos da população (usualmente uma pequena parte) é investigada. Neste caso, os dados disponíveis incluem: O conjunto de rótulos \\(s = \\left\\{ i_1 , \\ldots, i_n \\right\\}\\) dos distintos elementos na amostra, onde \\(n\\), \\(1 \\leq n \\leq N\\), é o número de elementos na amostra \\(s\\), também chamado de tamanho da amostra. Os valores na amostra das variáveis da pesquisa \\(\\mathbf{y}_{i_1}, \\ldots, \\mathbf{y}_{i_n}\\). Os valores das variáveis auxiliares na população \\(\\mathbf{x}_1, \\ldots, \\mathbf{x}_N\\), quando a informação auxiliar é dita completa; alternativamente, os valores das variáveis auxiliares na amostra \\(\\mathbf{x}_{i_1}, \\ldots, \\mathbf{x}_{i_n}\\), mais os totais ou médias destas variáveis na população, quando a informação auxiliar é dita parcial. O mecanismo usado para selecionar a amostra \\(s\\) da população finita \\(U\\) é chamado plano amostral. Uma forma de caracterizá-lo é através da função \\(p \\left( . \\right)\\), onde \\(p(s)\\) dá a probabilidade de selecionar a amostra \\(s\\) no conjunto \\(S\\) de todas as amostras possíveis. Só mecanismos amostrais envolvendo alguma forma de seleção probabilística bem definida são aqui considerados. Portanto, supõe-se que \\(0 \\leq p(s) \\leq 1 \\; \\forall \\, s \\in S\\) e \\(\\sum_{s \\in S} p(s) = 1\\). Esta caracterização do plano amostral \\(p(s)\\) é bem geral, permitindo que o mecanismo de seleção amostral dependa dos valores das variáveis auxiliares \\(\\mathbf{x}_1, \\ldots, \\mathbf{x}_N\\) bem como dos valores das variáveis da pesquisa na população \\(\\mathbf{y}_1, \\ldots, \\mathbf{y}_N\\) (amostragem informativa, ver Seção 2.9). Uma notação mais explícita para indicar esta possibilidade envolveria escrever \\(p(s)\\) como \\(p \\left[ s | (\\mathbf{y}_U , \\mathbf{x}_U ) \\right]\\). Tal notação é evitada por razões de simplicidade. Denotamos por \\(I(B)\\) a função indicadora que assume o valor \\(1\\) quando o evento \\(B\\) ocorre e \\(0\\) caso contrário. Seja \\(\\mathbf{\\Delta}_s = \\left[ I(1 \\in s), \\ldots, I(N \\in s) \\right]^{\\prime}\\) um vetor aleatório de indicadores dos elementos incluídos na amostra \\(s\\). Então o plano amostral pode ser alternativamente caracterizado pela distribuição de probabilidade de \\(\\boldsymbol{\\Delta }_s\\) denotada por \\(f\\left[ \\boldsymbol{\\delta}_s | \\left(\\mathbf{y}_U, \\mathbf{x}_U \\right) \\right]\\), onde \\(\\boldsymbol{\\delta}_s\\) é qualquer realização particular de \\(\\boldsymbol{\\Delta}_s\\) tal que \\({\\boldsymbol{\\delta}_s}^{\\prime} \\mathbf{1}_N = n\\), e \\(\\mathbf{1}_N\\) é o vetor unitário de dimensão \\(N\\). Notação adicional necessária nas seções posteriores é agora introduzida. Denotamos por \\(\\pi_i\\) a probabilidade de inclusão da unidade \\(i\\) na amostra \\(s\\), isto é, \\[ \\pi_i = P\\left( i \\in s \\right) = \\sum_{s \\ni i} p(s) \\quad \\tag{2.6} \\] e denotamos por \\(\\pi_{ij}\\) a probabilidade de inclusão conjunta na amostra \\(s\\) das unidades \\(i\\) e \\(j\\), dada por \\[ \\pi_{ij} = P \\left( i \\in s , j \\in s \\right) = \\sum_{s \\ni i,j} p(s) \\quad \\tag{2.7} \\] para todo \\(i \\neq j \\in U\\). Note que \\(\\pi_{ii} = \\pi_{i}\\) \\(\\forall\\, i \\in U.\\) Uma hipótese básica adotada com relação aos planos amostrais aqui considerados é que \\(\\pi_i &gt; 0\\) e \\(\\pi_{ij} &gt; 0\\) \\(\\forall \\, i \\neq j \\in U.\\) A suposição de termos probabilidades de inclusão conjuntas \\(\\pi_{ij}\\) positivas é adotada para simplificar a apresentação de expressões para estimadores de variância dos estimadores dos parâmetros de interesse. Contudo, esta não é uma hipótese crucial, pois há planos amostrais que não a satisfazem e para os quais estão disponíveis aproximações e estimadores satisfatórios das variâncias dos estimadores de totais e de médias. 2.9 Planos amostrais informativos e ignoráveis Ao fazer inferência usando dados de pesquisas amostrais precisamos distinguir duas situações que requerem tratamentos diferentes. Uma dessas situações ocorre quando o plano amostral empregado para coletar os dados é informativo, isto é, quando o mecanismo de seleção das unidades amostrais pode depender dos valores das variáveis de pesquisa. Um exemplo típico desta situação é o dos estudos de caso-controle, em que a amostra é selecionada de tal forma que há casos (unidades com determinada condição) e controles (unidades sem essa condição), sendo de interesse a modelagem do indicador de presença ou ausência da condição em função de variáveis preditoras, sendo esse indicador uma das variáveis de pesquisa, que por sua vez é considerada no mecanismo de seleção da amostra. Os métodos que discutimos ao longo deste livro não são adequados, em geral, para esse tipo de situação e, portanto, uma hipótese fundamental adotada ao longo deste texto é que os planos amostrais considerados são não informativos, isto é, não podem depender diretamente dos valores das variáveis da pesquisa. Logo eles satisfazem: \\[ f\\left[ \\boldsymbol{\\delta }_s | \\left( \\mathbf{y}_U , \\mathbf{x}_U \\right) \\right] = f\\left( \\boldsymbol{\\delta }_s | \\mathbf{x}_U \\right) \\quad\\tag{2.8} \\] Entre os planos amostrais não informativos, precisamos ainda distinguir duas outras situações de interesse. Quando o plano amostral é Amostragem Aleatória Simples Com Reposição - AASC - o modelo adotado para a amostra é o mesmo que o modelo adotado para a população antes da amostragem. Quando isto ocorre, o plano amostral é dito ignorável, porque a inferência baseada na amostra utilizando a abordagem de Modelagem Clássica descrita na Seção 2.2 pode prosseguir sem problemas. Entretanto, esquemas amostrais desse tipo são raramente empregados na prática, por razões de eficiência e custo. Em vez disso, são geralmente empregados planos amostrais envolvendo estratificação, conglomeração e probabilidades desiguais de seleção (amostragem complexa). Com amostragem complexa, porém, os modelos para a população e a amostra podem ser muito diferentes (plano amostral não ignorável), mesmo que o mecanismo de seleção não dependa das variáveis de pesquisa, mas somente das variáveis auxiliares. Neste caso, ignorar o plano amostral pode viciar a inferência. Ver o Exemplo 2.3 adiante. A definição precisa de ignorabilidade e as condições sob as quais um plano amostral é ignorável para inferência são bastante discutidas na literatura - ver por exemplo Sugden e Smith (1984) ou os Capítulos 1 e 2 de Chambers e Skinner (2003). Porém, testar a ignorabilidade do plano amostral é muitas vezes complicado. Em caso de dificuldade, o uso dos pesos amostrais tem papel fundamental, como se verá mais adiante. Uma forma simples de lidar com os efeitos do plano amostral na estimação pontual de quantidades descritivas populacionais de interesse é incorporar pesos adequados na análise, como pode ser visto em P. L. N. Silva et al. (2020) e no Capítulo 3. Essa forma porém, não resolve por si só o problema de estimação da precisão das estimativas pontuais, nem mesmo o caso da estimação pontual de parâmetros em modelos de superpopulação, o que vai requerer métodos específicos discutidos no Capítulo ??. Como incluir os pesos para proteger contra planos amostrais não ignoráveis e a possibilidade de má especificação do modelo? Uma ideia é modificar os estimadores dos parâmetros de modo que sejam consistentes (em termos da distribuição de aleatorização) para quantidades descritivas da população finita da qual a amostra foi extraída, que por sua vez seriam boas aproximações para os parâmetros dos modelos de interesse. Afirmações probabilísticas são então feitas com respeito à distribuição de aleatorização \\(p\\) das estatísticas amostrais ou com respeito à distribuição mista ou combinada \\(Mp\\). A seguir apresentamos um exemplo com a finalidade de ilustrar uma situação de plano amostral não ignorável. Exemplo 2.3 Efeito da amostragem estratificada simples com alocação desproporcional Considere \\(N\\) observações de uma população finita \\(U\\) onde são consideradas de interesse duas variáveis binárias \\((x_i ; y_i )\\). Suponha que na população os vetores aleatórios \\((X_i ; Y_i )\\) são independentes e identicamente distribuídos com distribuição de probabilidades conjunta dada por: Tabela 2.4: \\(\\text{Distribuição de probabilidades conjunta na população }P( Y_i = y ; X_i = x )\\) \\(x \\downarrow \\text{ | } y \\rightarrow\\) 0 1 Total 0 \\(\\eta_{00}\\) \\(\\eta_{01}\\) \\(\\eta_{0+}\\) 1 \\(\\eta_{10}\\) \\(\\eta_{11}\\) \\(\\eta_{1+}\\) Total \\(\\eta_{+0}\\) \\(\\eta_{+1}\\) 1 que também pode ser representada por: \\[ \\begin{eqnarray} f_U (x ; y) &amp;=&amp; P( X = x ; Y = y )\\nonumber\\\\ &amp; =&amp; \\eta_{00}^{(1-x)(1-y)} \\times \\eta_{01}^{(1-x)y} \\times \\eta_{10}^{x(1-y)} \\times (1 - \\eta_{00} - \\eta_{01} - \\eta_{10})^{xy} \\nonumber \\end{eqnarray} \\] onde a designação \\(f_U\\) é utilizada para denotar a distribuição na população. Note agora que a distribuição marginal da variável \\(Y\\) na população é Bernoulli com parâmetro \\(1 - \\eta_{00} - \\eta_{10}\\), ou alternativamente: \\[ f_U (y) = P( Y = y ) = (\\eta_{00} + \\eta_{10})^{(1-y)} \\times (1 - \\eta_{00} - \\eta_{10})^y \\nonumber \\] De forma análoga, a distribuição marginal da variável \\(X\\) na população também é Bernoulli, mas com parâmetro \\(1 - \\eta_{00} - \\eta_{01}\\), ou alternativamente: \\[ f_U (x) = P( X = x ) = (\\eta_{00} + \\eta_{01})^{(1-x)} \\times (1 - \\eta_{00} - \\eta_{01})^x \\nonumber \\] Seja \\(N_{xy}\\) o número de unidades na população com a combinação de valores observados \\((x;y)\\), onde \\(x\\) e \\(y\\) tomam valores em \\(\\Omega = \\{ 0 ; 1 \\}\\). É fácil notar então que o vetor de contagens populacionais \\(\\mathbf{N} = ( N_{00}, N_{01}, N_{10}, N_{11} )^{\\prime}\\) tem distribuição Multinomial com parâmetros \\(N\\) e \\(\\boldsymbol{\\eta} = (\\eta_{00} , \\eta_{01} , \\eta_{10} , 1 - \\eta_{00} - \\eta_{01} - \\eta_{10} )^{\\prime}\\). Após observada uma realização do modelo que dê origem a uma população, como seria o caso da realização de um censo na população, a proporção de valores de \\(y\\) iguais a \\(1\\) observada no censo seria dada por \\(N_{+1} / N = 1 - (N_{00} - N_{10})/N\\). E a proporção de valores de \\(x\\) iguais a \\(1\\) na população seria igual a \\(N_{1+} / N = 1 - (N_{00} - N_{01})/N\\). Agora suponha que uma amostra estratificada simples com reposição de tamanho \\(n\\) inteiro e par seja selecionada da população, onde os estratos são definidos com base nos valores da variável \\(x\\), e onde a alocação da amostra nos estratos é dada por \\(n_0 = n_1 = n/2\\), sendo \\(n_x\\) o tamanho da amostra no estrato correspondente ao valor \\(x\\) usado como índice. Esta alocação é dita alocação igual, pois o tamanho total da amostra é repartido em partes iguais entre os estratos definidos para seleção e, no caso, há apenas dois estratos. A alocação desta amostra é desproporcional exceto no caso em que \\(N_{0+} = N_{1+}\\). Nosso interesse aqui é ilustrar o efeito que uma alocação desproporcional pode causar na análise dos dados amostrais, caso não sejam levadas em conta na análise informações relevantes sobre a estrutura do plano amostral. Para isto, vamos precisar obter a distribuição amostral da variável de interesse \\(Y\\). Isto pode ser feito em dois passos. Primeiro, note que a distribuição condicional de \\(Y\\) dado \\(X\\) na população é dada por: Tabela 2.5: \\(\\text{Distribuição de probabilidades condicional de }y\\text{ dado }x \\text{ na população - }P( Y_i = y | X_i = x )\\) \\(x \\downarrow \\text{ | } y \\rightarrow\\) 0 1 Total 0 \\(\\eta_{00}/\\eta_{0+}\\) \\(\\eta_{01}/\\eta_{0+}\\) 1 1 \\(\\eta_{10}/\\eta_{1+}\\) \\(\\eta_{11}/\\eta_{1+}\\) 1 ou, alternativamente \\[ \\begin{eqnarray} f_U (y | x) &amp;=&amp; P( Y = y | X = x )\\nonumber\\\\ &amp; =&amp; (1-x) \\times \\frac{\\eta_{00}^{(1-y)} \\eta_{01}^y} {\\eta_{00}+\\eta_{01}} + x \\times \\frac{\\eta_{10}^{(1-y)} (1 - \\eta_{00} - \\eta_{01} - \\eta_{10})^y} {1 - \\eta_{00} - \\eta_{01}}\\nonumber \\end{eqnarray} \\] Dado o plano amostral acima descrito, a distribuição marginal de \\(X\\) na amostra é Bernoulli com parâmetro \\(1/2\\). Isto segue devido ao fato de que a amostra foi alocada igualmente com base nos valores de \\(x\\) na população e, portanto, sempre teremos metade da amostra com valores de \\(x\\) iguais a \\(0\\) e metade com valores iguais a \\(1\\). Isto pode ser representado como: \\[ f_s (x) = P( X_i = x | i \\in s ) = 1 / 2,\\; \\forall x \\in \\Omega \\mbox{ e } \\forall i \\in U \\nonumber \\] onde a designação \\(f_s\\) é utilizada para denotar a distribuição na amostra. Podemos usar a informação sobre a distribuição condicional de \\(Y\\) dado \\(X\\) na população e a informação sobre a distribuição marginal de \\(X\\) na amostra para obter a distribuição marginal de \\(Y\\) na amostra, que é dada por: \\[ \\begin{eqnarray} f_s (y) &amp;= &amp;P( Y_i = y | i \\in s ) \\nonumber\\\\ &amp;=&amp; \\sum _{x = 0} ^{1} P( X_i = x ; Y_i = y | i \\in s) \\nonumber \\\\ &amp;=&amp; \\sum _{x = 0} ^{1} P[ Y_i = y | (X_i = x) e (i \\in s)] \\times P( X_i = x | i \\in s) \\nonumber\\\\ &amp;=&amp; \\sum _{x = 0} ^{1} P( Y_i = y | X_i = x) \\times f_s (x) \\nonumber \\\\ &amp;=&amp; \\sum _{x = 0} ^{1} f_U ( y | x) f_s (x) \\nonumber \\\\ &amp;=&amp; \\frac{1}{2} \\times \\left[ \\frac{\\eta_{00}^{(1-y)} \\eta_{01}^y} {\\eta_{00}+\\eta_{01}}+ \\frac{\\eta_{10}^{(1-y)} (1 - \\eta_{00} - \\eta_{01} - \\eta_{10})^y} {1 - \\eta_{00} - \\eta_{01}} \\right] \\nonumber \\end{eqnarray} \\] Isto mostra que a distribuição marginal de \\(Y\\) na amostra é diferente da distribuição marginal de \\(Y\\) na população, mesmo quando o plano amostral é especialmente simples e utiliza amostragem aleatória simples com reposição dentro de cada estrato definido pela variável \\(X\\). Isto ocorre devido à alocação desproporcional da amostra, apesar de a distribuição condicional de \\(Y\\) dado \\(X\\) na população ser a mesma que a distribuição condicional de \\(Y\\) dado \\(X\\) na amostra. Um exemplo numérico facilita a compreensão. Se a distribuição conjunta de \\(X\\) e \\(Y\\) na população é dada por: Tabela 2.6: \\(\\text{Distribuição de probabilidades conjunta na população }f_U( x ; y )\\) \\(x \\downarrow \\text{ | } y \\rightarrow\\) 0 1 Total 0 0,7 0,1 0,8 1 0,1 0,1 0,2 Total 0,8 0,2 1 segue-se que a distribuição condicional de \\(Y\\) dado \\(X\\) na população (e também na amostra) é dada por Tabela 2.7: \\(\\text{Distribuição de probabilidades condicional de }Y\\text{ dado }X\\text{ na população - }f_U( y | x )\\) \\(x \\downarrow \\text{ | } y \\rightarrow\\) 0 1 Total 0 0,875 0,125 1 1 0,500 0,500 1 e que a distribuição marginal de \\(Y\\) na população e na amostra são dadas por Tabela 2.8: \\(\\text{Distribuição de probabilidades marginal de }Y\\text{ na população e na amostra - } f_U(y)\\text{ e } f_s(y)\\) \\(y\\) 0 1 \\(f_U(y)\\) 0,8000 0,2000 \\(f_s(y)\\) 0,6875 0,3125 Assim, inferência sobre a distribuição de \\(Y\\) na população levada a cabo a partir dos dados da amostra observada sem considerar a estrutura do plano amostral seria equivocada, pois a alocação igual da amostra nos estratos levaria à observação de uma proporção maior de valores de \\(X\\) iguais a 1 na amostra (1/2) do que a correspondente proporção existente na população (1/5). Em consequência, a proporção de valores de \\(Y\\) iguais a 1 na amostra (0,3125) seria 56% maior que a correspondente proporção na população (0,2). Este exemplo é propositalmente simples, envolve apenas duas variáveis com distribuição Bernoulli, mas ilustra bem como a amostragem pode modificar distribuições de variáveis na amostra em relação à correspondente distribuição na população. Isto ocorre mesmo em situações em que a amostragem não é informativa (pois a seleção da amostra não depende dos valores da variável \\(y\\)), mas onde o plano amostral não é ignorável para inferência sobre a distribuição marginal de \\(Y\\). Caso a inferência requerida fosse sobre parâmetros da distribuição condicional de \\(Y\\) dado \\(X\\), a amostragem seria ignorável, isto é, \\(f_s ( y | x) = f_U (y | x)\\). Assim, fica evidenciado também que a questão de saber se o plano amostral pode ou não ser ignorado depende da inferência desejada. No nosso exemplo, o plano amostral seria ignorável para inferência sobre a distribuição condicional de \\(Y\\) dado \\(X\\), mas não seria ignorável para inferência sobre a distribuição marginal de \\(Y\\). Feita esta discussão sobre o referencial para inferência que adotamos neste livro, no próximo capítulo apresentamos uma revisão rápida dos métodos de estimação da amostragem probabilística. Como já indicado, o leitor interessado numa discussão mais detalhada pode consultar P. L. N. Silva et al. (2020). "],["capplanamo.html", "Capítulo 3 Estimação Baseada no Plano Amostral 3.1 Estimação de totais 3.2 Estimação de variâncias - motivação 3.3 Linearização de Taylor (ou Delta) para estimar variâncias 3.4 Equações de estimação 3.5 Método do Conglomerado Primário 3.6 Métodos de replicação 3.7 Laboratório de R", " Capítulo 3 Estimação Baseada no Plano Amostral 3.1 Estimação de totais Devido a sua importância para os desenvolvimentos teóricos em vários dos capítulos subsequentes, alguns resultados básicos relativos à estimação de totais da população finita numa abordagem baseada no plano amostral são relembrados nesta seção. A referência básica usada foi a Seção 2.8 de Särndal et al. (1992). O leitor pode também consultar o Capítulo 3 de P. L. N. Silva et al. (2020). Consideremos o problema de estimar o vetor \\(\\mathbf{Y} = \\sum_{i \\in U} \\mathbf{y}_i\\) de totais das \\(Q\\) variáveis da pesquisa na população, a partir de uma amostra observada \\(s\\). Naturalmente, qualquer estimador viável do total \\(\\mathbf{Y}\\) só pode depender dos valores das variáveis de pesquisa observados na amostra, contidos em \\(\\mathbf{y}_{i_{1}}, \\ldots , \\mathbf{y}_{i_{n}}\\), mas não dos valores dessas variáveis para os elementos não pesquisados (\\(i \\in U-s\\)). Um estimador usual baseado no plano amostral para o total \\(\\mathbf{Y}\\) é o estimador de Horvitz-Thompson (ver Capítulo 2 deste livro e Seção 3.7 de P. L. N. Silva et al. (2020)), dado por: \\[ \\widehat{\\mathbf{Y}}_{HT} = \\sum_{i \\in s} \\mathbf{y}_i / \\pi_{i} = \\sum_{i \\in s} d_i \\mathbf{y}_i \\,\\, \\tag{3.1} \\] onde \\(d_i = 1/\\pi_i\\) é o peso básico da unidade \\(i\\). Na abordagem baseada no planejamento amostral, as propriedades de uma estatística ou estimador são avaliadas com respeito a sua distribuição de aleatorização. Denotemos por \\(E_p(.)\\) e \\(V_p(.)\\) os operadores de esperança e variância referentes à distribuição de probabilidades induzida pelo planejamento amostral \\(p(s)\\), que chamaremos daqui por diante de esperança de aleatorização e variância de aleatorização. O estimador \\(\\mathbf{\\widehat{Y}}_{HT}\\) é não viciado para o total \\(\\mathbf{Y}\\) com respeito à distribuição de aleatorização, isto é: \\[ E_p \\left( \\mathbf{\\widehat{Y}}_{HT} \\right) = \\mathbf{Y} \\] Além disto, sua variância de aleatorização é dada por \\[ V_p \\left( \\mathbf{\\widehat{Y}}_{HT} \\right) = \\sum_{i \\in U} \\sum_{j \\in U} \\left( \\frac{d_i d_j}{d_{ij}} - 1 \\right) \\mathbf{y}_i {\\mathbf{y}^\\prime_j} \\,\\,\\, \\tag{3.2} \\] Um estimador não viciado para a variância de aleatorização de \\(\\mathbf{ \\widehat{Y}}_{HT}\\) é dado por: \\[ \\widehat V_p \\left( \\mathbf{\\widehat{Y}}_{HT} \\right) =\\sum_{i \\in s} \\sum_{j \\in s} \\left( {d_i d_j} - d_{ij} \\right) \\mathbf{y}_i {\\mathbf{y}^\\prime_j} \\,\\,\\, \\tag{3.3} \\] O estimador de variância em (3.3) é um estimador não viciado da variância de aleatorização de \\(\\mathbf{\\widehat{Y}}_{HT}\\), isto é \\[ E_p \\left[ \\widehat V_p \\left( \\mathbf{\\widehat{Y}}_{HT} \\right) \\right] = V_p \\left( \\mathbf{\\widehat{Y}}_{HT} \\right) \\,\\,\\, \\tag{3.4} \\] desde que \\(\\pi_{ij} &gt; 0 \\quad \\forall\\,\\, i \\neq j \\in U\\), como vamos supor neste livro. Exemplo 3.1 Amostragem Aleatória Simples Sem Reposição - AAS Quando o plano amostral empregado num levantamento é amostragem aleatória simples sem reposição - AAS, as expressões apresentadas para o estimador de total, sua variância e estimadores desta variância simplificam bastante, porque as probabilidades de inclusão e os pesos básicos das unidades ficam iguais a \\[ \\pi_i = \\frac{n}{N}\\,\\text{ e }\\, d_i = \\frac{N}{n} \\, \\,\\, \\forall \\,\\,i \\in U \\,\\, \\tag{3.5} \\] e \\[ \\pi_{ij} = \\frac{n(n-1)}{N(N-1)} \\,\\, \\,\\,\\,\\text{e} \\,\\, d_{ij} = \\frac{N(N-1)}{n(n-1)} \\,\\,\\, \\forall \\, i \\neq j \\in U \\,\\, \\tag{3.6} \\] Essas probabilidades de inclusão e pesos básicos levam às seguintes expressões simplificadas para o caso AAS: \\[ \\widehat{\\mathbf{Y}}_{AAS} = \\frac{N}{n} \\sum_{i \\in s} \\mathbf{y}_i = N \\, \\overline{\\mathbf{y}} \\,\\, \\tag{3.7} \\] onde \\[ \\overline{\\mathbf{y}} = \\frac{1}{n} \\sum_{i \\in s} \\mathbf{y}_i \\,\\, \\tag{3.8} \\] \\[ V_{AAS} \\left( \\mathbf{\\widehat{Y}}_{AAS} \\right) = N^{2} \\left( \\frac{1}{n} - \\frac{1}{N} \\right) \\mathbf{S}_y \\,\\, \\tag{3.9} \\] onde \\[ \\mathbf{S}_y = \\frac{1}{N-1} \\sum_{i \\in U} \\left( \\mathbf{y}_i - \\overline{ \\mathbf{Y}} \\right) \\left( \\mathbf{y}_i - \\overline{\\mathbf{Y}} \\right) ^{^{\\prime }} \\tag{3.10} \\] \\[ \\overline{\\mathbf{Y}} = \\frac{1}{N} \\sum_{i \\in U} \\mathbf{y}_i = \\frac{1}{N} \\mathbf{Y} \\,\\,\\, \\tag{3.11} \\] Sob AAS, o estimador da variância do estimador de total simplifica para: \\[ \\widehat{V}_{AAS} \\left( \\mathbf{\\widehat{Y}}_{AAS} \\right) = N^{2} \\left( \\frac{1}{n} - \\frac{1}{N} \\right) \\mathbf{\\widehat S}_y \\,\\, \\tag{3.12} \\] onde \\[ \\widehat{\\mathbf{S}}_y = \\frac{1}{n-1} \\sum_{i \\in s} \\left( \\mathbf{y}_i - \\overline{\\mathbf{y}} \\right) \\left( \\mathbf{y}_i - \\overline{\\mathbf{y}} \\right) ^{^{\\prime }} \\,\\,\\, \\tag{3.13} \\] Vários outros estimadores de totais estão disponíveis na literatura de amostragem, porém os que são comumente usados na prática são estimadores ponderados (lineares) da forma \\[ \\mathbf{\\widehat{Y}}_w = \\sum\\limits_{i \\in s} w_i \\mathbf{y}_i \\,\\,\\, \\tag{3.14} \\] onde \\(w_i\\) é um peso associado à unidade \\(i\\) da amostra (\\(i \\in s\\)). O estimador de Horvitz-Thompson é um caso particular de \\(\\mathbf{\\widehat{Y}}_w\\) em (3.14) quando os pesos \\(w_i\\) são da forma \\[ w_i^{HT} = d_i = 1 / \\pi_i \\quad \\forall \\ i \\in s. \\] Outros dois estimadores de totais comumente usados pelos praticantes de amostragem são o estimador de razão simples \\(\\mathbf{\\widehat{Y}}_R\\) e o estimador de regressão simples \\(\\mathbf{\\widehat{Y}}_{REG}\\), dados respectivamente por \\[ \\mathbf{\\widehat{Y}}_R = \\sum_{i \\in s} {w_i^{R} \\ } \\mathbf{y}_i \\,\\,\\, \\tag{3.15} \\] com \\[ w_i^{R} = d_i \\times \\frac{\\sum_{i \\in U} x_i } {\\sum_{i \\in s} {d_i \\ } x_i} = d_i \\times \\frac{X}{\\widehat{X}_{HT}} \\,\\,\\, \\tag{3.16} \\] e \\[ \\mathbf{\\widehat{Y}}_{REG} = \\sum_{i \\in s} {w_i^{REG} \\ } \\mathbf{y}_i \\,\\,\\, \\tag{3.17} \\] onde \\[ w_i^{REG} = d_i \\times g_i \\,\\,\\, \\tag{3.18} \\] sendo \\[ g_{i} = 1 + x_{i \\mbox{ }} (X - \\widehat{X}_{HT}) / \\sum_{i \\in s} d_i x_i^2 \\] O fator multiplicativo de ajuste de regressão \\(g_i\\) depende de conhecermos o total populacional \\(\\sum_{i \\in U} x_i = X\\) de uma variável auxiliar \\(x\\), e do estimador tipo Horvitz-Thompson para esse total dado por \\(\\widehat{X}_{HT} = \\sum_{i \\in s} d_i \\, x_i\\). O estimador de regressão descrito em (3.17) é um caso particular do estimador de regressão generalizado, obtido quando se consideram vetores de variáveis auxiliares em vez de uma única variável auxiliar \\(x\\) como aqui. Para uma discussão detalhada do estimador de regressão generalizado ver o Capítulo 3 de P. L. N. Silva (1996), ou o excelente livro de Särndal et al. (1992). Por sua vez, o estimador de regressão generalizado é caso particular da família mais ampla dos estimadores de calibração, definidos por Deville e Särndal (1992). Mais informações sobre esta família de estimadores no Capítulo 13 de P. L. N. Silva et al. (2020). Para completar a descrição dos procedimentos de inferência para médias e totais baseados em estimadores ponderados do tipo razão ou regressão, é necessário identificar estimadores para as variâncias de aleatorização correspondentes. Entretanto, os estimadores de razão e regressão são viciados sob a distribuição de aleatorização para pequenas amostras. Em ambos os casos, o vício é desprezível para amostras grandes, e estão disponíveis expressões assintóticas para as respectivas variâncias de aleatorização. Partindo destas expressões foram então construídos estimadores amostrais das variâncias dos estimadores de razão e regressão, que podem ser encontrados na excelente revisão sobre o tema contida em Särndal et al. (1992), Seção 6.6 e Capítulo 7. Apesar de sua importância para os praticantes de amostragem, a discussão detalhada desse problema não está incluída neste livro. O problema da estimação das variâncias de aleatorização para estimadores como os de razão e regressão nos remete a uma questão central da teoria da amostragem. Trata-se dos métodos disponíveis para estimar variâncias de estimadores complexos. O caso dos estimadores de razão e regressão para totais e médias foi resolvido faz tempo, e não há muito o que discutir aqui. Entretanto, a variedade de métodos empregados para estimação de variâncias merece uma discussão em separado, pois as técnicas de ajuste consideradas neste livro para incorporar pesos e plano amostral na inferência partindo de dados de pesquisas amostrais complexas depende em grande medida da aplicação de tais técnicas. 3.2 Estimação de variâncias - motivação Em Amostragem, como de resto na Estatística Clássica, a estimação de variâncias é um componente essencial da abordagem inferencial adotada: sem estimativas de variância, nenhuma indicação da precisão (e, portanto, da qualidade) das estimativas de interesse está disponível. Nesse caso, uma tentação que assola muitos usuários incautos é esquecer que os resultados são baseados apenas em dados de uma amostra da população e, portanto, sujeitos a incerteza, que não pode ser quantificada sem medidas de precisão amostral. Em geral, a obtenção de estimativas de variâncias (alternativamente, de desvios padrões ou mesmo de coeficientes de variação) é requerida para que intervalos de confiança possam ser calculados, e outras formas de inferência realizadas. Intervalos de confiança elaborados com estimativas amostrais são geralmente baseados em aproximações assintóticas da distribuição amostral do estimador pela distribuição normal, usando resultados análogos ao TCL para populações finitas - ver Wayne A. Fuller (2009), tais que intervalos da forma \\[ IC\\left[ \\widehat{\\theta } ; 1-\\alpha \\right] =\\left[ \\,\\, \\widehat{\\theta } \\mp z_{\\alpha /2}\\sqrt{\\widehat{V}_{p} \\left( \\widehat{\\theta} \\right) } \\,\\, \\right] \\] têm probabilidade de cobertura aproximada \\(1-\\alpha\\), com \\(z_{\\alpha /2}\\) sendo o quantil que deixa área de \\(1-\\alpha/2\\) à sua esquerda na distribuição Normal padrão. Estimativas de variância podem ser úteis também para outras finalidades, tais como a detecção de problemas não antecipados, tais como observações suspeitas, celas raras em tabelas de contingência, etc. A estimação de variâncias para os casos padrões de amostragem, isto é, quando os estimadores são lineares nas observações amostrais, não viciados e todas as probabilidades de inclusão conjuntas são não nulas, é tratada em todos os livros de amostragem convencionais. Apesar disso, os pacotes estatísticos usuais, tais como SAS, SPSS, MINITAB e outros, por muito tempo não ofereciam rotinas prontas para estimar variâncias considerando o plano amostral, nem mesmo para estatísticas simples como estimadores de totais e médias. Felizmente tal situação mudou, e agora já é possível contar com ferramentas no SAS (procedimentos survey), no SPSS (módulo Complex Samples) e no STATA (funções svy). Mas, a nosso ver, é no pacote survey do sistema R que estão disponíveis as melhores ferramentas para estimação de parâmetros a partir de dados de amostras complexas. Para alguns planos amostrais utilizados na prática, as probabilidades de inclusão conjuntas podem ser nulas (caso de amostragem sistemática) ou difíceis de calcular (caso de alguns esquemas de seleção com probabilidades desiguais). Nesses casos, as expressões fornecidas na Seção 3.1 para os estimadores das variâncias dos estimadores de totais não são mais adequadas. Em muitos outros casos, como se vê no restante deste livro, os parâmetros de interesse são não lineares (diferentes de totais, médias e proporções, por exemplo). Casos comuns que consideremos mais adiante são a estimação de razões, coeficientes de modelos de regressão etc. Nesses casos é comum que as estatísticas empregadas para estimar tais parâmetros também sejam não lineares. Finalmente, alguns estimadores de variância podem, em alguns casos, produzir estimativas negativas da variância, que são inaceitáveis de um ponto de vista prático (tais como o estimador da expressão (3.3) para alguns esquemas de seleção com probabilidades desiguais e determinadas configurações peculiares da amostra). Em todos esses casos, é requerido o emprego de técnicas especiais de estimação de variância. É de algumas dessas técnicas que tratam as seções seguintes deste capítulo. A seleção das técnicas discutidas aqui não é exaustiva, e um tratamento mais completo e aprofundado da questão pode ser encontrado no livro de Wolter (2007). Discutimos inicialmente a técnica de Linearização de Taylor, em seguida uma abordagem comumente adotada para estimar variâncias para planos amostrais estratificados e conglomerados em vários estágios, com seleção de unidades primárias com probabilidades desiguais, denominada Método do Conglomerado Primário (do inglês Ultimate Cluster). Por último, tratamos brevemente de uma técnica baseada na ideia de pseudo replicações da amostra, denominada Bootstrap. A combinação dessas três idéias suporta os desenvolvimentos teóricos dos algoritmos empregados pelo pacote survey do sistema R para estimação de variâncias - ver Lumley (2006) e Lumley (2010). 3.3 Linearização de Taylor (ou Delta) para estimar variâncias Um problema que ocorre frequentemente é o de estimar um vetor de parâmetros \\(\\mathbf{\\theta} = \\left( \\theta _{1},\\ldots ,\\theta_{K}\\right)\\) de uma população finita \\(U\\), que pode ser escrito na forma: \\[ \\mathbf{\\theta} = \\mathbf{g}(\\mathbf{Y}) \\] onde \\(\\mathbf{Y} = \\sum_{i \\in U} \\mathbf{y}_i\\) é o vetor de totais de \\(Q\\) variáveis de pesquisa. Poderíamos usar como estimador para o vetor de parâmetros \\(\\theta\\) o estimador \\(\\mathbf{\\widehat{\\theta}}\\) dado por: \\[ \\mathbf{\\widehat{\\theta}} = \\mathbf{g} \\left( \\widehat{ \\mathbf{Y}}_{HT} \\right) = \\mathbf{g} \\left(\\sum_{i \\in s} \\, d_i \\, \\mathbf{y}_{i} \\right) \\] No caso particular em que \\(\\mathbf{g}(\\bullet)\\) é uma função linear dos totais das variáveis de pesquisa, isto é: \\[ \\mathbf{\\theta} = \\mathbf{A Y} \\] onde \\(\\mathbf{A}\\) é uma matriz de constantes de dimensão \\(K \\times Q\\), o estimador \\(\\mathbf{\\widehat{\\theta}}\\) de \\(\\mathbf{\\theta}\\) neste caso seria \\[ \\mathbf{\\widehat{\\theta}} = \\mathbf{A \\widehat{Y}}_{HT} \\, \\] Nesse caso particular, é fácil estudar as propriedades do estimador \\(\\mathbf{\\widehat{\\theta}}\\). Este estimador é não viciado e tem variância de aleatorização dada por: \\[ V_{p}\\left( \\mathbf{\\widehat{\\theta}} \\right) = \\mathbf{A} \\left[ V_{p} \\left( \\mathbf{\\widehat{Y}}_{HT} \\right) \\right] \\mathbf{A}^{^{\\prime }} \\,\\, \\] onde \\(V_{p} \\left( \\mathbf{\\widehat{Y}}_{HT}\\right)\\) é dado em (3.2). Quando \\(\\mathbf{g}(\\bullet)\\) é uma função não linear, podemos usar a técnica de Linearização de Taylor (ou Método Delta) para obter aproximações assintóticas para a variância de \\(\\mathbf{ \\widehat{\\theta}} = \\mathbf{g} \\left( \\widehat{\\mathbf{Y}}_{HT}\\right)\\). Para maiores detalhes sobre esse método, ver por exemplo página 172 de Särndal et al. (1992) ou página 486 de Bishop et al. (1975). Vamos considerar a expansão de \\(\\mathbf{g} \\left( \\mathbf{\\widehat{Y}}_{HT} \\right)\\) em torno de \\(\\mathbf{Y}\\), até o termo de primeira ordem, desprezando o resto, dada por: \\[ \\mathbf{\\widehat{\\theta} \\doteq \\widehat{\\theta}}_{L} = \\mathbf{g(Y) + \\Delta g(Y)} \\left( \\mathbf{\\widehat{Y}}_{HT} - \\mathbf{Y} \\right) \\,\\,\\, \\tag{3.19} \\] onde \\(\\mathbf{\\Delta g(Y)}\\) é a matriz Jacobiana \\(K \\times Q\\) cuja \\(q\\)-ésima coluna é \\(\\mathbf{\\partial g(Y)/}\\partial Y_{q}\\), para \\(q=1,\\ldots, Q\\). A ideia básica do método de linearização é aproximar a variância do estimador \\(\\mathbf{\\widehat{\\theta}}\\) pela variância do estimador linearizado \\(\\mathbf{\\widehat{\\theta}}_L\\) dado pelo lado direito da expressão (3.19). Para obter a variância do estimador linearizado, note que \\(\\mathbf{g(Y)}\\) é uma constante, e que \\[ \\begin{array}{lll} \\mathbf{\\Delta g(Y)} \\left( \\mathbf{\\widehat{Y}}_{HT} - \\mathbf{Y} \\right) &amp; = &amp; \\mathbf{\\Delta g(Y)} \\mathbf{\\widehat{Y}}_{HT} - \\mathbf{\\Delta g(Y)} \\mathbf{Y} \\\\ &amp; = &amp; \\sum_{i \\in s} \\, d_i \\, \\mathbf{\\Delta g(Y)} \\mathbf{y}_{i} - \\sum_{i \\in U} \\, \\mathbf{\\Delta g(Y)} \\mathbf{y}_{i} \\\\ &amp; = &amp; \\sum_{i \\in s} \\, d_i \\, \\mathbf{z}_{i} - \\sum_{i \\in U} \\, \\mathbf{z}_{i} = \\mathbf{\\widehat{Z}}_{HT} - \\mathbf{Z} \\end{array} \\] onde \\(\\mathbf{z}_{i} = \\mathbf{\\Delta g(Y)} \\mathbf{y}_{i}\\). Logo, a variância aproximada por linearização do estimador \\(\\widehat{\\theta}\\) pode ser obtida usando a expressão (3.2) \\[ V_p \\left( \\widehat{\\theta} \\right) \\doteq V_p \\left( \\mathbf{\\widehat{Z}}_{HT} \\right) \\] Este resultado segue porque na expressão do lado direito o único termo que tem variância de aleatorização é \\(\\mathbf{\\widehat{Z}}_{HT}\\). Um estimador consistente de \\(V_{p} \\left( \\mathbf{\\widehat{\\theta}}\\right)\\) é dado por: \\[ \\widehat{V}_{p} \\left( \\mathbf{\\widehat{\\theta}} \\right) = \\widehat{V}_{p} \\left( \\mathbf{\\widehat{Z}}_{HT} \\right) \\,\\,\\, \\tag{3.20} \\] onde \\(\\widehat{V}_{p}\\left( \\mathbf{\\widehat{Z}}_{HT}\\right)\\) é dado em (3.3), onde substituímos o vetor de variáveis resposta original \\(\\mathbf{y}_i\\) pelo vetor de variáveis linearizadas \\(\\mathbf{z}_{i} = \\mathbf{\\Delta g(Y)} \\mathbf{y}_{i}\\). Linearização de Taylor pode ser trabalhosa, porque para cada parâmetro/estimador de interesse são requeridas derivações e cálculos específicos. Felizmente, grande parte das situações de interesse prático estão hoje cobertas por pacotes estatísticos especializados na estimação de medidas descritivas e parâmetros de modelos, e suas respectivas variâncias de aleatorização empregando o método de linearização, de modo que essa desvantagem potencial tende a se diluir. Linearização de Taylor pode não ser imediatamente possível, pois pode ocorrer que as quantidades de interesse não podem ser expressas como funções de totais ou médias populacionais (este é o caso de quantis de distribuições, por exemplo). Para estes casos é necessário recorrer a outras técnicas de estimação de variâncias, como discutido, por exemplo, em Wolter (2007). 3.4 Equações de estimação Até aqui, falamos da estimação de totais e de parâmetros que podem ser escritos como funções de totais. O caminho para obter resultados gerais referentes a muitos outros parâmetros de interesse é o que discutimos nesta seção. Se um parâmetro populacional de interesse \\(\\theta_U\\) é uma solução única de um sistema de equações de estimação definidas como \\[ \\sum_{i \\in U} \\mathbf{u_i(\\theta)} = \\mathbf{0} \\,\\,\\, \\tag{3.21} \\] para uma função \\(\\mathbf{u(\\bullet)}\\) conhecida, então é possível estimar o parâmetro \\(\\theta_U\\) usando o estimador \\(\\widehat \\theta\\) obtido resolvendo as equações de estimação amostrais: \\[ \\sum_{i \\in s} d_i \\, \\mathbf{u_i(\\theta)} = \\mathbf{0} \\,\\,\\, \\tag{3.22} \\] O estimador \\(\\widehat \\theta\\) é consistente para \\(\\theta_U\\), e adiante mostraremos como o método de Linearização de Taylor pode ser usado para estimar a sua variância. Antes, porém, vamos usar alguns exemplos para ilustrar casos particulares relevantes de como aplicar essa ideia. Exemplo 3.2 Estimação de médias populacionais Para ilustrar a aplicação da abordagem de equações de estimação, considere o caso em que a função \\(\\mathbf{u_i(\\theta)} = y_i - \\theta\\). Nesse caso, as equações de estimação populacionais (3.21) simplificam para: \\[ \\sum_{i \\in U} \\mathbf{u_i(\\theta)} = \\sum_{i \\in U} (y_i - \\theta) = \\mathbf{0} \\] Resolvendo esta equação, obtemos: \\[ \\theta_U = \\frac{1}{N} \\sum_{i \\in U} y_i = \\overline{Y} \\] A solução das equações de estimação amostrais fornece: \\[ \\widehat \\theta = \\frac{\\sum_{i \\in s} d_i y_i}{{\\sum_{i \\in s} d_i}} = \\overline{y}_{Hàjek} \\] que é o conhecido estimador de Hàjek da média populacional. Exemplo 3.3 Estimação de razões populacionais Considere agora o caso em que a função \\(\\mathbf{u_i(\\theta)} = y_i - \\theta z_i\\). Nesse caso, as equações de estimação populacionais (3.21) simplificam para: \\[ \\sum_{i \\in U} \\mathbf{u_i(\\theta)} = \\sum_{i \\in U} (y_i - \\theta z_i) = \\mathbf{0} \\] Resolvendo esta equação, obtemos: \\[ \\theta_U = \\frac{\\sum_{i \\in U} y_i}{\\sum_{i \\in U} z_i} = \\frac{Y}{Z} = R \\] A solução das equações de estimação amostrais correspondentes fornece: \\[ \\widehat \\theta = \\frac{\\sum_{i \\in s} d_i y_i}{\\sum_{i \\in s} d_i z_i} = \\frac{\\widehat{Y}_{HT}}{\\widehat{Z}_{HT}} = \\widehat{R} \\] Os exemplos apresentados ilustram que a estimação de médias e razões populacionais são casos particulares simples da abordagem mais geral de equações de estimação. Essa abordagem também se mostrará útil quando lidamos com a estimação de parâmetros sob vários tipos de modelos paramétricos, que está apresentada nos capítulos seguintes deste livro. É também graças a ela que foi possível desenvolver software genérico para estimação a partir de amostras complexas, como é o caso do pacote survey do sistema R. A estimação de variâncias nesse caso pode ser feita usando o método de Linearização de Taylor, empregando a estratégia de calcular variáveis linearizadas \\(z\\) definidas como na Seção 3.3. Esta é a estratégia adotada no pacote survey do sistema R. 3.5 Método do Conglomerado Primário A ideia central do Método do Conglomerado Primário (do inglês Ultimate Cluster) para estimação de variâncias para estimadores de totais e médias em planos amostrais de múltiplos estágios, proposto por Hansen et al. (1953), é considerar apenas a variação entre informações disponíveis no nível das unidades primárias de amostragem - UPAs, isto é, dos conglomerados primários, e admitir que estes teriam sido selecionados com reposição da população de UPAs. Esta ideia é simples, porém bastante poderosa, porque permite acomodar uma enorme variedade de planos amostrais envolvendo estratificação, amostragem conglomerada e seleção com probabilidades desiguais (com ou sem reposição) tanto das UPAs como das demais unidades de amostragem. Os requisitos fundamentais para permitir a aplicação deste método são que estejam disponíveis estimadores não viciados dos totais da variável de interesse para cada um dos conglomerados primários selecionados, e que pelo menos dois destes sejam selecionados em cada estrato (se a amostra for estratificada no primeiro estágio). Embora o método tenha sido originalmente proposto para estimação de totais, pode ser aplicado também para estimar (por linearização) quantidades populacionais que possam ser representadas como funções de totais, conforme discutido na Seção 3.3. De fato, esse método fornece a base para ferramentas dos sistemas estatísticos para cálculo de variâncias considerando o plano amostral, tais como o pacote survey do R, as funções svy do STATA, o módulo Complex Samples do SPSS, as procs Survey do SAS, entre outros. Para descrever o método, considere um plano amostral em vários estágios, no qual \\(n_{h}\\) unidades primárias de amostragem - UPAs foram selecionadas no estrato \\(h\\), com \\(h=1, \\ldots, H\\). Denotemos por \\(\\pi_{hi}\\) a probabilidade de inclusão na amostra da UPA (conglomerado primário) \\(i\\) do estrato \\(h\\), e por \\(\\widehat{Y}_{hi}\\) um estimador não viciado do total \\(Y_{hi}\\) da variável de pesquisa \\(y\\) na \\(i\\)-ésima UPA do estrato \\(h\\). Então um estimador não viciado do total \\(Y = \\sum_{h=1}^{H} \\sum_{i=1}^{N_{h}} Y_{hi}\\) da variável de pesquisa \\(y\\) na população é dado por \\[ \\widehat{Y}_{CP} = \\sum_{h=1}^{H} \\sum_{i=1}^{n_{h}} \\widehat{Y}_{hi} / \\pi _{hi} \\,\\,\\, \\tag{3.23} \\] e um estimador não viciado da variância de aleatorização correspondente por \\[ \\widehat{V}_{p} \\left( \\widehat{Y}_{CP}\\right) = \\sum_{h=1}^{H}\\frac{n_{h}} {n_{h}-1} \\sum_{i=1}^{n_{h}} \\left( \\frac{\\widehat{Y}_{hi}}{\\pi _{hi}} - \\frac{\\widehat{Y}_{h}}{n_{h}} \\right) ^{2} \\tag{3.24} \\] onde \\(\\widehat{Y}_{h} = \\sum_{i=1}^{n_{h}} \\widehat{Y}_{hi} / \\pi _{hi}\\) para \\(h=1,\\ldots ,H\\). (Ver por exemplo, Shah et al. (1993), página 4). Embora na prática a seleção das UPAs seja geralmente feita sem reposição, o estimador do Método do Conglomerado Primário - MCP aqui apresentado pode fornecer uma aproximação razoável da correspondente variância de aleatorização, especialmente nos casos em que as frações amostrais de UPAs são pequenas nos estratos. Isso ocorre porque planos amostrais sem reposição são em geral mais eficientes que planos com reposição de igual tamanho. Tal aproximação é largamente utilizada pelos praticantes de amostragem para estimar variâncias de quantidades descritivas usuais tais como totais e médias (com a devida adaptação) devido à sua simplicidade, comparada com a complexidade muito maior envolvida com o emprego de estimadores de variância que tentam incorporar todas as etapas de planos amostrais conglomerados em vários estágios. Uma discussão sobre a qualidade dessa aproximação e alternativas pode ser encontrada em Särndal et al. (1992), página 153. 3.6 Métodos de replicação A ideia de usar métodos indiretos ou de replicação para estimar variâncias em amostragem não é nova. Mahalanobis (1939), Mahalanobis (1944) e Deming (1956) foram os precursores e muitos desenvolvimentos importantes se seguiram. Hoje em dia várias técnicas baseadas nessa ideia são rotineiramente empregadas por praticantes de amostragem, e inclusive formam a base para pacotes especializados de estimação tais como WesVarPC (ver Westat (1996)). A ideia básica original foi construir a amostra de tamanho \\(n\\) como a união de \\(G\\) amostras de tamanho \\(n/G\\) cada uma, selecionadas de forma independente e usando o mesmo plano amostral, onde \\(G\\) é o número de réplicas. Nesse caso, se \\(\\theta\\) é o parâmetro-alvo, e \\(\\widehat{\\theta}_{g}\\) é um estimador não viciado de \\(\\theta\\) baseado na \\(g\\)-ésima réplica \\((g=1,\\ldots ,G)\\), segue-se que \\[ \\widehat{\\theta }_{G}=\\frac{1}{G}\\sum_{g=1}^{G}\\widehat{\\theta }_{g} \\] é também um estimador não viciado de \\(\\theta\\) e \\[ \\widehat{V}_{G} \\left( \\widehat{\\theta }_{G}\\right) = \\frac{1}{G \\left( G-1 \\right)} \\sum_{g=1}^{G} \\left( \\widehat{\\theta }_{g} - \\widehat{\\theta}_{G} \\right)^{2} \\,\\, \\tag{3.25} \\] é um estimador não viciado (de replicação) da variância do estimador \\(\\widehat{\\theta}_{G}\\). Note que desde que as réplicas sejam construídas de forma independente conforme indicado, os estimadores \\(\\widehat{\\theta }_{G}\\) e \\(\\widehat{V}_{G}\\left( \\widehat{\\theta }_{G}\\right)\\) são não viciados qualquer que seja o plano amostral empregado para selecionar a amostra de cada réplica, o que faz desta uma técnica flexível e genérica. Além disso, a abordagem de replicação é bastante geral, pois os estimadores aos quais se aplica não precisam ser necessariamente expressos como funções de totais, como ocorre com a técnica de Linearização de Taylor discutida na Seção 3.3. Apesar destas vantagens, a aplicação prática desta técnica de forma exata é restrita porque, em geral, é menos eficiente, inconveniente e mais caro selecionar \\(G\\) amostras (réplicas) independentes com o mesmo esquema, se comparado à seleção de uma única amostra de tamanho \\(n\\) diretamente. Além disto, se o número de réplicas \\(G\\) for pequeno, o estimador de variância pode ser instável. Mesmo quando a amostra não foi selecionada exatamente dessa forma, a construção de réplicas a posteriori para fins de estimação de variâncias em situações complexas é também uma ideia simples de aplicar, poderosa e flexível, por acomodar uma ampla gama de planos amostrais e situações de estimação de interesse. Quando as réplicas são construídas após a pesquisa (a posteriori), mediante repartição (por sorteio) da amostra pesquisada em \\(G\\) grupos mutuamente exclusivos de igual tamanho, estas são chamadas de réplicas dependentes ou grupos aleatórios (do inglês random groups). As expressões fornecidas para o estimador de replicação e sua variância são também empregadas nesse caso como uma aproximação, mas não possuem as mesmas propriedades do caso de réplicas independentes. Uma pesquisa importante e de grande porte em que esta ideia é aplicada é a pesquisa de preços para formar o índice de Preços ao Consumidor (do inglês Consumer Price Index - CPI) do US Bureau of Labour Statistics (2020), página 46, que utiliza duas ou mais réplicas para formar a amostra de itens cujos preços são pesquisados. É importante observar que a repartição da amostra em grupos aleatórios a posteriori precisa considerar o plano amostral empregado e pode não ser possível em algumas situações. Idealmente, tal repartição deveria ser feita respeitando estratos e alocando UPAs inteiras (isto é, com todas as respectivas unidades subordinadas). Wolter (1985), página 31, discute algumas regras sobre como fazer para respeitar o plano amostral ao fazer a repartição da amostra a posteriori, porém recomendamos que o interessado no uso dessa técnica exerça cautela. Além da modificação da interpretação das réplicas no caso de serem formadas a posteriori, é comum também nesse caso empregar um estimador para o parâmetro \\(\\theta\\) baseado na amostra completa (denotado \\(\\widehat{\\theta}\\)), e um estimador de variância mais conservador que o estimador \\(\\widehat{V}_{G}\\left( \\widehat{\\theta }_{G}\\right)\\) anteriormente apresentado, dado por \\[ \\widehat{V}_{G}\\left( \\widehat{\\theta }\\right) =\\frac{1}{G\\left( G-1\\right) }\\sum_{g=1}^{G}\\left( \\widehat{\\theta }_{g}-\\widehat{\\theta }\\right) ^{2} \\,\\, \\tag{3.26} \\] Um exemplo de aplicação desta técnica pode ser encontrado na forma recomendada para estimação de variâncias a partir das Amostras de Uso Público do Censo Demográfico Brasileiro de 80 (ver IBGE (1985)). Nesta seção descreveremos duas outras dessas técnicas baseadas em replicações. A primeira é o método de jackknife. Este método foi originalmente proposto por Quenoille (1949) e Quenoille (1956) como uma técnica para redução de vício de estimadores, num contexto da Estatística Clássica. A ideia central consiste em repartir a amostra (a posteriori, como no caso do método dos grupos aleatórios) em \\(G\\) grupos mutuamente exclusivos de igual tamanho \\(n/G\\). Em seguida, para cada grupo formado calcular os chamados pseudo estimadores dados por \\[ \\widehat{\\theta }_{\\left( g\\right) }=G\\widehat{\\theta }-\\left( G-1\\right) \\widehat{\\theta }_{g} \\] onde \\(\\widehat{\\theta }_{g}\\) é um estimador de \\(\\theta\\) obtido da amostra após eliminar os elementos do grupo \\(g\\), empregando a mesma forma funcional adotada no cálculo do estimador \\(\\widehat{\\theta}\\) que considera a amostra inteira. A estimação da variância por esse método pode então ser feita de duas maneiras alternativas, usando um dos estimadores dados por \\[ \\widehat{V}_{J1}\\left( \\widehat{\\theta }\\right) =\\frac{1}{G\\left( G-1\\right) }\\sum_{g=1}^{G}\\left( \\widehat{\\theta }_{\\left( g\\right) }-\\widehat{\\theta } _{J}\\right) ^{2} \\tag{3.27} \\] ou \\[ \\widehat{V}_{J2}\\left( \\widehat{\\theta }\\right) =\\frac{1}{G\\left( G-1\\right) }\\sum_{g=1}^{G}\\left( \\widehat{\\theta }_{\\left( g\\right) }-\\widehat{\\theta } \\right) ^{2} \\,\\,\\, \\tag{3.28} \\] onde \\(\\widehat{\\theta }_{J} = \\frac{1}{G} \\sum_{g=1}^{G} \\widehat{\\theta }_{\\left( g\\right)}\\) é um estimador pontual jackknife para \\(\\theta\\), alternativo ao estimador da amostra inteira \\(\\hat{\\theta}\\). Observaçao 3.1: A descrição do método jackknife aqui apresentada não cobre o caso de planos amostrais estratificados, que é mais complexo. Para detalhes sobre este caso, consulte Wolter (1985), pág. 174. Observaçao 3.2: O estimador \\(\\widehat{V}_{J2}\\left( \\widehat{\\theta }\\right)\\) é mais conservador que o estimador \\(\\widehat{V}_{J1}\\left( \\widehat{\\theta }\\right)\\). Observaçao 3.3: É comum aplicar a técnica fazendo o número de grupos igual ao tamanho da amostra, isto é, tomando \\(G=n\\) e portanto eliminando uma observação da amostra de cada vez ao calcular os pseudo valores. Essa regra deve ser aplicada considerando o número de UPAs quando o plano amostral é em múltiplos estágios, pois as UPAs devem sempre ser eliminadas com todas as unidades subordinadas. Os estimadores de variância do método jackknife fornecem resultadoS idênticos aos dos estimadores usuais de variância quando aplicados para o caso de estimadores lineares nas observações amostrais. Além disso, suas propriedades são razoáveis para vários outros casos de estimadores não lineares de interesse (ver, por exemplo, Cochran (1977), página 321 e Wolter (1985), página 306). A situação merece maiores cuidados para o caso de quantis ou estatísticas de ordem, tais como a mediana e o máximo, pois neste caso essa técnica não funciona bem Wolter (1985), página 163. O pacote WesVarPC (Westat, 1996) baseia suas estimativas de variância principalmente no método jackknife, embora também possua uma opção para usar outro método conhecido como de replicações de meias amostras balanceadas (do inglês balanced half-sample replication). O outro método de replicação que vamos considerar é uma variante do método bootstrap proposta por Rao et al. (1992). O método consiste dos seguintes passos: Selecione amostras aleatórias simples com reposição de \\(m_h\\) das \\(n_h\\) UPAs de cada estrato \\(h=1, \\dots, H\\). Calcule as contagens \\(m_{hi}^*\\) de vezes que cada UPA \\(i\\) aparece na amostra selecionada no estrato \\(h\\); note que \\(\\sum_i m_{hi}^* = m_h\\) para todo estrato \\(h\\); Defina pesos bootstrap para as unidades da amostra selecionada em (1) usando: \\[ w_{hik}^* = \\left[ 1 - \\left( \\frac{m_h} {n_h - 1} \\right)^{1/2} + \\left( \\frac{m_h} {n_h - 1} \\right)^{1/2} \\times \\frac{n_h} {m_h} \\times m_{hi}^* \\right] \\times w_{hik} \\,\\,\\, \\tag{3.29} \\] onde \\(w_{hik}\\) é o peso da unidade \\(k\\) da UPA \\(i\\) do estrato \\(h\\). Note que quando uma UPA \\(i\\) não é selecionada, sua contagem \\(m_{hi}^*\\) é igual a zero, e o terceiro termo dentro do colchete é nulo. Calcule uma estimativa \\(\\widehat \\theta _b\\) para o parâmetro de interesse usando os pesos bootstrap \\(w_{hik}^*\\) em lugar dos pesos originais \\(w_{hik}\\). Repita os passos 1) a 4) um número \\(B\\) grande de vezes. Estime a variância do estimador \\(\\widehat \\theta\\) com: \\[ \\widehat{V}_{B}\\left( \\widehat{\\theta }\\right) = \\frac{1}{B} \\sum_{b=1}^{B} \\left( \\widehat \\theta _b - \\widehat{\\theta} \\right) ^{2} \\,\\,\\, \\tag{3.30} \\] A Pesquisa Nacional por Amostra de Domicílios Contínua - PNAD Contínua do IBGE passou a usar este método bootstrap para estimação da precisão dos indicadores que divulga a partir do terceiro trimestre de 2021, ver IBGE (2021). Embora computacionalmente mais custoso que o método da Linearização de Taylor, o método bootstrap aqui descrito tem como vantagem a aplicação em casos onde o estimador não é função suave de totais populacionais, tais como separatrizes (quantis), algumas medidas de desigualdade e pobreza etc. Além disso, o método pode ser aplicado com qualquer software que permita implementar o algoritmo descrito, e não requer pacotes especializados. Vale mencionar, entretanto, que este método está disponível no pacote survey do sistema R. Sua utilização é ilustrada em capítulos posteriores. XXX Parei aqui 3.7 Laboratório de R Vamos utilizar dados da Pesquisa de Padrão de Vida (PPV) do IBGE para ilustrar alguns métodos de estimação de variâncias. Vamos considerar a estimação da proporção de analfabetos na faixa etária acima de 14 anos. Os dados da pesquisa encontram-se no data frame . A variável analf2 é indicadora da condição de analfabetismo na faixa etária acima de 14 anos e a variável faixa2 é indicadora da faixa etária acima de 14 anos. Queremos estimar a proporção de analfabetos na faixa etária acima de 14 anos na região Sudeste. Antes apresentamos o método de estimação de variância por linearização de Taylor Vamos criar duas variáveis: analf - variável indicadora da condição de analfabetismo: v04a01 ou v04a02 igual a 2; faixa - variável indicadora de faixa etária entre 7 e 14 anos. library(survey) ppv_dat &lt;- readRDS(&quot;./data/ppv.rds&quot;) # carrega dados # cria objeto de desenho ppv_plan&lt;-svydesign(ids = ~nsetor, strata = ~estratof, data = ppv_dat, nest = TRUE, weights = ~pesof) # atualiza objeto de desenho com novas variáveis ppv_plan&lt;-update(ppv_plan, analf=(v04a01 == 2 | v04a02 == 2)*1, faixa=(v02a08 &gt;= 7 &amp; v02a08 &lt;= 14) *1, analf.faixa= (analf==1 &amp; faixa==1)*1 ) Como estamos interessados em estimativas relativas à Região Sudeste, vamos restringir o desenho a esse domínio: ppv_se_plan &lt;- subset(ppv_plan, regiao == 2) Vamos estimar os totais das variáveis analf.faixa e faixa: analf_faixa_tot_est&lt;-svytotal(~analf.faixa+faixa ,ppv_se_plan ) Vcov.Y1.Y2&lt;-vcov(analf_faixa_tot_est) Substituindo os valores na expressão (3.21), obtemos a estimativa da variância da razão de totais das variáveis analf.faixa e faixa. y1hat&lt;-coef(analf_faixa_tot_est)[1] y2hat&lt;-coef(analf_faixa_tot_est)[2] Var.raz&lt;-(1/y2hat)*(1/y2hat)*Vcov.Y1.Y2[1,1]+2*(1/y2hat)*(-y1hat/y2hat^2)*Vcov.Y1.Y2[1,2]+ (-y1hat/y2hat^2)*(-y1hat/y2hat^2)*Vcov.Y1.Y2[2,2] # estimativa do desvio-padrão sqrt(Var.raz) ## faixa ## 0,0118 Podemos calcular diretamente o desvio-padrão: svyratio(~analf.faixa, ~faixa, ppv_se_plan) ## Ratio estimator: svyratio.survey.design2(~analf.faixa, ~faixa, ppv_se_plan) ## Ratios= ## faixa ## analf.faixa 0,119 ## SEs= ## faixa ## analf.faixa 0,0118 A estimativa do desvio-padrão obtida por meio da função svyratio coincide com a obtida diretamente pelo método de linearização, e é igual a r round(sqrt(Var.raz),digits=5). O método default para estimar variâncias usado pela library survey (Lumley, 2021) do R é o de linearização de Taylor. A library survey dispõe de métodos alternativos para a estimação de variância. Vamos utilizar os métodos de replicação de Jackknife e de Bootstrap para estimar esta variância de razão. Inicialmente, vamos converter o objeto de desenho ppv1_se_plan em um objeto de desenho de replicação de tipo Jackknife, contendo as réplicas de pesos que fornecem correspondentes réplicas de estimativas. ppv_se_plan_jkn&lt;-as.svrepdesign(ppv_se_plan,type=&quot;JKn&quot;) svyratio(~analf.faixa, ~faixa, ppv_se_plan_jkn) ## Ratio estimator: svyratio.svyrep.design(~analf.faixa, ~faixa, ppv_se_plan_jkn) ## Ratios= ## faixa ## analf.faixa 0,119 ## SEs= ## [,1] ## [1,] 0,0118 Para o tipo Bootstrap, temos: ppv_se_plan_boot&lt;-as.svrepdesign(ppv_se_plan,type=&quot;bootstrap&quot;) svyratio(~analf.faixa, ~faixa, ppv_se_plan_boot) ## Ratio estimator: svyratio.svyrep.design(~analf.faixa, ~faixa, ppv_se_plan_boot) ## Ratios= ## faixa ## analf.faixa 0,119 ## SEs= ## [,1] ## [1,] 0,013 Vamos apresentar mais detalhes sobre a obtenção dos estimadores de Jackknife e Bootstrap na library survey (Lumley, 2021). A classe do objeto ppv_se_plan_jkn é svyrep.design e ele contém as seguintes componentes: class(ppv_se_plan_jkn) ## [1] &quot;svyrep.design&quot; names(ppv_se_plan_jkn) ## [1] &quot;repweights&quot; &quot;pweights&quot; &quot;type&quot; &quot;rho&quot; ## [5] &quot;scale&quot; &quot;rscales&quot; &quot;call&quot; &quot;combined.weights&quot; ## [9] &quot;selfrep&quot; &quot;mse&quot; &quot;variables&quot; &quot;degf&quot; A componente repweights é uma lista com duas componentes: weights e index. A componente weights é uma matriz de dimensão \\(276 \\times 276\\), onde \\(276\\) é o número de conglomerados primários do plano amostral da PPV na região Sudeste. A partir desta matriz, podemos obter \\(276\\) réplicas de pesos de desenho de Jackknife. ppv_se_dat&lt;-ppv_se_plan_jkn$variables nrow(ppv_se_dat) ## [1] 8903 ncong&lt;-sum(with(ppv_se_dat,tapply( nsetor,estratof, function(t) length(unique(t))))) ncong ## [1] 276 O argumento compress da função as.svrepdesign permite especificar se, na saída da função, a matriz weights é na forma comprimida ou não. Na aplicação feita foi usado o valor default que é a forma comprimida. A forma não comprimida da matriz weights tem r nrow(ppv_se_dat) linhas e r ncong colunas. A forma comprimida permite economizar memória, e pode ser facilmente convertida para a forma não comprimida, utilizando-se a componenteindex. No método jackknife, cada um dos conglomerados primários é removido, e a réplica correspondente dos pesos é o produto do peso amostral original por um fator apropriado, definido da forma a seguir. Suponhamos que foi removido um conglomerado no estrato \\(h\\), então os pesos do plano amostral serão multiplicados por: \\(0\\) para as unidades no conglomerado removido; \\(m_h/(m_h-1)\\) para unidades pertencentes a outros conglomerados do estrato \\(h\\); \\(1\\) para unidades em estratos \\(h&#39;\\neq h\\). Podemos obter a matriz de fatores de correção do peso amostral na forma não comprimida da seguinte maneira: fact_peso_comp_mat&lt;-ppv_se_plan_jkn$repweights[[1]] ind_cong &lt;-ppv_se_plan_jkn$repweights[[2]] fat_pesos_mat&lt;- fact_peso_comp_mat[ind_cong,] str(fat_pesos_mat) ## num [1:8903, 1:276] 0 0 1,06 1,06 1,06 ... Podemos obter matriz de réplicas de pesos multiplicando cada coluna dessa matriz pelos pesos do plano amostra: rep_pesos_mat&lt;-weights(ppv_se_plan)*fat_pesos_mat Utilizando esta matriz de réplicas de pesos, podemos obter réplicas correspondentes de estimativas da razão. rep_est_raz&lt;-numeric(ncol(rep_pesos_mat)) for (i in 1:ncol(rep_pesos_mat)){ rep_est_raz[i]&lt;-sum(rep_pesos_mat[,i]*ppv_se_dat$analf.faixa)/sum(rep_pesos_mat[,i]*ppv_se_dat$faixa) } A partir destas réplicas de estimativas da razão, finalmente estimamos a variância: mean_raz&lt;-mean( rep_est_raz[ppv_se_plan_jkn$rscales&gt;0]) var_jack_raz&lt;- sum((rep_est_raz-mean_raz)^2*ppv_se_plan_jkn$rscales)*ppv_se_plan_jkn$scale round(sqrt(var_jack_raz),5) ## [1] 0,0118 A library survey (Lumley, 2021) fornece uma função para estimar a variância de uma função de totais a partir das réplicas de pesos: var_raz_rep&lt;-withReplicates(ppv_se_plan_jkn, function(w,ppv_se_dat) sum(w*ppv_se_dat$analf.faixa)/sum(w*ppv_se_dat$faixa)) var_raz_rep ## theta SE ## [1,] 0,119 0,01 Resultado que coincide com a estimativa obtida pela aplicação da função svyratio. A vantagem de utilizar métodos de replicação é a facilidade com que estimamos a variância de qualquer característica da população, cujo estimador pontual é conhecido. Por exemplo, se quisermos estimar a variância da razão das taxas de analfabetos nas faixas etárias de 0 a 14 anos e acima de 14 anos podemos usar as mesmas réplicas de pesos: withReplicates (ppv_se_plan_jkn,function(w,ppv_se_dat) with(ppv_se_dat, (sum(w*(analf==1&amp;faixa==1))/sum(w*(faixa==1)))/(sum(w*(analf==1&amp;faixa==0))/sum(w*(faixa==0))) )) ## theta SE ## [1,] 0,504 0,05 O erro padrão da razão entre razões estimada no exemplo anterior pode ser estimado por linearização de Taylor, usando-se a função svycontrast() da library survey: # cria variáveis dummies: ppv_se_plan &lt;- update(ppv_se_plan, num1 = as.numeric(analf==1 &amp; faixa==1), num2 = as.numeric(analf==1 &amp; faixa==0), den1 = as.numeric (faixa == 1), den2 = as.numeric(faixa == 0) ) # estima totais e matriz de covariância de estimativas de totais comp.tot &lt;- svytotal(~num1+num2+den1+den2, ppv_se_plan) # estima razão de razões: svycontrast(comp.tot, quote((num1/den1)/(num2/den2))) ## nlcon SE ## contrast 0,504 0,05 "],["epa.html", "Capítulo 4 Efeitos do Plano Amostral 4.1 Introdução 4.2 Efeito do plano amostral de Kish 4.3 Efeito do plano amostral ampliado 4.4 Efeitos sobre intervalos de confiança e testes de hipóteses uniparamétricos 4.5 Efeitos multivariados do plano amostral 4.6 Laboratório de R", " Capítulo 4 Efeitos do Plano Amostral 4.1 Introdução A estimação do desvio ou erro padrão de estimativas, de intervalos de confiança e o uso de testes de hipóteses desempenham papel fundamental em estudos analíticos. Além de estimativas pontuais, na inferência analítica é necessário conhecer e comunicar a precisão associada às estimativas e construir intervalos de confiança para os parâmetros de interesse. Valores de desvios padrões, ou alternativamente margens de erro iguais à semiamplitude de intervalos de confiança, permitem avaliar a precisão da estimação. Em muitos casos, a estimação do desvio padrão ou da variância também possibilita a construção de estatísticas para testar hipóteses relativas aos parâmetros do modelo (tradição de modelagem) ou aos parâmetros da população finita (tradição de amostragem). Testes de hipóteses são também usados na fase de seleção de variáveis ou efeitos para inclusão ou manutenção nos modelos ajustados. Os sistemas mais comuns de análise estatística incluem em suas saídas valores de estimativas pontuais e seus desvios padrões, intervalos de confiança e valores-\\(p\\) relativos a hipóteses de interesse. Contudo, as fórmulas usadas nestes sistemas para a estimação dos desvios padrões e obtenção de estatísticas de testes são, em geral, baseadas nas hipóteses de independência e de igualdade de distribuição (IID) das observações ou, equivalentemente, do emprego de Amostragem Aleatória Simples Com Reposição - AASC. Tais hipóteses quase nunca valem para dados obtidos através de pesquisas por amostragem, como as que realizam o IBGE e outras agências produtoras de estatísticas públicas e/ou oficiais. Os principais motivos para isso são o emprego de estratificação, conglomeração, planos amostrais com probabilidades desiguais de seleção e correções para não resposta, que dão origem a observações amostrais com pesos distintos, e/ou que não são independentes quando provenientes dos mesmos grupos usados como conglomerados nalguma das etapas de amostragem. Este capítulo trata de como avaliar o impacto sobre estimativas de desvios padrões, intervalos de confiança e níveis de significância de testes usuais quando há afastamentos das hipóteses IID mencionadas, devidos ao uso de planos amostrais complexos para obter os dados. Como veremos, o impacto pode ser muito grande em algumas situações, justificando os cuidados que devem ser tomados na análise de dados provenientes de amostras complexas. Neste capítulo, usamos como referência básica Skinner (1989b). 4.2 Efeito do plano amostral de Kish Para medir o efeito do plano amostral sobre a variância de um estimador, Kish (1965) propôs uma medida que denominou Efeito do Plano Amostral - \\(EPA\\) (em inglês, design effect ou, abreviadamente, deff). O objetivo desta medida é comparar planos amostrais no estágio de planejamento da pesquisa. O \\(EPA\\) de Kish é uma razão entre variâncias (de aleatorização) de um estimador, calculadas para dois planos amostrais alternativos. Vamos considerar um estimador \\(\\widehat{\\theta}\\) para um parâmetro único \\(\\theta\\) e calcular a variância de sua distribuição induzida pelo plano amostral complexo (verdadeiro) \\(V_{VERD}\\left(\\widehat{\\theta}\\right)\\) e a variância da distribuição do estimador induzida pelo plano de amostragem aleatória simples \\(V_{AAS}\\left(\\widehat{\\theta}\\right)\\). Nessa comparação, está implícita a ideia de que o estimador \\(\\widehat{\\theta}\\) é não enviesado ou ao menos consistente para o parâmetro \\(\\theta\\) tanto sob o plano amostral complexo como sob AAS. Definição 4.1 O Efeito do Plano Amostral - \\(EPA\\) de Kish para um estimador \\(\\widehat{\\theta}\\) é \\[ EPA_{Kish} \\left(\\widehat{\\theta}\\right) = \\frac{V_{VERD} \\left(\\widehat{\\theta}\\right)} {V_{AAS} \\left(\\widehat{\\theta}\\right)} \\quad \\tag{4.1} \\] Para ilustrar o conceito do \\(EPA_{Kish}\\left(\\widehat{\\theta}\\right)\\), vamos considerar um exemplo. Exemplo 4.1 Efeitos do plano amostral de Kish para estimadores de totais com amostragem conglomerada em dois estágios. P. L. N. Silva e Moura (1990) estimaram o \\(EPA_{Kish}\\) para estimadores de totais de várias variáveis socioeconômicas no nível das Regiões Metropolitanas - RMs - utilizando dados do questionário de amostra do Censo Demográfico de 1980. Essas medidas estimadas do efeito do plano amostral foram calculadas para três estratégias amostrais alternativas, todas considerando amostragem conglomerada de domicílios em dois estágios, tendo o setor censitário como unidade primária de amostragem - UPA - e o domicílio como unidade secundária de amostragem - USA. Duas das alternativas consideraram seleção de setores com equiprobabilidade via amostragem aleatória simples sem reposição - AC2S - e fração amostral constante de domicílios no segundo estágio (uma usando o estimador Horvitz-Thompson - HT do total, e outra usando o estimador de razão para o total calibrando no número total de domicílios da população). Uma terceira estratégia, denominada AC2PC, considerou a seleção de setores com probabilidades proporcionais ao tamanho - PPT - usando o número de domicílios por setor como medida de tamanho, a seleção de \\(15\\) domicílios em cada setor da amostra usando AAS e empregando o correspondente estimador HT. A título de ilustração, resultados referentes à Região Metropolitana do Rio de Janeiro são apresentados na Tabela 4.1 para algumas variáveis. Note que a população-alvo para a qual se faz inferência considera apenas moradores em domicílios particulares permanentes na Região Metropolitana do Rio de Janeiro. Tabela 4.1: \\(\\text{Efeitos do plano amostral de Kish para variáveis selecionadas}\\) \\(\\text{Região Metropolitana do Rio de Janeiro}\\) Variável AC2S + Estimador HT AC2S + Estimador de Razão AC2PC + Estimador HT Número total de moradores 10,74 2,00 1,90 Número de moradores ocupados 5,78 1,33 1,28 Rendimento monetário mensal 5,22 4,92 4,49 Número total de filhos nascidos vivos de mulheres com 15 anos ou mais 4,59 2,02 1,89 Número de domicílios que têm fogão 111,27 1,58 1,55 Número de domicílios que têm telefone 7,11 7,13 6,41 Valor do aluguel ou prestação mensal 7,22 7,02 6,45 Número de domicílios que têm automóvel e renda &lt; 5SM 1,80 1,67 1,55 Número de domicílios que têm geladeira e renda \\(\\geq\\) 5SM 46,58 2,26 2,08 Os valores apresentados na Tabela 4.1 para a RM do Rio de Janeiro são similares aos observados para as demais RMs, se consideradas as mesmas variáveis, conforme os resultados obtidos por P. L. N. Silva e Moura (1990). Nota-se grande variação dos valores do \\(EPA_{Kish}\\) cujos valores mínimo e máximo são de 1,28 e 111,27 respectivamente. Porém, em todos os casos, os valores dos \\(EPA_{Kish}\\) são maiores que \\(1\\), indicando que as três estratégias consideradas levariam a estimativas menos precisas que as que poderiam ser obtidas usando AAS com os mesmos tamanhos de amostra. Quanto maior o valor do \\(EPA_{Kish}\\), menor a precisão das estimativas obtidas com cada estratégia em comparação com a de uma AAS de igual tamanho. Os valores elevados do \\(EPA_{Kish}\\) observados para algumas variáveis realçam a importância de considerar o plano amostral verdadeiro ao estimar variâncias e desvios padrões associados às estimativas pontuais. Isso ocorre porque estimativas ingênuas de variância baseadas na hipótese de AASC podem subestimar as variâncias corretas com viés substancial. Uma outra análise revela que, para algumas variáveis (1, 2, 4, 5 e 9), o \\(EPA_{Kish}\\) varia consideravelmente entre as diferentes estratégias, enquanto para outras variáveis (3, 6, 7 e 8) as variações entre as estratégias é pequena. Esta análise ilustra o uso pretendido por Kish (1965), qual seja o de permitir comparar estratégias de amostragem em etapas de planejamento de pesquisas por amostragem, usando a precisão da AAS como marco de referência para estratégias alternativas sendo consideradas. Outra regularidade encontrada nesse valores é que o \\(EPA_{Kish}\\) para a estratégia que usa o plano amostral AC2S com o estimador HT apresenta sempre os valores mais elevados, revelando que esta estratégia é menos eficiente que as duas competidoras consideradas. Em geral, o \\(EPA_{Kish}\\) é menor para a estratégia AC2PC com o correspondente estimador HT, com valores próximos aos da estratégia AC2S com estimador de razão. Os valores dos \\(EPA_{Kish}\\) calculados por P. L. N. Silva e Moura (1990) podiam ser usados para planejar pesquisas amostrais (ao menos nas regiões metropolitanas), pois permitiam comparar e antecipar o impacto do uso de algumas estratégias amostrais alternativas sobre a precisão de estimadores de totais de várias variáveis relevantes. Permitiam também calcular tamanhos amostrais para garantir determinado nível de precisão, sem emprego de fórmulas complicadas, como discutido, por exemplo, em P. L. N. Silva et al. (2020), Seção 12.10.4. Portanto, tais valores seriam úteis como informação de apoio ao planejamento de novas pesquisas por amostragem, antes que as respectivas amostras fossem efetivamente selecionadas. Entretanto, esses valores teriam pouca utilidade em termos de usos analíticos dos dados da amostra do Censo Demográfico 1980 - CD80. É que tais valores, embora tendo sido estimados com essa amostra, foram calculados para planos amostrais distintos do que foi efetivamente adotado para seleção da amostra daquele censo. A amostra de domicílios usada no CD80 foi estratificada por setor censitário com seleção sistemática de uma fração fixa (1/4 ou 25%) dos domicílios de cada setor. Já os planos amostrais considerados por P. L. N. Silva e Moura (1990) na estimação dos \\(EPA_{Kish}\\) que apresentaram eram planos amostrais em dois estágios, com seleção de setores no primeiro estágio, e domicílios no segundo estágio. Tais planos foram considerados por sua similaridade com os planos amostrais adotados nas principais pesquisas domiciliares do IBGE, tais como a PNAD e a Pesquisa Mensal de Emprego - PME. Portanto, a utilidade maior dos valores tabulados dos \\(EPA_{Kish}\\) seria a comparação de planos amostrais alternativos para planejamento de pesquisas futuras, e não a análise dos resultados da amostra do CD80. 4.3 Efeito do plano amostral ampliado O que se observou no Exemplo 4.1 com respeito à dificuldade ou mesmo impossibilidade de uso dos \\(EPA_{Kish}\\) calculados para fins analíticos também se aplica para outras situações e é uma deficiência estrutural do conceito de \\(EPA\\) proposto por Kish (1965). Para tentar contornar essa dificuldade, é necessário considerar um conceito ampliado de \\(EPA\\), correspondente ao conceito de misspecification effect ou, abreviadamente, meff proposto por Skinner et al. (1989) na página 24, que apresentamos e discutimos nesta seção. Para introduzir este conceito ampliado de \\(EPA\\), que tem utilidade também para fins de inferência analítica, vamos agora considerar um modelo subjacente às observações usadas para o cálculo do estimador pontual \\(\\widehat{\\theta}\\) para um parâmetro único \\(\\theta\\). Designemos por \\(v_{0} = \\widehat{V}_{IID} \\left(\\widehat{\\theta}\\right)\\) um estimador usual (consistente) da variância de \\(\\widehat{\\theta}\\) calculado sob a hipótese (ingênua) de que as observações da amostra disponível são IID. A inadequação da hipótese de IID poderia ser consequência ou da estrutura da população ou do efeito de um plano amostral complexo, ou ambos. Em qualquer dos casos, a estimativa \\(v_{0}\\) da variância de \\(\\widehat{\\theta}\\) calculada sob a hipótese de observações IID se afastaria da variância de \\(\\widehat{\\theta}\\) sob o plano amostral (ou modelo) verdadeiro, denotada \\(V_{VERD}\\left(\\widehat{\\theta}\\right)\\). Note que \\(V_{VERD}\\left(\\widehat{\\theta}\\right) = V_{M}\\left(\\widehat{\\theta}\\right)\\) na abordagem baseada em modelos e \\(V_{VERD}\\left(\\widehat{\\theta}\\right) = V_{p}\\left(\\widehat{\\theta}\\right)\\) na abordagem de aleatorização, onde o plano amostral \\(p\\) considerado é diferente de AASC. Para avaliar se este afastamento tende a ser grande ou pequeno, vamos considerar a distribuição de \\(v_{0}\\) com relação à distribuição de aleatorização verdadeira (ou do modelo verdadeiro) e localizar \\(v_{0}\\) com relação a esta distribuição de referência. Como em geral seria complicado obter esta distribuição, vamos tomar uma medida de centro ou locação da distribuição de \\(v_{0}\\) e compará-la ao valor de \\(V_{VERD}\\left(\\widehat{\\theta}\\right)\\). Podemos desta forma introduzir uma medida de efeito da especificação incorreta do plano amostral (ou do modelo) sobre a estimativa \\(v_{0}\\) da variância do estimador \\(\\widehat{\\theta}\\). Definição 4.2 O efeito da especificação incorreta do plano amostral (ou do modelo) sobre a estimativa \\(v_{0}\\) da variância do estimador \\(\\widehat{\\theta}\\) é \\[ EPA \\left(\\widehat{\\theta}, v_{0}\\right) = \\frac{V_{VERD}\\left(\\widehat{\\theta}\\right)} {E_{VERD}\\left(v_{0}\\right)} \\quad\\tag{4.2} \\] Desta forma, o \\(EPA\\left(\\widehat{\\theta}, v_{0}\\right)\\) mede a tendência de \\(v_{0}\\) a subestimar ou superestimar \\(V_{VERD}\\left(\\widehat{\\theta}\\right)\\), variância verdadeira de \\(\\widehat{\\theta}\\). Valores de \\(EPA\\left(\\widehat{\\theta}, v_{0}\\right)\\) maiores que \\(1\\) sinalizam que \\(v_{0}\\) tende a subestimar a variância \\(V_{VERD}\\left(\\widehat{\\theta}\\right)\\). Quanto mais afastado de \\(1\\) for o valor de \\(EPA\\left(\\widehat{\\theta}, v_{0}\\right)\\), mais incorreta será considerada a especificação do plano amostral ou do modelo considerado. Enquanto a medida proposta por Kish (1965) baseia-se nas distribuições induzidas pela aleatorização dos planos amostrais comparados, o \\(EPA\\left(\\widehat{\\theta}, v_{0}\\right)\\) pode ser calculado com respeito a distribuições de aleatorização ou do modelo envolvido, bastando calcular \\(V_{VERD}\\) e \\(E_{VERD}\\) da definição (4.2) com relação à distribuição de referência correspondente. Em geral, são esperadas as seguintes consequências sobre o \\(EPA\\) ao ignorar o plano amostral efetivamente adotado e admitir que a seleção da amostra foi AASC: Ignorar os pesos em \\(v_{0}\\) pode inflacionar o \\(EPA\\); Ignorar conglomeração em \\(v_{0}\\) pode inflacionar o \\(EPA\\); Ignorar estratificação em \\(v_{0}\\) pode reduzir o \\(EPA\\). Combinações destes aspectos num mesmo plano amostral complexo, resultando na especificação incorreta do plano amostral como se fosse AASC ou da hipótese de observações IID que levam ao estimador ingênuo de variância \\(v_{0}\\), podem inflacionar ou reduzir o \\(EPA\\). Nesses casos é difícil prever o impacto de ignorar o plano amostral (ou modelo) verdadeiro sobre a análise baseada em hipóteses IID. Por essa razão, é recomendável ao menos estimar os \\(EPA\\) antes de concluir a análise padrão, para então poder avaliar se há impactos importantes a considerar. Embora pensadas com objetivos distintos, as duas definições de \\(EPA\\) consideradas têm em comum a ideia de que são medidas adimensionais, estabelecidas mediante comparação de um valor de interesse - \\(V_{VERD}\\left(\\widehat{\\theta}\\right)\\) - com valores de referência - \\(V_{AAS}\\left(\\widehat{\\theta}\\right)\\) ou \\(E_{VERD}\\left(v_{0}\\right)\\) - que nos servem de baliza para avaliar o resultado, por serem quantidades habitualmente usadas ou fáceis de calcular. Essa ideia é recorrente na Estatística, de buscar referir quantidades novas a valores ou distribuições de referência conhecidos, como veremos na sequência deste livro. Apesar dessa diferença de conceitos do \\(EPA\\) de Kish e do \\(EPA\\) ampliado, na prática vai quase sempre ser necessário estimar valores de \\(EPA\\) usando dados de uma amostra. O estimador habitualmente usado para os dois tipos de \\(EPA\\) será então o mesmo, dado por: \\[ \\widehat{EPA} \\left(\\widehat{\\theta},v_{0}\\right) = \\frac{\\widehat{V}_{VERD}\\left(\\widehat{\\theta}\\right)} {v_{0}} \\quad \\tag{4.3} \\] onde o numerador é um estimador não viciado (ou ao menos consistente) para a verdadeira variância do estimador sob o plano amostral de fato empregado para obter a amostra usada na inferência, e no denominador usamos a ideia de que a estimativa \\(v_{0}\\) obtida na amostra é não viciada para estimar o valor esperado dessa quantidade aleatória sob o plano amostral de fato empregado na obtenção da amostra. Apesar de resultar numa estimativa de \\(EPA\\) idêntica para os dois conceitos, a interpretação do resultado será bastante distinta dependendo de qual dos dois parâmetros se buscava estimar. No caso do \\(EPA\\) de Kish ser o alvo, o interesse seria pela comparação de eficiência relativa entre o plano amostral efetivamente empregado e AAS. No caso do \\(EPA\\) ampliado ser o alvo, o interesse é em avaliar quão viciada pode ser a aplicação de métodos padrões de forma ingênua para estimar a variância de estimadores dos parâmetros de interesse da análise. Exemplo 4.2 Efeitos do plano amostral para estimação de médias na amostragem estratificada simples com alocação desproporcional Neste exemplo consideramos uma população de \\(N=749\\) empresas, para as quais foram observadas as seguintes variáveis: pessoal ocupado em 31/12/1994 - PO; total de salários pagos no ano de 1994 - SAL; receita total no ano de 1994 - REC. A ideia é considerar o problema de estimar as médias populacionais das variáveis SAL e REC (variáveis de pesquisa consideradas neste exemplo), usando amostras estratificadas simples com alocação desproporcional, implicando em unidades amostrais com pesos desiguais numa situação bastante simples. A variável PO é a variável de estratificação. Como temos dados de todas as empresas da população, as médias populacionais das variáveis de pesquisa são conhecidas. Entretanto, para efeitos do presente exemplo, vamos supor que seriam desconhecidas e que amostragem seria usada para sua estimação. Para estimar estas médias, as empresas da população foram divididas em dois estratos, definidos a partir da variável PO, conforme indicado na Tabela 4.2. Tabela 4.2: \\(\\text{Definição da estratificação da população de empresas}\\) Estrato Condição Tamanho 1 empresas com PO \\(&gt;21\\) \\(161\\) empresas 2 empresas com PO \\(\\leq21\\) \\(588\\) empresas A ideia seria então selecionar, de cada um dos estratos, amostras aleatórias simples sem reposição de tamanhos \\(n_h = 30\\) empresas, implicando em uso de alocação igual e em frações amostrais desiguais, em vista dos diferentes tamanhos populacionais dos estratos. Como o estrato 1 contém cerca de \\(21\\%\\) das observações da população, a proporção de \\(50\\%\\) das observações da amostra total sendo alocada no estrato 1 (das maiores empresas) da amostra é bem maior do que seria esperado sob amostragem aleatória simples da população de empresas. Em consequência, a média amostral simples \\(\\overline{y}\\) de qualquer das duas variáveis de pesquisa (SAL ou REC) dada por \\[ \\overline{y} = \\frac{1}{n} \\sum \\limits_{h=1}^{2} \\sum_{i \\in s_h} y_i = \\sum \\limits_{h=1}^{2} \\frac{n_h}{n} \\overline{y}_h \\] tenderia a superestimar a média populacional \\(\\overline{Y}\\) correspondente dada por \\[\\overline{Y} = \\frac{1}{N} \\sum\\limits_{h=1}^{2} \\sum_{i \\in U_{h}} y_{i} = \\sum \\limits_{h=1}^{2} \\frac{N_h}{N} \\overline{Y}_h\\] onde: \\(y_{i}\\) é o valor da variável de pesquisa \\(y\\), \\(y \\in \\{SAL; REC\\}\\), para a \\(i-\\)ésima observação; \\(n\\) é o tamanho total da amostra; \\(N\\) o tamanho total da população; \\(s_h\\) e \\(U_h\\) representam os conjuntos de unidades na amostra e na população do estrato \\(h\\) respectivamente; \\(n_h\\) é o número de unidades na amostra do estrato \\(h\\); \\(N_h\\) é o número de unidades na população do estrato \\(h\\); \\(\\overline{y}_{h} = \\frac{1}{n_{h}} \\sum_{i \\in s_h} y_i\\) é a média dos \\(y^{\\prime}s\\) na amostra no estrato \\(h \\in \\{1; 2\\}\\) e \\(\\overline{Y}_h = \\frac{1}{N_h} \\sum_{i \\in U_h} y_i\\) é a média populacional dos \\(y^{\\prime}s\\) no estrato \\(h \\in \\{1; 2\\}\\). É fácil verificar que o vício do estimador \\(\\overline{y}\\) para a média populacional \\(\\overline{Y}\\) é dado por: \\[ B_{AES}(\\overline{y}) = \\sum\\limits_{h=1}^{2} \\left( \\frac{n_h}{n} - \\frac{N_h}{N} \\right) \\overline{Y}_h \\] É fácil notar que sob alocação proporcional da amostra estratificada o vício seria nulo, o que não ocorre no presente exemplo. Como aqui a amostra estratificada carrega proporcionalmente mais unidades do estrato de maiores empresas, o valor deste viés será positivo. De fato, o valor exato deste vício pode ser calculado no presente exemplo onde conhecemos todos os dados das unidades da população. Para amostras estratificadas simples como a considerada neste exemplo, o estimador não viciado tipo Horvitz-Thompson da média populacional \\(\\overline{Y}\\) seria dado por \\[ \\overline{y}_w = \\sum\\limits_{h=1}^2 W_h \\overline{y}_h = \\frac{1}{N} \\sum\\limits_{h=1}^2 \\sum_{i \\in s_h} \\frac{N_h}{n_h} y_i \\] onde \\(W_h = N_h / N\\) é a proporção de unidades da população no estrato \\(h \\in \\{1; 2\\}\\). Com a finalidade de ilustrar o cálculo do \\(EPA\\), vamos considerar o estimador não viciado \\(\\overline{y}_{w}\\) e calcular sua variância sob o plano amostral realmente utilizado (amostragem estratificada simples - AES - com alocação igual, mas desproporcional). Essa variância poderá então ser comparada com o valor esperado (sob a distribuição induzida pelo plano amostral estratificado) do estimador da variância obtido sob a hipótese de amostragem aleatória simples. Neste exemplo, a variância do estimador \\(\\overline{y}_w\\) pode ser obtida de duas formas: calculando a expressão da variância utilizando os dados de todas as unidades da população (que são conhecidos, mas admitidos desconhecidos para fins do exercício de estimação de médias via amostragem) e por simulação. A variância de \\(\\overline{y}_w\\) sob a distribuição de aleatorização do plano amostral verdadeiro - AES - é dada por - ver a Seção 11.2.3 de P. L. N. Silva et al. (2020): \\[ V_{AES} \\left( \\overline{y}_w \\right) = \\sum\\limits_{h=1}^2 W_h^2 \\left( \\frac{1}{n_h} - \\frac{1}{N_h} \\right) S_h^2 \\quad \\tag{4.4} \\] onde \\(S_h^2 = \\frac{1}{N_h - 1} \\sum_{i \\in U_h} \\left(y_i - \\overline{Y}_h \\right)^2\\) é a variância populacional da variável de pesquisa \\(y\\) dentro do estrato \\(h\\). Conforme a Seção 11.2.3 de P. L. N. Silva et al. (2020), esta variância pode ser estimada sem viés sob AES usando o estimador \\[ \\widehat{V}_{AES} \\left( \\overline{y}_w \\right) = \\sum\\limits_{h=1}^2 W_h^2 \\left( \\frac{1}{n_h} - \\frac{1}{N_h} \\right) \\widehat{S}_h^2 \\quad \\tag{4.5} \\] onde \\(\\widehat{S}_h^2 = \\frac{1}{n_h - 1} \\sum_{i \\in s_h} (y_i - \\overline{y}_h)^2\\). Um estimador ingênuo da variância de \\(\\overline{y}\\) que seria usado sob amostragem aleatória simples é dado por \\[ v_{0} = \\left( \\frac{1}{n} - \\frac{1}{N} \\right) \\widehat{S}^2 \\] onde \\(\\widehat{S}^2 = \\frac{1}{n-1} \\sum\\limits_{h=1}^2 \\sum_{i \\in s_{h}} \\left(y_i - \\overline{y} \\right)^2\\). Note que tanto o estimador média amostral simples \\(\\overline{y}\\) como o correspondente estimador de variância \\(v_{0}\\) devem ser viciados no contexto da amostragem estratificada proposta neste exemplo. Mas a ideia do exemplo é justamente ilustrar os problemas que surgem quando se adota uma inferência padrão, dependente das hipóteses de observações IID (ou de AASC), como a que está disponível nos sistemas padrões de análise de dados, sem levar em conta os aspectos do plano amostral de fato usado para obtenção dos dados considerados na análise. O valor do \\(EPA\\) foi também estimado por meio de simulação. O motivo para usar simulação é que a obtenção do valor esperado sob AES de \\(v_{0}\\) de forma analítica é trabalhosa. Geramos então \\(500\\) amostras de tamanho \\(n=60\\), segundo o plano amostral estratificado considerado. Para cada uma das \\(500\\) amostras e cada uma das duas variáveis de pesquisa (SAL e REC) foram calculadas as estatísticas: média amostral (\\(\\overline{y}\\)); estimativa ponderada da média populacional (\\(\\overline{y}_{w}\\)); estimativa da variância da estimativa ponderada da média (\\(\\overline{y}\\)) considerando observações IID \\(v_{0}\\); estimativa da variância da estimativa ponderada da média (\\(\\overline{y}_{w}\\)) considerando o plano amostral verdadeiro \\(\\widehat{V}_{AES} \\left( \\overline{y}_{w} \\right)\\). Note que na apresentação dos resultados os valores dos salários foram expressos em milhares de Reais (R$ \\(1.000,00\\)) e os valores das receitas em milhões de Reais (R$ \\(1.000.000,00\\)). Como a população é conhecida, os parâmetros populacionais de interesse podem ser calculados, obtendo-se os valores na primeira linha da Tabela 4.3. Tabela 4.3: \\(\\text{Propriedades dos estimadores da média das variáveis de pesquisa}\\) Quantidade de interesse Salários Receitas Média Populacional 78,3 2,11 Média de estimativas de média AAS 163,3 4,18 Média de estimativas de média AES 77,8 2,10 Em contraste com os valores dos parâmetros populacionais, calculamos a média das médias amostrais não ponderadas (\\(\\overline{y}\\)) dos salários e das receitas obtidas nas \\(500\\) amostras simuladas, obtendo os valores na segunda linha da Tabela 4.3. Como previsto, observamos um viés para cima na estimação das médias populacionais, da ordem de \\(108,5\\%\\) para os salários e de \\(98,1\\%\\) para as receitas, demonstrando o que era esperado e o quanto seria inadequado neste exemplo ignorar os pesos amostrais na estimação da média populacional. XXX Rever estes parágrafos após calcular erros padrões e estatísticas t de teste XXX para o vício do estimador média ponderada Usamos também o estimador \\(\\overline{y}_{w}\\) para estimar a média dos salários e das receitas na população, obtendo para esse estimador as médias apresentadas na terceira linha da Tabela 4.3. Observamos ainda um pequeno vício relativo da ordem de \\(-0,6\\%\\) e \\(-0,5\\%\\) para os salários e receitas, respectivamente. Note que o estimador \\(\\overline{y}_{w}\\) é não viciado sob o plano amostral adotado, entretanto o pequeno vício observado na simulação não pode ser ignorado pois é significantemente diferente de \\(0\\) ao nível de significância de \\(5\\%\\), apesar do tamanho razoável da simulação (\\(500\\) replicações). XXX Além das estimativas pontuais, o interesse maior da simulação foi comparar valores de estimativas de variância e, consequentemente, de medidas do efeito do plano amostral. Como o estimador pontual dado pela média amostral não ponderada (\\(\\overline{y}\\)) é grosseiramente viciado, não consideramos estimativas de variância para esse estimador, mas tão somente para o estimador não viciado dado pela média ponderada \\(\\overline{y}_{w}\\). Para esse último, consideramos dois estimadores de variância, a saber o estimador ingênuo sob a hipótese de AASC (dado por \\(v_{0}\\), mas com o valor da estimativa de média usado no seu cálculo substituído por \\(\\overline{y}_{w}\\)) e um estimador não viciado da variância sob o plano amostral AES efetivamente empregado \\(\\widehat{V}_{AES}\\left( \\overline{y}_{w}\\right)\\) dado pela Expressão (4.5). Como neste exercício a população é conhecida, podemos calcular \\(V_{AES} \\left( \\overline{y}_{w} \\right)\\) através das variâncias de \\(y\\) dentro dos estratos \\(h=1,2\\) ou estimar essa variância através da simulação. Esses valores são apresentados respectivamente na primeira e segunda linhas da Tabela 4.4, para as duas variáveis de pesquisa consideradas. Tabela 4.4: \\(\\text{Propriedades dos estimadores de variância do estimador ponderado da média}\\) Quantidade de interesse Salários Receitas Variância do estimador AES 244 0,435 Média de estimativas de variância AES 243 0,505 Valor esperado AES do estimador AAS de variância 1.613 1,188 Média de estimativas de variância AAS 1.714 1,242 Os valores de \\(E_{VERD} \\left[ v_{0} \\left( \\overline{SAL}_{w} \\right) \\right]\\) e de \\(E_{VERD} \\left[ v_{0} \\left( \\overline{REC}_{w} \\right) \\right]\\) foram também calculados a partir das variâncias dentro e entre estratos na população, resultando nos valores na linha 3 da Tabela 4.4, e estimativas desses valores baseadas nas \\(500\\) amostras da simulação são apresentadas na linha 4 da Tabela 4.4. Os valores para o \\(EPA\\) foram calculados tanto com base nas estimativas de simulação como nos valores populacionais das variâncias, cujos cálculos estão ilustrados a seguir: \\(EPA\\left[ \\overline{SAL}_{w}, v_0 \\left(\\overline{SAL}_{w} \\right)\\right] =\\) ## 242,792358381168/1713,8055430219=0,142 \\(EPA\\left[ \\overline{REC}_{w},v_{0} \\left( \\overline{REC}_{w} \\right) \\right] =\\) ## 0,505416004004538/1,24157646252246=0,407 \\(EPA\\left[ \\overline{SAL}_{w}, v_{0} \\left( \\overline{SAL}_{w} \\right) \\right] =\\) ## 244,17580090709/1613,3=0,151 \\(EPA\\left[ \\overline{REC}_{w}, v_{0} \\left( \\overline{REC}_{w} \\right) \\right] =\\) ## 0,434994493392157/1,188=0,366 A Tabela 4.5 resume os principais resultados deste exercício, para o estimador ponderado da média \\(\\overline{y}_{w}\\). Apesar das diferenças entre os resultados da simulação e suas contrapartidas calculadas considerando conhecidos os valores da população, as conclusões da análise são similares: ignorar os pesos na estimação da média provoca vícios substanciais, que não podem ser ignorados; portanto, o uso do estimador simples de média (\\(\\overline{y}\\)) é desaconselhado; ignorar os pesos na estimação da variância do estimador ponderado \\(\\overline{y}_{w}\\) também provoca vícios substanciais, neste caso, superestimando a variância por ignorar o efeito de estratificação; os efeitos do plano amostral são substancialmente menores que \\(1\\) para as duas variáveis de pesquisa consideradas (salários e receita); portanto o uso do estimador ingênuo de variância \\(v_{0}\\) é desaconselhado. Essas conclusões são largamente aceitas pelos amostristas e produtores de dados baseados em pesquisas amostrais para o caso da estimação de médias e totais, e respectivas variâncias. Entretanto, ainda há exemplos de usos indevidos de dados amostrais nos quais os pesos e outros aspectos importantes dos planos amostrais complexos de fato empregados para obter os dados são ignorados nas análises, em particular para a estimação de variâncias associadas a estimativas pontuais de médias e de parâmetros de modelos. Tal situação se deve ao uso ingênuo de sistemas estatísticos padrões desenvolvidos para analisar amostras IID, sem a devida consideração dos pesos e outros aspectos da estrutura do plano amostral empregado para obtenção dos dados. Tabela 4.5: \\(\\text{Estimativas da variância e do efeito do plano amostral para as médias dos salários e receitas}\\) Variável Estimativa Simulação População Salário Variância 242,792 244,176 Salário \\(EPA\\) 0,142 0,151 Receita Variância 0,505 0,435 Receita \\(EPA\\) 0,407 0,366 Observação 4.1: Neste exemplo não foi feito uso analítico dos dados e sim descritivo, onde é usual incorporar os pesos no cálculo de estimativas e variâncias. Não seria esperado usar um estimador ponderado para a média e não considerar os pesos no cálculo de variâncias, como fizemos neste exemplo. Observação 4.2: O exemplo mostra que ignorar a estratificação ao calcular \\(v_{0}\\) diminui o \\(EPA\\). Um outro exemplo relevante é utilizado a seguir para ilustrar o fato de que o conceito do \\(EPA\\) adotado aqui é mais abrangente do que o definido por Kish (1965), em particular porque a origem do efeito pode estar na estrutura da população e não no plano amostral usado para obter os dados. Exemplo 4.3 População conglomerada com conglomerados de tamanho 2 - Skinner et al. (1989), página 25 Considere uma população de unidades agrupadas em conglomerados de tamanho \\(2\\), isto é, onde as unidades (elementares ou de referência) estão grupadas em pares (exemplos de tais populações incluem pares de irmãos gêmeos, casais, jogadores numa dupla de vôlei de praia ou de tênis, etc.). Suponha que os valores de uma variável de pesquisa medida nessas unidades têm média \\(\\theta\\) e variância \\(\\sigma^{2}\\), além de uma correlação \\(\\rho\\) entre os valores dentro de cada par (correlação intraclasse, veja P. L. N. Silva e Moura (1990), Capítulo 2 e Haggard (1958)). Suponha que um único par é sorteado ao acaso da população e que os valores \\(y_{1}\\) e \\(y_{2}\\) são observados para as duas unidades do par selecionado. O modelo assumido \\(M\\) pode então ser representado como \\[ M = \\left\\{ \\begin{array}{l} E_{M}\\left( Y_{i}\\right) =\\theta \\\\ V_{M}\\left( Y_{i}\\right) =\\sigma ^{2} \\\\ CORR_{M}\\left( Y_{1};Y_{2}\\right) =\\rho \\end{array} \\right. \\;\\;i=1,2. \\] Um estimador não viciado para \\(\\theta\\) é a média amostral dada por \\(\\widehat{\\theta } = (y_{1}+y_{2})/2\\). Assumindo a (falsa) hipótese de que o esquema amostral é AASC de unidades individuais e não de pares ou, equivalentemente, que \\(y_{1}\\) e \\(y_{2}\\) são observações de variáveis aleatórias IID, a variância de \\(\\widehat{\\theta}\\) é dada por \\[ V_{AASC} \\left( \\widehat{\\theta } \\right) = \\sigma^{2}/2 \\] com um estimador não viciado dado por \\[ v_{0} \\left( \\widehat{\\theta } \\right) = (y_{1} - y_{2})^{2}/4 \\] Entretanto, na realidade a variância de \\(\\widehat{\\theta}\\) é dada por \\[ V_{VERD} \\left( \\widehat{\\theta } \\right) = V_{M} \\left( \\widehat{\\theta} \\right) = \\sigma^{2} (1 + \\rho)/2 \\] O valor esperado do estimador de variância \\(v_{0} \\left( \\widehat{\\theta} \\right)\\) é dado por \\[ E_{VERD} \\left[ v_{0} \\left( \\widehat{\\theta} \\right) \\right] = \\sigma^{2} (1 - \\rho) / 2 \\] Consequentemente, considerando as equações (4.1) e (4.2), tem-se que \\[ EPA_{Kish} \\left( \\widehat{\\theta} \\right) = 1 + \\rho \\] e o efeito do plano amostral ampliado é \\[ EPA \\left( \\widehat{\\theta}, v_{0} \\right) = (1 + \\rho) / (1 - \\rho) \\] A Figura 4.1 mostra os valores de \\(EPA_{Kish} \\left( \\widehat{\\theta} \\right)\\) e \\(EPA \\left( \\widehat{\\theta}, v_{0} \\right)\\) para valores de \\(\\rho\\) entre \\(0\\) e \\(0,8\\). Como se pode notar, o efeito da especificação inadequada do plano amostral ou da estrutura populacional pode ser severo, com valores de \\(EPA \\left( \\widehat{\\theta} , v_{0} \\right)\\) chegando a \\(9\\). Um aspecto importante a notar é que o \\(EPA_{Kish} \\left( \\widehat{\\theta} \\right)\\) tem variação muito mais modesta que o \\(EPA \\left( \\widehat{\\theta} , v_{0} \\right)\\). Figura 4.1: Valores de \\(EPA\\) e \\(EPA\\) de Kish para conglomeração Este exemplo ilustra bem dois aspectos distintos do uso de medidas como as duas propostas para avaliar o efeito do plano amostral. O primeiro é que as duas medidas são distintas, embora as respectivas estimativas baseadas numa particular amostra seriam coincidentes, conforme discutido ao apresentar o estimador na Expressão (4.3). No caso particular deste exemplo, o \\(EPA_{Kish} \\left( \\widehat{\\theta} \\right)\\) cresce pouco com o valor do coeficiente de correlação intraclasse \\(\\rho\\), o que implica que um plano amostral conglomerado como o adotado (seleção ao acaso de um par da população) seria menos eficiente que um plano amostral aleatório simples (seleção de duas unidades ao acaso da população), mas a perda de eficiência seria modesta. Isto se dá porque os tamanhos dos conglomerados são bem pequenos - duas unidades. Já se o interesse é medir, a posteriori, o efeito da má especificação do plano amostral no estimador de variância, o impacto, medido pelo \\(EPA \\left( \\widehat{\\theta} , v_{0} \\right)\\), seria muito maior. Assim, a imprudência na estimação de variâncias (e erros padrões, intervalos de confiança, testes de significância, etc.) teria consequências bem mais sérias para as análises. Vale ainda notar que o \\(EPA \\left( \\widehat{\\theta} , v_{0} \\right)\\) mede o impacto da má especificação do plano amostral ou do modelo para a estrutura populacional. Neste exemplo, ignorar a estrutura da população (o fato de que as observações são pareadas) poderia provocar subestimação da variância do estimador de média, que seria tanto maior quanto maior fosse o coeficiente de correlação intraclasse \\(\\rho\\). Efeitos como esse são comuns devido ao planejamento amostral, mesmo em populações onde a conglomeração é imposta artificialmente pelo amostrista. 4.4 Efeitos sobre intervalos de confiança e testes de hipóteses uniparamétricos A partir da estimativa pontual \\(\\widehat{\\theta}\\) de um parâmetro \\(\\theta\\) (da população finita ou do modelo de superpopulação) é possível construir um intervalo de confiança de nível de confiança aproximado \\(\\left( 1 - \\alpha \\right)\\) a partir da distribuição assintótica de \\[ t_0 = \\frac{\\widehat{\\theta} - \\theta} {v_0^{1/2}} \\] que, sob a hipótese de que as observações são IID, tem distribuição bem aproximada pela \\(N(0 ; 1)\\) para amostras grandes. Neste caso, um intervalo de nível de confiança aproximado \\(\\left( 1 - \\alpha \\right)\\) é dado por \\(\\left[ \\widehat{\\theta} \\mp z_{\\alpha/2} v_0^{1/2} \\right]\\), onde \\(z_{\\alpha/2}\\) é o quantil que deixa área igual a \\(\\alpha/2\\) à sua direita sob a curva da função de densidade da distribuição normal padrão ou \\(N(0 ; 1)\\). Vamos agora analisar o efeito de um plano amostral complexo sobre o intervalo de confiança. Nesse caso, a distribuição que é aproximadamente normal é a da estatística pivô dada por: \\[ t = \\frac{\\widehat{\\theta} - \\theta} {\\left[ \\widehat{V}_{VERD} \\left( \\widehat{\\theta} \\right) \\right]^{1/2}} \\] Por outro lado, para obter a variância da distribuição assintótica de \\(t\\) note que \\[ t_0 = \\frac{\\widehat{\\theta} - \\theta } {v_{0}^{1/2}} = \\frac{\\widehat{\\theta} - \\theta} { \\left[ \\widehat{V}_{VERD} \\left( \\widehat{\\theta} \\right) \\right]^{1/2}} \\times \\frac{ \\left[ \\widehat{V}_{VERD} \\left( \\widehat{\\theta} \\right) \\right] ^{1/2}}{v_{0}^{1/2}} = t \\times \\left[ \\widehat{EPA} \\left( \\widehat{\\theta}, v_{0} \\right) \\right]^{1/2} \\] Como a distribuição de \\(t\\) tende para uma \\(N\\left( 0;1\\right)\\), a variância assintótica de \\(t_{0}\\) é aproximadamente igual ao quadrado do limite do segundo fator no lado direito da expressão, isto é, a \\(EPA\\left( \\widehat{\\theta}, v_0 \\right)\\). Logo temos que a distribuição assintótica de \\(t_{0}\\) é dada por \\[ t_{0} \\approx N \\left( 0 ; EPA \\left( \\widehat{\\theta}, v_{0} \\right) \\right) \\] Dependendo do valor de \\(EPA \\left( \\widehat{\\theta} , v_0 \\right)\\), o intervalo de confiança baseado na distribuição assintótica verdadeira de \\(t_0\\) pode ser bem distinto daquele baseado na distribuição assintótica obtida sob a hipótese de observações IID. Em geral, a probabilidade de cobertura assintótica do intervalo \\(\\left[ \\widehat{\\theta} \\mp z_{\\alpha /2} v_{0}^{1/2} \\right]\\) será aproximadamente igual a \\[ 2 \\Phi \\left( z_{\\alpha/2} / \\left[ EPA \\left( \\widehat{\\theta} , v_0 \\right) \\right]^{1/2} \\right) - 1 \\] onde \\(\\Phi\\) é a função de distribuição acumulada da distribuição normal padrão. Calculamos esta probabilidade para alguns valores do \\(EPA\\), que apresentamos na Tabela 4.6. Tabela 4.6: \\(\\text{Probabilidades de cobertura para níveis nominais de 0,95 e 0,99}\\) \\(EPA \\left( \\widehat{\\theta}, v_0\\right)\\) \\(1-\\alpha=0,95\\) \\(1-\\alpha=0,99\\) 0,90 0,96 0,99 0,95 0,96 0,99 1,0 0,95 0,99 1,5 0,89 0,96 2,0 0,83 0,93 2,5 0,78 0,90 3,0 0,74 0,86 3,5 0,71 0,83 4,0 0,67 0,80 À medida que o valor do \\(EPA \\left( \\widehat{\\theta}, v_0 \\right)\\) aumenta, a probabilidade real de cobertura diminui, sendo menor que o valor nominal para valores de \\(EPA \\left( \\widehat{\\theta}, v_0 \\right)\\) maiores que 1, como esperado, já que nestes casos o estimador ingênuo \\(v_0\\) subestima a variância verdadeira do estimador. Utilizando a correspondência existente entre intervalos de confiança e testes de hipóteses, podemos derivar os níveis de significância nominais e reais subtraindo de \\(1\\) os valores da Tabela 4.6. Por exemplo, para \\(\\alpha = 0,05\\) e \\(EPA \\left( \\widehat{\\theta}, v_0 \\right) = 2\\), o nível de significância real seria aproximadamente \\(1 - 0,83 = 0,17\\). Exemplo 4.4 Teste de hipótese sobre proporção Vamos considerar um exemplo hipotético de teste de hipótese sobre uma proporção, semelhante ao de Sudman (1976), apresentado na página 196 de Lehtonen e Pahkinen (1995). Uma amostra de \\(m = 50\\) conglomerados é extraída de uma grande população de empresas industriais (conglomerados de empregados). Suponhamos que cada empresa \\(i = 1, \\ldots ,50\\) da amostra tenha \\(n_{i} = 20\\) empregados. O tamanho total da amostra de empregados (unidades elementares) é \\(n = \\sum_{i \\in s} n_i = 1.000\\). Queremos estudar o acesso dos trabalhadores das empresas a planos de saúde. Usando-se conhecimento do ano anterior, foi estabelecida a hipótese de que a proporção de trabalhadores cobertos por planos de saúde é \\(80\\%\\), ou seja \\(H_{0}: p = p_{0} = 0,8\\). Vamos adotar o nível de significância \\(\\alpha = 5\\%\\). A estimativa obtida na pesquisa foi \\(\\widehat{p} = n_A / n = 0,84\\), onde \\(n_A = 840\\) é o número de trabalhadores na amostra com acesso a planos de saúde. Ignorando o plano amostral e a conglomeração das unidades elementares na população, podemos considerar um teste binomial e usar a aproximação normal \\(N(0;1)\\) para a estatística de teste \\[ Z_{AASC} = |\\widehat{p} - p_0| / \\sqrt{p_0 \\left( 1 - p_0 \\right)/ n} \\,\\,\\, \\tag{4.6} \\] onde o denominador é o desvio padrão da estimativa \\(\\widehat{p}\\) sob a hipótese nula, e consideramos como hipótese alternativa \\(H_A: \\, \\, p \\neq 0,8\\). Vamos calcular o valor da estatística \\(Z_{AASC}\\), supondo que tenha sido usada amostragem aleatória simples com reposição - AASC de empregados. Vamos também considerar uma abordagem baseada no plano amostral de conglomerados. O desvio padrão de \\(\\widehat{p}\\), no denominador de \\(Z_{AASC}\\), será baseado na hipótese de distribuição binomial, com tamanhos amostrais diferentes para as duas abordagens. Para o teste baseado na AASC, ignoramos a conglomeração e usamos na fórmula do desvio padrão do estimador \\(\\widehat p\\) da proporção o tamanho total da amostra de unidades elementares (empregados), isto é, \\(n = 1.000\\). O valor da estatística de teste \\(Z_{AASC}\\) definida em (4.6) fica, portanto, igual a \\[ Z_{AASC} = |0,84 - 0,8| / \\sqrt{0,8 \\left( 1 - 0,8 \\right) / 1.000} = 3,162 &gt; z_{0,975} = 1,96 \\,\\,\\, \\] onde \\(\\sqrt{0,8 \\left( 1 - 0,8 \\right) / 1.000} = 0,0126\\) é o desvio padrão de \\(\\widehat{p}\\) sob a hipótese nula e \\(z_{0,975}\\) é o quantil que deixa área de \\(0,975\\) à sua esquerda sob a densidade da distribuição normal padrão. Este resultado indica a rejeição da hipótese \\(H_0\\) ao nível de significância estabelecido. Por outro lado, é razoável admitir que se uma empresa oferece cobertura por plano de saúde, cada empregado dessa empresa terá acesso ao benefício. Essa é uma informação importante que foi ignorada no teste anterior. De fato, selecionar mais de uma pessoa numa empresa não aumenta nosso conhecimento sobre a cobertura por plano de saúde no local. Portanto, o tamanho efetivo da amostra é \\(\\overline{n} = 50\\), em contraste com o valor \\(1.000\\) usado no teste anterior. O termo tamanho efetivo foi introduzido em Kish (1965) para designar o tamanho de uma amostra aleatória simples necessário para estimar \\(p\\) com a mesma precisão obtida por uma amostra conglomerada de tamanho \\(n\\) (neste caso, igual a \\(1.000\\)) unidades elementares. Usando o tamanho efetivo de amostra, temos a estatística de teste baseada no plano amostral verdadeiro \\[ Z_{VERD} = |\\widehat{p} - p_0| / \\sqrt{p_0 \\left( 1 - p_0 \\right) / \\overline n} = |0,84 - 0,8| / \\sqrt{0,8 \\left( 1 - 0,8 \\right) / 50} = 0,707 \\] onde o valor \\(\\sqrt{0,8 \\left( 1 - 0,8 \\right) / 50} = 0,0566\\) é muito maior que o valor do desvio padrão empregado no cálculo da estatística de teste \\(Z_{AASC}\\). Em consequência, o valor observado de \\(Z_{VERD}\\) é menor que o limite de aceitação \\(z_{0,975} = 1,96\\), e a nova estatística de teste indica a não rejeição da mesma hipótese nula. Neste exemplo, portanto, se verifica que ignorar a conglomeração pode induzir a uma decisão incorreta de rejeitar a hipótese nula, quando a mesma não seria rejeitada se o plano amostral de fato empregado fosse corretamente incorporado na análise. Efeitos desse tipo são mais difíceis de antecipar para inferência analítica, particularmente quando os planos amostrais empregados envolvem combinações de estratificação, conglomeração, probabilidades desiguais de seleção e calibração de pesos. Por esse motivo, a recomendação é procurar sempre considerar o plano amostral na análise, ao menos como forma de verificar se as conclusões obtidas por formas ingênuas de análise ignorando os pesos e plano amostral seriam mantidas. 4.5 Efeitos multivariados do plano amostral O conceito de efeito do plano amostral introduzido em (4.2) é relativo a inferências sobre um único parâmetro \\(\\theta\\). Consideremos agora o problema de estimação de um vetor \\(\\boldsymbol{\\theta}\\) contendo \\(K\\) parâmetros. Seja \\(\\boldsymbol{\\widehat{\\theta}}\\) um estimador de \\(\\boldsymbol{\\theta}\\) e seja \\(\\mathbf{V}_{0}\\) um estimador da matriz \\(K \\times K\\) de covariância de \\(\\boldsymbol{\\widehat{\\theta}}\\), baseado nas hipóteses de independência e igualdade de distribuição das observações - IID, ou equivalentemente, de amostragem aleatória simples com reposição - AASC. É possível generalizar a equação (4.2), definindo o Efeito Multivariado do Plano Amostral - EMPA de \\(\\boldsymbol{\\widehat{\\theta}}\\) e seu estimador ingênuo de variância \\(\\mathbf{V}_0\\) como: \\[ \\mathbf{EMPA} (\\boldsymbol{\\widehat{\\theta}} , \\mathbf{V}_0) = \\boldsymbol{\\Delta} = \\left[ E_{VERD} \\left( \\mathbf{V}_0 \\right) \\right]^{-1} \\times \\mathbf{V}_{VERD} (\\boldsymbol{\\widehat{\\theta}}) \\quad \\tag{4.7} \\] onde \\(E_{VERD} \\left( \\mathbf{V}_0 \\right)\\) é o valor esperado de \\(\\mathbf{V}_0\\) e \\(\\mathbf{V}_{VERD}(\\boldsymbol{\\widehat{\\theta})}\\) é a matriz de covariância de \\(\\boldsymbol{\\widehat{\\theta}}\\), ambos calculados com respeito à distribuição induzida pelo plano amostral efetivamente utilizado (verdadeiro), ou alternativamente sob o modelo correto. Os autovalores \\(\\delta_1 \\geq \\ldots \\geq \\delta_K\\) da matriz \\(\\boldsymbol{\\Delta}\\) são denominados efeitos generalizados do plano amostral. A partir deles, e utilizando resultados padrões de teoria das matrizes (Johnson e Wichern (1988), página 64) é possível definir limites para os efeitos (univariados) do plano amostral para qualquer combinação linear \\(\\mathbf{c}^{\\prime} \\widehat{\\boldsymbol{\\theta}}\\) das componentes de \\(\\widehat{\\boldsymbol{\\theta}}\\). Segundo Skinner (1989b), página 43, temos os seguintes resultados: \\[ \\begin{array}{ccc} \\delta_{1} &amp; = &amp; \\max \\left\\{ EPA(\\mathbf{c^{\\prime}} \\widehat{\\boldsymbol{ \\theta}} , \\mathbf{c^{\\prime}}\\mathbf{V}_{0}\\mathbf{c)} \\right\\} \\\\ \\delta_{K} &amp; = &amp;\\min \\left\\{ EPA(\\mathbf{c^{\\prime}} \\widehat{\\boldsymbol{ \\theta}} , \\mathbf{c^{\\prime}}\\mathbf{V}_{0}\\mathbf{c)} \\right\\} \\end{array} \\] No caso particular onde \\(\\boldsymbol{\\Delta = I}_K\\), temos \\(\\delta_1 = \\ldots = \\delta_K = 1\\) e os efeitos (univariados) do plano amostral das combinações lineares para componentes de \\(\\boldsymbol{\\widehat{\\theta}}\\) são todos iguais a \\(1\\). Para ilustrar esse conceito, vamos reconsiderar o Exemplo 4.2 de estimação de médias com amostragem estratificada desproporcional anteriormente apresentado, mas agora considerando a natureza multivariada do problema (há duas variáveis de pesquisa - SAL e REC). Exemplo 4.5 Efeitos Multivariados do Plano Amostral para as médias de Salários e de Receitas Vamos considerar as variáveis Salário (em R$ \\(1.000\\)) e Receita (em R$ \\(1.000.000\\)) definidas na população de empresas do Exemplo 4.2 e calcular a matriz \\(\\mathbf{EMPA}\\left( \\boldsymbol{\\widehat{\\theta}, V}_{0} \\right)\\), onde \\(\\boldsymbol{\\widehat{\\theta} = } \\left( \\overline{SAL}_{w}, \\overline{REC}_{w} \\right)^{\\prime}\\). Neste exemplo, os dados populacionais são conhecidos e, portanto, podemos calcular a covariância dos estimadores \\(\\left( \\overline{SAL}_{w}, \\overline{REC}_{w}\\right)\\). Usando a mesma notação do Exemplo 4.2, temos que: \\[ COV_{AES} (\\overline{SAL}_w , \\overline{REC}_w ) = \\sum\\limits_{h=1}^{2} W_{h}^{2} \\left(\\frac{1}{n_h} - \\frac{1}{N_h}\\right) S_{SAL,REC}^{\\left(h\\right)} \\] onde \\[ S_{SAL,REC}^{\\left(h\\right) } = \\frac{1} {N_h - 1} \\sum\\limits_{i \\in U_{h}} \\left( SAL_i - \\overline{SAL}_{h} \\right) \\left( REC_i - \\overline{REC}_{h} \\right) \\] Substituindo os valores conhecidos na população das variáveis \\(SAL_i\\) e \\(REC_i\\), obtemos para esta covariância o valor \\[ COV_{AES} \\left( \\overline{SAL}_w , \\overline{REC}_w \\right) = 3,2358 \\] e portanto a matriz de variância \\(\\mathbf{V}_{AES} \\left(\\overline{SAL}_w , \\overline{REC}_w \\right)\\) dos estimadores ponderados da média fica igual a SAL REC SAL 244,18 3,24 REC 3,24 0,43 onde os valores das variâncias usadas nos cálculos com a Expressão (4.7) foram os obtidos no Exemplo 4.2 e coincidem, respectivamente, com os valores usados nos numeradores de \\(EPA\\left( \\overline{SAL}_w\\right)\\) e de \\(EPA\\left( \\overline{REC}_w\\right)\\) lá apresentados. Para calcular o \\(\\mathbf{EMPA}(\\boldsymbol{\\widehat{\\theta}, V}_0)\\) é preciso agora obter \\(E_{VERD}\\left(\\mathbf{V}_0\\right)\\). Neste exemplo, a matriz de efeito do plano amostral \\(\\mathbf{EMPA} \\left(\\boldsymbol{\\widehat{\\theta} , V}_0 \\right) = \\boldsymbol{\\Delta}\\) pode também ser calculada através de simulação, de modo análogo ao que foi feito no Exemplo 4.2. Para isto, foram utilizadas as \\(500\\) amostras de tamanho \\(60\\) segundo o plano amostral descrito no Exemplo 4.2. Para cada uma das \\(500\\) amostras foram calculadas estimativas: da variância da média amostral ponderada do salário e da receita assumindo observações IID; da covariância entre médias ponderadas do salário e da receita assumindo observações IID; da variância da média amostral ponderada do salário e da receita considerando o plano amostral verdadeiro; da covariância entre médias ponderadas do salário e da receita considerando o plano amostral verdadeiro. A partir da simulação foram obtidos os seguintes resultados: A matriz de covariância das médias amostrais ponderadas de salário e da receita, supondo observações IID \\(E_{AES} \\left( \\mathbf{V}_0\\right)\\): SAL REC SAL 1713,8 26,3 REC 26,3 1,2 A matriz de covariância das médias ponderadas de salário e da receita considerando o plano amostral verdadeiro \\(\\mathbf{V}_{AES} \\left( \\boldsymbol{\\widehat{\\theta}} \\right)\\): SAL REC SAL 242,8 3,1 REC 3,1 0,5 A matriz \\(\\Delta\\) definida em (4.7) \\[ \\boldsymbol{\\Delta} = \\left[ E_{AES} \\left(\\mathbf{V}_0 \\right) \\right]^{-1} \\times \\mathbf{V}_{AES} (\\widehat{\\boldsymbol{\\theta}}) \\] sal rec [1,] 0,153 -0,00656 [2,] -0,740 0,54597 Os autovalores 1 e 1,02 de \\(\\boldsymbol{\\Delta}\\) fornecem os efeitos generalizados do plano amostral. Da mesma forma que o \\(EPA\\left( \\widehat{\\theta}, v_0 \\right)\\) definido em (4.2) para o caso uniparamétrico foi utilizado para corrigir níveis de confiança de intervalos e níveis de significância de testes, o \\(\\mathbf{EMPA} (\\boldsymbol{\\widehat{\\theta} , V}_0)\\) definido em (4.7) pode ser utilizado para corrigir níveis de regiões de confiança e também de significância de testes de hipóteses no caso multiparamétrico. Para ilustrar, vamos considerar o problema de testar a hipótese \\(H_0: \\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0\\), onde \\(\\boldsymbol{\\theta}\\) é o vetor de médias de um vetor de variáveis de pesquisa \\(\\mathbf{y}\\). A estatística de teste usualmente adotada para este caso - ver Johnson e Wichern (1988), página 171 - é a \\(T^{2}\\) de Hottelling dada por \\[ T^{2} = n \\left( \\boldsymbol{\\overline{y} - \\theta}_{0} \\right)^{^{\\prime}} \\mathbf{S}_{y}^{-1} \\left( \\boldsymbol{\\overline{y} - \\theta}_{0} \\right) \\,\\,\\, \\tag{4.8} \\] onde: \\[ \\begin{array}{ccl} \\, \\mathbf{\\overline y} &amp; = &amp; \\frac{1}{n} \\sum_{i \\in s} \\mathbf{y}_{i} \\\\ \\mathbf{S}_{y} &amp; = &amp; \\frac{1}{n-1} \\sum_{i \\in s} \\left( \\mathbf{y}_{i} - \\mathbf{\\overline{y}} \\right) \\left( \\mathbf{y}_{i} - \\mathbf{\\overline{y}} \\right)^{^{\\prime }} \\\\ \\boldsymbol{\\theta}_{0} &amp; = &amp; \\left( \\theta _{0;1}, \\theta _{0;2}, \\ldots , \\theta _{0;K} \\right)^{^{\\prime}} \\;\\; \\end{array} \\] Sob \\(H_0\\), se as observações \\(\\mathbf{y}_{i}\\) forem IID normais, a estatística \\(T^2\\) tem a distribuição \\(\\frac{ (n - 1)K } { n - K } F{\\left( K ; n - K \\right)}\\), onde \\(F{\\left( K ; n - K \\right)}\\) denota uma variável aleatória com distribuição \\(F\\) com \\(K\\) e \\(\\left(n - K\\right)\\) graus de liberdade. Mesmo se as observações \\(\\mathbf{y}_i\\) não tiverem distribuição normal, \\(T^2\\) tem distribuição assintótica \\(\\chi^{2} \\left( K \\right)\\) quando \\(n \\rightarrow \\infty\\), Johnson e Wichern (1988), página 191. Contudo, se for utilizado um plano amostral complexo, \\(T^2\\) tem aproximadamente a distribuição da variável \\(\\sum_{k=1}^K \\delta_k Z_k^{2}\\), onde \\(Z_1, \\ldots , Z_K\\) são variáveis aleatórias independentes com distribuição normal padrão e os \\(\\delta_k\\) são os autovalores da matriz \\(\\boldsymbol{\\Delta} = \\boldsymbol{\\Sigma}_{AASC}^{-1} \\boldsymbol{\\Sigma}_p\\), onde \\(\\boldsymbol{\\Sigma}_{AASC} = E_p (\\mathbf{S}_y/n)\\) e \\(\\boldsymbol{\\Sigma}_p = V_p (\\mathbf{\\overline{y})}\\). Vamos analisar o efeito do plano amostral sobre o nível de significância deste teste. Para simplificar, consideremos o caso em que \\(\\delta_1 = \\ldots = \\delta_K = \\delta\\). Neste caso, o nível de significância real é dado aproximadamente por \\[ P \\left(T^2 &gt; \\chi_{\\alpha }^{2} \\left( K \\right) / \\delta \\right) \\quad \\tag{4.9} \\] onde \\(\\chi_{\\alpha}^{2}\\left(K\\right)\\) é o quantil superior \\(\\alpha\\) de uma distribuição \\(\\chi^2\\) com \\(K\\) graus de liberdade, isto é, o valor tal que \\(P\\left[ \\chi^2\\left(K\\right) &gt; \\chi_{\\alpha}^2 \\left(K\\right) \\right] = \\alpha\\) . A Tabela 4.7 apresenta os níveis de significância reais para \\(\\alpha = 5\\%\\) para vários valores de \\(K\\) e \\(\\delta\\). Mesmo quando os valores dos \\(\\delta_k\\) são distintos, os valores da Tabela 4.7 podem ser devidamente interpretados. Para isso, consideremos o valor-\\(p\\) do teste da hipótese \\(H_{0}: \\boldsymbol{\\theta }=\\boldsymbol{\\theta}_{0}\\), sob a hipótese de AASC e sob o plano amostral efetivamente utilizado. Por definição este valor é dado por \\[ \\mbox{valor-}p_{AASC} \\left( \\mathbf{\\overline{y}} \\right) = P\\left[ \\chi^{2} \\left( K \\right) &gt; \\left( \\boldsymbol{\\overline{y} - \\theta}_{0} \\right)^{{\\prime}} \\boldsymbol{\\Sigma}_{AASC}^{-1} \\left( \\boldsymbol{\\overline{y} - \\theta}_{0} \\right) \\right] \\] e \\(H_0\\) é rejeitada com nível de significância \\(\\alpha\\) se \\(\\mbox{valor-}p_{AASC} &lt; \\alpha\\). O verdadeiro \\(\\mbox{valor-}p_{AASC}\\) pode ser definido analogamente como \\[ \\mbox{valor-}p_{VERD} \\left( \\mathbf{\\overline{y}} \\right) = P\\left[ \\chi^{2} \\left( K \\right) &gt; \\left( \\boldsymbol{\\overline{y} - \\theta}_0 \\right)^{\\prime} \\boldsymbol{\\Sigma}_{VERD}^{-1} \\left( \\boldsymbol{\\overline{y} - \\theta}_0 \\right) \\right] \\quad \\tag{4.10} \\] Os valores na Tabela 4.7 podem ser usados para quantificar a diferença entre estes valores-\\(p\\). Consideremos a região crítica do teste de nível \\(\\alpha\\) baseado na hipótese de AASC: \\[ \\begin{array}{ccl} RC_{AASC}\\left( \\mathbf{\\overline{y}}\\right) &amp;=&amp; \\left\\{ \\mathbf{\\overline{y}:} \\quad \\left( \\boldsymbol{\\overline{y} - \\theta }_0\\right)^{\\prime } \\boldsymbol{\\Sigma}_{AASC}^{-1} \\left( \\boldsymbol{\\overline{y} - \\theta}_0\\right) &gt; \\chi_{\\alpha}^2 \\left(K\\right) \\right\\} \\quad \\tag{4.11} \\\\ &amp;=&amp;\\left\\{ \\mathbf{\\overline{y}:} \\quad \\mbox{valor-}p_{AASC} \\left(\\mathbf{\\overline{y}} \\right) &lt; \\alpha \\right\\} \\end{array} \\] Pode-se mostrar - ver Skinner (1989b), página 43 - que o máximo de \\(\\text{valor-}p_{VERD} \\left(\\mathbf{\\overline{y}}\\right)\\) quando \\(\\mathbf{\\overline{y}}\\) pertence à \\(RC_{AASC}\\left(\\mathbf{\\overline{y}}\\right)\\) é dado por: \\[ \\max_{\\mathbf{\\overline{y}} \\in RC_{AASC} \\left( \\mathbf{\\overline{y}}\\right) } \\mbox{valor-}p_{VERD} \\left(\\mathbf{\\overline{y}}\\right) = P \\left[ \\chi^2(K) &gt; \\chi_{\\alpha}^2(K) / \\delta _{1} \\right] \\quad \\tag{4.12} \\] Observe que o segundo membro de (4.12) é da mesma forma que o segundo membro de (4.9). Logo, os valores da Tabela 4.7 podem ser interpretados como valores máximos \\(\\mbox{valor-}p_{VERD} \\left(\\mathbf{\\overline{y}}\\right)\\) para \\(\\mathbf{\\overline{y}}\\) na região \\(RC_{AASC}\\left(\\mathbf{\\overline{y}}\\right)\\), considerando-se \\(\\delta_{1}\\) no lugar de \\(\\delta\\). Tabela 4.7: \\(\\text{Níveis de significância verdadeiros, em porcentagem, do teste } T^2 \\text{ para o nível nominal}\\) \\(\\text{de 5 por cento assumindo autovalores iguais a }\\delta\\) \\(\\delta\\) K=1 K=2 K=3 K=4 0,9 4 4 3 3 1,0 5 5 5 5 1,5 11 14 16 19 2,0 17 22 27 32 2,5 22 30 37 44 3,0 26 37 46 53 Os valores apresentados na Tabela 4.7 mostram que, mesmo quando os efeitos do plano amostral são modestos (valores iguais a 1,5, por exemplo) os níveis de significância reais são bem maiores que o nível nominal especificado. Além disso, esses níveis crescem rapidamente com o número de parâmetros \\(K\\) considerados na estatística de teste. Vale então reforçar o alerta aos analistas de dados para que não deixem de levar em conta o plano amostral empregado para obter os dados usados em suas análises, sob pena de tomarem decisões incorretas com frequências muito acima das que seriam aceitáveis em aplicações dos testes de hipóteses considerados. 4.6 Laboratório de R Utilizando o R, obtemos a seguir alguns resultados descritos nos Exemplos 4.2 e 4.5. Na simulação, usamos o pacote sampling (Tillé e Matei, 2016) para gerar amostras estratificadas de tamanho \\(n=60\\), com estratos definidos na Tabela 4.2, para obter os valores nas Tabelas 4.3 e 4.4. # carrega library library(survey) # carrega dados #library(anamco) popul_dat &lt;- readRDS(file = &#39;data/popul.rds&#39;) # carrega dados N &lt;- nrow(popul_dat) n1 &lt;- 30 n2 &lt;- 30 nh = c(n1, n2) n &lt;- sum(nh) Nh &lt;- table(popul_dat$estrat) fh &lt;- nh/Nh Wh &lt;- Nh/N f &lt;- n/N popul_dat$sal &lt;- popul_dat$sal/1000 popul_dat$rec &lt;- popul_dat$rec/1e+06 library(sampling) # define espaços para salvar resultados est_aas &lt;- c(0, 0) est_aes &lt;- c(0, 0) cov_mat_aas_est &lt;- matrix(0, 2, 2) cov_mat_aes_est &lt;- matrix(0, 2, 2) set.seed(123) # gera amostras com dois estratos de tamanho 30 for (i in 1:500) { s &lt;- strata(popul_dat, &quot;estrat&quot;, c(30, 30), method = &quot;srswor&quot;) dados &lt;- getdata(popul_dat, s) # média amostral de salário e de receita est_aas &lt;- est_aas + c(mean(dados$sal), mean(dados$rec)) # estimador v0 cov_mat_aas_est &lt;- cov_mat_aas_est + (1 - f) * cov(cbind(dados$sal, dados$rec))/n # vhat_aes estimador não viciado popul_plan &lt;- svydesign(~1, strata = ~estrat, data = dados, fpc = ~Prob) # estimador não viciado da média de salario e receita sal_rec_aes_est &lt;- svymean(~sal + rec, popul_plan) est_aes &lt;- est_aes + coef(sal_rec_aes_est) cov_mat_aes_est &lt;- cov_mat_aes_est + attr(sal_rec_aes_est, &quot;var&quot;) } # média populacional med_pop &lt;- round(c(mean(popul_dat$sal), mean(popul_dat$rec)), 3) # Calcula médias das estimativas na simulação ## Média das estimativas pontuais para as 500 amostras aas mean_est_aas &lt;- round(est_aas/500,3) mean_est_aas ## [1] 163,30 4,18 ## Média das estimativas pontuais para as 500 amostras aes mean_est_aes &lt;- round(est_aes/500,3) mean_est_aes ## sal rec ## 77,8 2,1 # Média das estimativas de matriz de covariância para as 500 # amostras aas mean_cov_mat_aas_est &lt;- round(cov_mat_aas_est/500, 3) mean_cov_mat_aas_est ## [,1] [,2] ## [1,] 1713,8 26,28 ## [2,] 26,3 1,24 # Média das estimativas de matriz de covariância para as 500 # amostras aes mean_cov_mat_aes_est &lt;- round(cov_mat_aes_est/500, 3) mean_cov_mat_aes_est ## sal rec ## sal 242,8 3,103 ## rec 3,1 0,505 ## Matriz de covariância populacional mat_cov_pop &lt;- by(popul_dat, popul_dat$estrat, function(t) var(cbind(t$sal, t$rec))) ## Matriz de covariância considerando o plano amostral ## verdadeiro mat_cov_aleat_verd &lt;- (Wh[1]^2 * (1 - fh[1])/nh[1]) * mat_cov_pop[[1]] + (Wh[2]^2 * (1 - fh[2])/nh[2]) * mat_cov_pop[[2]] mat_cov_aleat_verd &lt;- round(mat_cov_aleat_verd,3) ## estimativa de efeitos generalizados do plano amostral DELTA = solve(mean_cov_mat_aas_est) %*% mean_cov_mat_aes_est epa &lt;-round(eigen(DELTA)$values,3) Exemplo 4.6 Teste da igualdade de médias para duas populações Para exemplificar o material descrito na Seção 4.4, vamos utilizar o data frame amolim, contendo dados da Amostra do Censo Experimental de Limeira. # Carrega dados amolim &lt;- readRDS(&quot;./data/amolim.rds&quot;) dim(amolim) ## [1] 706 14 names(amolim) ## [1] &quot;setor&quot; &quot;np&quot; &quot;domic&quot; &quot;sexo&quot; &quot;renda&quot; &quot;lrenda&quot; &quot;raca&quot; &quot;estudo&quot; ## [9] &quot;idade&quot; &quot;na&quot; &quot;peso&quot; &quot;domtot&quot; &quot;peso1&quot; &quot;pesof&quot; Objeto de desenho para os dados da Amostra do Censo Experimental de Limeira: library(survey) amolim.des &lt;- svydesign(data=amolim, id=~setor+domic, weights=~pesof) Vamos estimar, a renda média por raça: svyby(~renda, ~raca, amolim.des, svymean) ## raca renda se ## 1 1 110406 11262 ## 2 2 73560 8207 Vamos estimar, a renda média por sexo: svyby(~renda, ~sexo, amolim.des, svymean) ## sexo renda se ## 1 1 108746 11696 ## 2 2 40039 4042 Vamos testar a igualdade de rendas por sexo: svyttest(renda ~ sexo, amolim.des) ## ## Design-based t-test ## ## data: renda ~ sexo ## t = -6, df = 23, p-value = 0,000005 ## alternative hypothesis: true difference in mean is not equal to 0 ## 95 percent confidence interval: ## -92694 -44719 ## sample estimates: ## difference in mean ## -68707 Vamos testar a igualdade de rendas por raça: svyttest(renda ~ raca, amolim.des) ## ## Design-based t-test ## ## data: renda ~ raca ## t = -4, df = 23, p-value = 0,0006 ## alternative hypothesis: true difference in mean is not equal to 0 ## 95 percent confidence interval: ## -56039 -17653 ## sample estimates: ## difference in mean ## -36846 "],["capC5.html", "Capítulo 5 Ajuste de Modelos Paramétricos 5.1 Introdução 5.2 Método de Máxima Verossimilhança - MV 5.3 Ponderação de dados amostrais 5.4 Método de Máxima Pseudo-Verossimilhança - MPV 5.5 Robustez do procedimento MPV 5.6 Desvantagens da inferência de aleatorização 5.7 Laboratório de R", " Capítulo 5 Ajuste de Modelos Paramétricos 5.1 Introdução Nos primórdios do uso moderno de pesquisas por amostragem, os dados obtidos eram usados principalmente para estimar funções simples dos valores das variáveis de interesse nas populações finitas, tais como totais, médias, razões etc. Isto caracterizava o uso dos dados dessas pesquisas para inferência descritiva. Nas últimas décadas, os dados de pesquisas amostrais têm sido cada vez mais utilizados também para examinar associações, ajustar modelos, testar hipóteses etc. Inferências analíticas como estas, quando baseadas em dados de pesquisas amostrais, são aquelas que envolvem a estimação de parâmetros de modelos denominados de superpopulação - ver Kalton (1983b) e Binder et al. (1987). Quando os valores amostrais das variáveis da pesquisa podem ser considerados como realizações de vetores aleatórios independentes e identicamente distribuídos - IID, modelos podem ser especificados, ajustados, testados e reformulados usando procedimentos estatísticos padrões como os apresentados, por exemplo, em Bickel e Doksum (1977) e Garthwaite et al. (1995). Neste caso, métodos e sistemas estatísticos padrões podem ser usados para executar os cálculos de estimativas de parâmetros e medidas de precisão correspondentes, bem como o diagnóstico e a verificação da adequação das hipóteses dos modelos ajustados. Na prática das pesquisas amostrais, contudo, as hipóteses de observações IID para os dados amostrais são raramente adequadas. Com maior frequência, modelos alternativos com hipóteses mais complexas e/ou estimadores especiais devem ser considerados a fim de acomodar aspectos da estrutura da população e/ou do plano amostral empregado para obter os dados. Além disso, com frequência estão disponíveis informações sobre variáveis auxiliares, utilizadas ou não na especificação do plano amostral, que podem ser incorporadas com proveito na estimação dos parâmetros ou na própria formulação dos modelos de interesse. Os exemplos apresentados no Capítulo 4 demonstram claramente a inadequação de ignorar o plano amostral ao efetuar análises de dados obtidos com pesquisas amostrais. Os valores dos \\(EPAs\\) calculados, tanto para estimadores de medidas descritivas tais como médias e totais, como para estatísticas analíticas usadas em testes de hipóteses e os correspondentes efeitos nos níveis de significância reais, revelam que ignorar o plano amostral pode levar a decisões erradas e a avaliações inadequadas da precisão das estimativas. Embora as medidas propostas no Capítulo 4 para os efeitos de plano amostral sirvam para avaliar o impacto de ignorar o plano amostral nas inferências descritivas ou mesmo analíticas baseadas em dados amostrais, elas não resolvem o problema de como incorporar o plano amostral nessas análises. No caso das inferências descritivas usuais para médias, totais e proporções, o assunto é amplamente tratado na literatura de amostragem e o interessado em maiores detalhes pode consultar livros clássicos como Cochran (1977) e Särndal et al. (1992), ou mais recentes como P. L. N. Silva et al. (2020). Já os métodos requeridos para inferências analíticas só foram consolidados em livro pela primeira vez em Skinner et al. (1989). Este capítulo apresenta um dos métodos centrais disponíveis para ajuste de modelos paramétricos regulares considerando dados amostrais complexos, baseado no trabalho de Binder (1983). Antes de descrever esse método, entretanto, fazemos breve discussão sobre o papel dos pesos na análise de dados amostrais, considerando o trabalho de Pfeffermann (1993). Primeiramente, porém, fazemos uma revisão sucinta do Método de Máxima Verossimilhança - MV para ajustar modelos dentro da abordagem de modelagem clássica, necessária para compreensão adequada do material subsequente. Essa revisão não pretende ser exaustiva ou detalhada, mas tão somente recordar os principais resultados aqui requeridos. Para uma discussão mais detalhada do método de Máxima Verossimilhança para estimação em modelos paramétricos regulares ver, por exemplo, Garthwaite et al. (1995). 5.2 Método de Máxima Verossimilhança - MV Seja \\(\\mathbf y_i = \\left( y_{i1}, \\ldots, y_{iR} \\right)&#39;\\) um vetor \\(Q \\times 1\\) dos valores das variáveis de interesse observados para a unidade \\(i\\) da amostra, que supomos que é gerado por um vetor aleatório \\(\\mathbf{Y}_i\\), para \\(i=1, \\ldots, n\\), onde \\(n\\) é o tamanho da amostra. Suponha que os vetores aleatórios \\(\\mathbf Y_i\\), para \\(i=1, \\ldots, n\\), são independentes e identicamente distribuídos - IID com distribuição comum \\(f(\\mathbf y ; \\boldsymbol{\\theta})\\), onde \\(\\boldsymbol{\\theta} = \\left( \\theta_1, \\ldots, \\theta_K \\right)^{\\prime}\\) é um vetor \\(K \\times 1\\) de parâmetros desconhecidos de interesse. Sob essas hipóteses, a verossimilhança amostral é dada por \\[ l_s \\left( \\boldsymbol{\\theta} \\right) = \\prod \\limits_{i=1}^{n} f \\left( \\mathbf y_i ; \\boldsymbol{\\theta} \\right) \\] e a correspondente log-verossimilhança é igual a \\[ L_s \\left( \\boldsymbol{\\theta} \\right) = \\sum_{i=1}^n \\log \\left[ f \\left( \\mathbf y_i ; \\boldsymbol{\\theta} \\right) \\right] \\] O Método de Máxima Verossimilhança para ajustar modelos requer encontrar o valor do parâmetro \\(\\boldsymbol{\\theta}\\) que maximize a verossimilhança amostral \\(l_s \\left( \\boldsymbol{\\theta} \\right)\\). Tal valor para esse parâmetro seria então o mais verossímil capaz de ter gerado os dados observados. Maximizar a função \\(l_s \\left( \\boldsymbol{\\theta} \\right)\\) é equivalente a maximizar seu logaritmo \\(L_s \\left( \\boldsymbol{\\theta} \\right)\\), o que pode ser tentado por métodos analíticos, calculando as derivadas parciais de \\(L_s \\left( \\boldsymbol{\\theta} \\right)\\) com relação a cada componente de \\(\\boldsymbol{\\theta}\\) e igualando a \\(0\\), obtendo assim um sistema de equações de estimação dadas por: \\[ \\partial L_s \\left( \\boldsymbol{\\theta} \\right) / \\partial \\boldsymbol{\\theta} = \\sum_{i=1}^n \\mathbf u_i \\left( \\boldsymbol{\\theta} \\right) = \\mathbf{0} \\] onde \\(\\mathbf u_i \\left( \\boldsymbol{\\theta} \\right) = \\partial \\log \\left[ f \\left( \\mathbf y_i; \\boldsymbol{\\theta} \\right) \\right] / \\partial \\boldsymbol{\\theta}\\) é o vetor de dimensão \\(K \\times 1\\) dos escores da unidade \\(i\\). Sob condições de regularidade - ver por exemplo Cox e Hinkley (1974), página 281 - a solução \\(\\boldsymbol{\\widehat{\\theta}}\\) deste sistema de equações é o Estimador de Máxima Verossimilhança - EMV de \\(\\boldsymbol{\\theta}\\). A variância assintótica do estimador \\(\\boldsymbol{\\widehat{\\theta}}\\) sob o modelo adotado, denominado aqui abreviadamente modelo \\(M\\), é dada por \\[ V_M \\left( \\boldsymbol{\\widehat{\\theta}} \\right) \\simeq \\left[ J \\left( \\boldsymbol{\\theta} \\right) \\right]^{-1} \\] e um estimador consistente dessa variância é dado por \\[ \\widehat V_M \\left( \\boldsymbol{\\widehat{\\theta}} \\right) = \\left[ J \\left( \\boldsymbol{\\widehat{\\theta}} \\right) \\right]^{-1} \\] onde \\[ J \\left( \\boldsymbol{\\theta} \\right) = \\sum \\limits_{i=1}^{n} \\partial \\mathbf u_i \\left( \\boldsymbol{\\theta} \\right) / \\partial \\boldsymbol{\\theta} \\] e \\[ J \\left( \\boldsymbol{\\widehat{\\theta}} \\right) = \\left. J \\left( \\boldsymbol{\\theta} \\right) \\right| _{\\boldsymbol{\\theta = \\widehat{\\theta}}} \\] 5.3 Ponderação de dados amostrais O papel da ponderação na análise de dados amostrais ainda é alvo de controvérsia entre os estatísticos e outros analistas. Apesar de incorporada comumente na inferência descritiva, não há concordância plena com respeito a seu uso na inferência analítica, havendo um espectro de opiniões entre dois extremos. Num extremo estão os modelistas, que consideram o uso de pesos irrelevante, desde que o modelo formulado e ajustado seja o modelo correto, e no outro os amostristas, que incorporam pesos em qualquer análise, como estratégia para obter robustez. Uma discussão mais ampla do tema é apresentada na Seção 5.5. Exemplo 5.1 Uso analítico dos dados da Pesquisa Nacional por Amostra de Domicílios - PNAD A título de ilustração, consideremos uma pesquisa com uma amostra complexa como a da PNAD do IBGE, que emprega uma amostra de domicílios estratificada e conglomerada em dois ou três estágios, tendo como unidades primárias de amostragem - UPAs os municípios ou os setores censitários, que são estratificados segundo as unidades da federação - UFs e regiões menores dentro das UFs - ver IBGE (1981), página 67 e também P. L. do N. Silva et al. (2002). A seleção de municípios dentro de cada estrato é feita com probabilidades desiguais, proporcionais ao tamanho, havendo inclusive municípios incluídos na amostra com certeza (chamados de municípios auto-representativos, que nesse caso, se tornam estratos para a seleção de setores censitários como UPAs nesses municípios). Da mesma forma, a seleção de setores censitários (unidades secundárias de amostragem ou USAs) dentro de cada município é feita com probabilidades proporcionais ao número de domicílios em cada setor segundo o último censo disponível. Dentro de cada setor, a seleção de domicílios é feita por amostragem sistemática simples (portanto, com equiprobabilidade). Todas as pessoas moradoras em cada domicílio da amostra são pesquisadas. A amostra de domicílios e de pessoas dentro de cada estrato é autoponderada, isto é, tal que todos os domicílios e pessoas dentro de um mesmo estrato têm igual probabilidade de inclusão na amostra e, em consequência, igual peso amostral básico. Entretanto, as probabilidades de inclusão (e consequentemente os pesos) variam bastante entre as várias regiões de pesquisa. A Tabela 5.1 revela como variavam essas probabilidades de seleção entre as regiões cobertas pela amostra da PNAD na década de 1990 - ver também P. L. do N. Silva et al. (2002). Como se pode observar, tais probabilidades de inclusão chegavam a ser \\(5\\) vezes maiores para a região metropolitana - RM de Belém do que para domicílios de São Paulo (RM ou interior) e, portanto, variação semelhante será observada também nos pesos amostrais básicos. Tabela 5.1: \\(\\text{Probabilidades de seleção da amostra da PNAD da década de 1990 segundo regiões}\\) Região da pesquisa Probabilidade de seleção RM de Belém 1/150 RMs de Fortaleza, Recife, Salvador, Porto Alegre e Distrito Federal 1/200 RMs de Belo Horizonte e Curitiba 1/250 Rondônia, Acre, Amazonas, Roraima, Amapá,Tocantins, Sergipe, Mato Grosso do Sul, Mato Grosso e Goiás 1/300 Pará 1/350 RM do Rio de Janeiro, Piauí, Ceará, Rio Grande do Norte, Paraíba, Pernambuco, Alagoas, Bahia, Minas Gerais, Espírito Santo e Rio de Janeiro 1/500 Paraná, Santa Catarina, Rio Grande do Sul 1/550 RM de São Paulo, Maranhão, São Paulo 1/750 Se \\(\\pi_i\\) representa a probabilidade de inclusão na amostra do \\(i\\)-ésimo domicílio da população, \\(i = 1, \\ldots, N\\), então \\[ \\pi_i = \\pi_{munic\\acute{\\imath}pio \\left| estrato \\right. } \\times \\pi_{setor \\left| munic\\acute{\\imath}pio\\right.} \\times \\pi_{domic\\acute{\\imath}lio \\left| setor\\right. } \\] Isto é, a probabilidade global de inclusão de um domicílio (e consequentemente de todas as pessoas nele moradoras) é dada pelo produto das probabilidades condicionais de inclusão nos vários estágios de amostragem. A estimação do total populacional \\(Y\\) de uma variável de pesquisa \\(y\\) num dado estrato usando os dados da PNAD era feita rotineiramente com estimadores ponderados de tipo razão \\(\\widehat Y_R = \\widehat Y_{HT} \\, X \\, / \\, \\widehat X_{HT} = \\sum_{i\\in s} w_i^R y_i\\) (tal como definidos por (3.15), com pesos dados por \\(w_i^R = \\pi_i^{-1} X \\, / \\, \\widehat{X}_{HT}\\), ver (3.17), onde \\(X\\) é o total da população no estrato obtido por métodos demográficos de projeção populacional utilizado como variável auxiliar, e \\(\\widehat X_{HT}\\) e \\(\\widehat Y_{HT}\\) são os estimadores tipo Horvitz-Thompson de \\(X\\) e \\(Y\\), respectivamente. Para estimar para conjuntos de estratos basta somar as estimativas para cada estrato incluído no conjunto. Para estimar médias e proporções, os pesos são também incorporados da forma apropriada. No caso, a estimação de médias é feita usando estimadores ponderados da forma \\(\\overline y^R = \\sum_{i\\in s} w_i^R y_i / {\\sum_{i \\in s} w_i^R}\\) e a estimação de proporções é caso particular da estimação de médias quando a variável de pesquisa \\(y\\) é do tipo indicador (isto é, só toma valores \\(1\\) e \\(0\\)). Estimadores ponderados (como por exemplo os usados na PNAD) são preferidos pelos praticantes de amostragem por sua simplicidade e por serem não viciados (ao menos aproximadamente) com respeito à distribuição de aleatorização induzida pela seleção da amostra, independentemente dos valores assumidos pelas variáveis de pesquisa na população. Já para a modelagem de relações entre variáveis de pesquisa, o uso dos pesos induzidos pelo planejamento amostral, embora já frequente, ainda não é aceito sem controvérsia. Um exemplo de modelagem desse tipo com dados da PNAD em que os pesos e o desenho amostral não foram considerados na análise é encontrado em Leote (1996). Essa autora empregou modelos de regressão logística para traçar um perfil socioeconômico da mão-de-obra empregada no mercado de trabalho informal urbano no Rio de Janeiro, usando dados do suplemento sobre trabalho da PNAD de 1990. Todos os ajustes efetuados ignoraram os pesos e o plano amostral da pesquisa. O problema foi revisitado por D. G. C. Pessoa et al. (1997), quando então esses aspectos foram devidamente incorporados na análise. Um resumo desse trabalho é discutido no Capítulo ??. Vamos supor que haja interesse em explicar uma determinada variável de pesquisa \\(y\\) usando algumas outras variáveis de pesquisa num vetor de preditores \\(\\mathbf z\\). Seria natural indagar se, como no caso do total e da média, os pesos amostrais poderiam desempenhar algum papel na estimação dos parâmetros do modelo (linear) de regressão considerado. Uma possibilidade de incluir os pesos seria estimar os coeficientes da regressão por: \\[ \\boldsymbol{\\widehat{\\beta}}_w = \\left( \\sum_{i \\in s} w_i \\mathbf z_i^{\\prime} \\mathbf z_i \\right)^{-1} \\sum_{i \\in s} w_i \\mathbf z_i^{\\prime} y_i = \\left( \\mathbf Z_s^{\\prime} \\mathbf W_s \\mathbf Z_s \\right)^{-1} \\mathbf Z_s^{\\prime} \\mathbf W_s \\mathbf Y_s \\quad \\tag{5.1} \\] em lugar do estimador de Mínimos Quadrados Ordinários - MQO dado por \\[ \\boldsymbol{\\widehat{\\beta}} = \\left( \\sum_{i \\in s} \\mathbf z_i^{\\prime} \\mathbf z_i \\right)^{-1} \\sum_{i \\in s} \\mathbf z_i^{\\prime } y_i = \\left(\\mathbf Z_s^{\\prime} \\mathbf Z_s \\right)^{-1} \\mathbf Z_s^{\\prime} \\mathbf Y_s \\quad \\tag{5.2} \\] onde \\(w_i = \\pi_i^{-1}\\), \\(y_i\\) é o valor da variável resposta e \\(\\mathbf z_i\\) é o vetor de preditores para a observação \\(i\\), \\(\\mathbf Z_s\\) e \\(\\mathbf Y_s\\) são respectivamente a matriz e vetor com os valores amostrais dos preditores \\(\\mathbf z_i\\) e resposta \\(y_i\\), e \\(\\mathbf W_s = diag \\left \\{ w_i ; i \\in s \\right \\}\\) é a matriz diagonal com os pesos amostrais. Não é possível justificar o estimador \\(\\boldsymbol{\\widehat{\\beta}}\\) em (5.1) com base em um critério de otimalidade, tal como ocorre com os estimadores usuais de Máxima Verossimilhança ou de Mínimos Quadrados Ordinários - MQO, caso a abordagem clássica de supor observações IID fosse adotada para os dados da amostra usada para ajustar o modelo. De um ponto de vista formal (matemático), o estimador \\(\\boldsymbol{\\widehat{\\beta}}_w\\) em (5.1) é equivalente ao estimador de Mínimos Quadrados Ponderados - MQP com pesos \\(w_i\\). Entretanto, esses estimadores diferem de maneira acentuada. Os estimadores de MQP são usualmente considerados quando o modelo de regressão é heteroscedástico, isto é, quando os erros têm variâncias desiguais. Neste caso, os pesos adequados seriam dados pelos inversos das variâncias dos erros correspondentes a cada uma das observações e, portanto, em geral diferentes dos pesos iguais aos inversos das correspondentes probabilidades de inclusão na amostra. Além desta diferença de interpretação do papel dos pesos no estimador, outro aspecto em que os dois estimadores diferem de forma acentuada é na estimação da correspondente precisão, com o estimador MQP acoplado a um estimador de variância baseado no modelo e o estimador \\(\\boldsymbol{\\widehat{\\beta}}_w\\) acoplado a estimadores de variância que incorporam o planejamento amostral e os pesos amostrais ásicos, como se verá mais adiante. O estimador \\(\\boldsymbol{\\widehat{\\beta}}_w\\) foi proposto formalmente por W. A. Fuller (1975), que o concebeu como uma função de estimadores de totais populacionais. A mesma ideia subsidiou vários outros autores que estudaram a estimação de coeficientes de regressão partindo de dados amostrais complexos, tais como Nathan e Holt (1980), Pfeffermann e Nathan (1981). Uma revisão abrangente da literatura existente sobre estimação de parâmetros em modelos de regressão linear com dados amostrais complexos pode ser encontrada no Capítulo 6 de P. L. N. Silva (1996). Apesar dessas dificuldades, será que é possível justificar o uso de pesos amostrais na inferência baseada em modelos? Se for o caso, sob que condições? Seria possível desenvolver diretrizes para o uso de pesos em inferência analítica partindo de dados amostrais complexos? A resposta para essas perguntas é afirmativa, ao menos quando a questão da robustez da inferência é relevante. Em inferências analíticas partindo de dados amostrais complexos, os pesos podem ser usados para proteger: contra planos amostrais não-ignoráveis, que poderiam introduzir ou causar vícios; contra a má especificação do modelo. A robustez dos procedimentos que incorporam pesos é obtida pela mudança de foco da inferência para quantidades da população finita, que definem parâmetros-alvo alternativos aos parâmetros do modelo de superpopulação, conforme já discutido na Seção 2.5. A questão da construção dos pesos para uso na inferência não será tratada neste texto, usando-se sempre como peso básico o inverso da probabilidade de inclusão de cada unidade na amostra. É possível utilizar pesos de outro tipo como, por exemplo, aqueles de razão empregados na estimação da PNAD, ou pesos decorrentes de estimadores de regressão ou de calibração, como os atualmente empregados na PNAD Contínua do IBGE. Para esses casos, há que fazer alguns ajustes da teoria aqui exposta para estimação de variâncias conforme discutido no Capítulo 6 de P. L. N. Silva (1996) ou em Hidiroglou et al. (1999) e Hidiroglou et al. (2000). Há várias formas alternativas de incorporar os pesos amostrais no processo de inferência. A principal que será adotada ao longo deste texto será o Método de Máxima Pseudo-Verossimilhança, que descrevemos na próxima seção. Este método foi desenvolvido por Binder (1983), embora só tenha recebido esta denominação mais tarde, em Skinner et al. (1989). Apesar disso, as ideias de Binder (1983) foram inicialmente expandidas por artigos como Chambless e Boyle (1985) e Roberts et al. (1987). 5.4 Método de Máxima Pseudo-Verossimilhança - MPV Suponha que os vetores observados \\(\\mathbf{y}_{i}\\) das variáveis de pesquisa das unidades \\(i \\in U\\) são gerados por vetores aleatórios \\(\\mathbf{Y}_{i}\\). Suponha também que \\(\\mathbf{Y}_{1}, \\ldots, \\mathbf{Y}_{N}\\) são IID com densidade \\(f \\left( \\mathbf{y}, \\boldsymbol{\\theta} \\right)\\). Se os dados de todas as unidades da população finita \\(U\\) fossem conhecidos, as funções de verossimilhança e de log-verossimilhança populacionais seriam dadas respectivamente por \\[ l_{U} \\left( \\boldsymbol{\\theta} \\right) = \\prod \\limits_{i\\in U} f \\left( \\mathbf{y}_{i}; \\boldsymbol{\\theta} \\right) \\quad \\tag{5.3} \\] e \\[ L_{U} \\left( \\boldsymbol{\\theta} \\right) = \\sum_{i\\in U} \\log \\left[ f \\left( \\mathbf{y}_{i}; \\boldsymbol{\\theta} \\right) \\right] \\quad \\tag{5.4} \\] Para maximizar a verossimilhança com respeito a \\(\\boldsymbol{\\theta}\\), sob condições de regularidade usuais, as equações de estimação populacionais correspondentes são dadas por: \\[ \\sum_{i\\in U} \\mathbf{u}_{i} \\left( \\boldsymbol{\\theta} \\right) = \\mathbf{0} \\quad \\tag{5.5} \\] com \\[ \\mathbf{u}_{i} \\left( \\boldsymbol{\\theta} \\right) = \\partial \\log \\left[ f \\left( \\mathbf{y}_{i}; \\boldsymbol{\\theta} \\right) \\right] / \\partial \\boldsymbol{\\theta} \\quad \\tag{5.6} \\] denotando o vetor \\(K \\times 1\\) de escores da unidade \\(i \\in U\\). Sob as condições de regularidade indicadas em Cox e Hinkley (1974), p. 281, a solução \\(\\boldsymbol{\\theta}_{U}\\) deste sistema de equações é o Estimador de Máxima Verossimilhança de \\(\\boldsymbol{\\theta}\\) no caso de um censo. Podemos considerar \\(\\boldsymbol{\\theta}_{U}\\) como uma Quantidade Descritiva Populacional Correspondente - QDPC - a \\(\\boldsymbol{\\theta}\\), no sentido definido por Pfeffermann (1993), sobre a qual se deseja fazer inferências com base em informações da amostra. Essa definição da QDPC \\(\\boldsymbol{\\theta}_{U}\\) pode ser generalizada para contemplar outras abordagens de inferência além da abordagem clássica baseada em maximização da verossimilhança aqui considerada. Basta para isso especificar outra função de perda ou critério a otimizar e então definir a QDPC como a solução ótima segundo essa nova função de perda. Tal generalização, discutida em Pfeffermann (1993), não será aqui considerada para manter a simplicidade. A QDPC \\(\\boldsymbol{\\theta}_{U}\\) definida implicitamente com base em (5.5) não é calculável a menos que um censo seja realizado na população \\(U\\). Entretanto, desempenha papel fundamental nessa abordagem inferencial, por constituir-se num pseudo-parâmetro, eleito como alvo da inferência num esquema que incorpora o planejamento amostral. Isto se justifica porque, sob certas condições de regularidade, \\(\\boldsymbol{\\theta}_{U} - \\boldsymbol{\\theta } = o_{p} \\left( 1 \\right)\\). Como em pesquisas por amostragem o tamanho da população é geralmente grande, um estimador adequado para \\(\\boldsymbol{\\theta}_{U}\\) será geralmente adequado também para \\(\\boldsymbol{\\theta}\\). Seja \\(\\mathbf{T} = \\sum_{i\\in U} \\mathbf{u}_i \\left( \\boldsymbol{\\theta} \\right)\\) a soma dos vetores de escores na população, o qual é um vetor de totais populacionais. Para estimar este vetor de totais, podemos então usar um estimador linear ponderado da forma \\(\\mathbf{\\widehat{T}} = \\sum_{i \\in s} w_i \\, \\mathbf{u}_i ( \\boldsymbol{\\theta} )\\), ver Capítulo 2.8, onde \\(w_i\\) são pesos amostrais definidos adequadamente. Com essa notação, podemos agora obter um estimador para \\(\\boldsymbol{\\theta}_{U}\\) resolvendo o sistema de equações obtido igualando o estimador \\(\\mathbf{\\widehat{T}}\\) do total \\(\\mathbf{T}\\) a zero. Definição 5.1 O estimador de Máxima Pseudo-Verossimilhança - MPV \\(\\boldsymbol{\\widehat{\\theta}}_{MPV}\\) de \\(\\boldsymbol{\\theta}_U\\) (e consequentemente de \\(\\boldsymbol{\\theta}\\)) será a solução das equações de estimação (ou de Pseudo-Verossimilhança) dadas por \\[ \\mathbf{\\widehat{T}} = \\sum_{i\\in s} w_{i} \\mathbf{u}_i ( \\boldsymbol{\\theta} ) = \\mathbf{0} \\quad \\tag{5.7} \\] Através da linearização de Taylor, ver Seção 3.3, considerando os resultados de Binder (1983), podemos obter a variância de aleatorização assintótica do estimador \\(\\boldsymbol{\\widehat{\\theta}}_{MPV}\\) e seu estimador correspondente, dados respectivamente por: \\[ V_{p} \\left( \\boldsymbol{\\widehat{\\theta}}_{MPV} \\right) \\simeq \\left[ J ( \\boldsymbol{\\theta}_{U} ) \\right]^{-1} V_{p} \\left[ \\sum_{i\\in s} w_i \\, \\mathbf{u}_i ( \\boldsymbol{\\theta}_U ) \\right] \\left[ J ( \\boldsymbol{\\theta}_U ) \\right]^{-1} \\quad \\tag{5.8} \\] e \\[ \\widehat{V}_{p} \\left( \\boldsymbol{\\widehat{\\theta}}_{MPV} \\right) = \\left[ \\widehat{J} \\left( \\boldsymbol{\\widehat{\\theta}}_{MPV} \\right) \\right]^{-1} \\widehat{V}_{p} \\left[ \\sum_{i\\in s} w_i \\, \\mathbf{u}_{i} \\left( \\boldsymbol{\\widehat{\\theta}}_{MPV} \\right) \\right] \\left[ \\widehat{J} \\left( \\boldsymbol{\\widehat{\\theta}}_{MPV} \\right) \\right]^{-1} \\quad \\tag{5.9} \\] onde \\[ J ( \\boldsymbol{\\theta}_U ) = \\left. \\frac{\\partial \\mathbf{T} ( \\boldsymbol{\\theta} ) } {\\partial \\boldsymbol{\\theta}} \\right| _{\\boldsymbol{\\theta = \\theta}_{U}} = \\sum_{i\\in U} \\left. \\frac{\\partial \\mathbf{u}_i ( \\boldsymbol{\\theta} ) } {\\partial \\boldsymbol{\\theta} } \\right| _{\\boldsymbol{\\theta = \\theta}_U} \\quad \\tag{5.10} \\] e \\[ \\widehat{J} \\left( \\boldsymbol{\\widehat{\\theta}}_{MPV} \\right) = \\left. \\frac{\\partial \\mathbf{\\widehat{T}} ( \\boldsymbol{\\theta} ) } {\\partial \\boldsymbol{\\theta}} \\right| _{\\boldsymbol{\\theta = \\widehat{\\theta}}_{MPV}} = \\sum_{i\\in s} w_i \\, \\left. \\frac{\\partial \\mathbf{u}_i ( \\boldsymbol{\\theta} ) } {\\partial \\boldsymbol{\\theta}} \\right| _{\\boldsymbol{\\theta = \\widehat{\\theta}}_{MPV}} \\quad \\tag{5.11} \\] Note que \\(V_p \\left[ \\sum_{i \\in s} w_i \\, \\mathbf{u}_i ( \\boldsymbol{\\theta}_U ) \\right]\\) é a matriz de variância (de aleatorização) do estimador do total populacional dos escores e \\(\\widehat{V}_p \\left[ \\sum_{i \\in s} w_i \\, \\mathbf{u}_i \\left( \\boldsymbol{\\widehat{\\theta}}_{MPV} \\right) \\right]\\) é um estimador consistente para esta variância. Binder (1983) mostrou também que a distribuição assintótica de \\(\\boldsymbol{\\widehat{\\theta}}_{MPV}\\) é Normal Multivariada, isto é, que \\[ \\left[ \\widehat{V}_p \\left( \\boldsymbol{\\widehat{\\theta}}_{MPV} \\right) \\right]^{-1/2} \\left( \\boldsymbol{\\widehat{\\theta}}_{MPV} - \\boldsymbol{\\theta}_U \\right) \\approx \\mathbf{NM} \\left( \\mathbf{0}; \\mathbf{I} \\right) \\quad \\tag{5.12} \\] o que fornece uma base para a inferência sobre \\(\\boldsymbol{\\theta}_U\\) (ou \\(\\boldsymbol{\\theta}\\)) usando amostras grandes, como as habitualmente empregadas nas pesquisas amostrais cujos dados se busca analisar. Muitos modelos paramétricos podem ser ajustados resolvendo-se as equações de Pseudo-Verossimilhança (5.7), satisfeitas algumas condições de regularidade enunciadas no apêndice de Binder (1983) e revistas em P. L. N. Silva (1996), página 126. Entretanto, os estimadores de MPV não serão únicos, já que existem diversas maneiras de se definir os pesos \\(w_i\\). Não há restrições quanto aos tipos de planos amostrais e estimadores de totais considerados, contanto que sejam capazes de fornecer estimativas consistentes para totais. Os pesos \\(w_i\\) devem ser tais que os estimadores de total em (5.7) sejam assintoticamente normais e não-viciados, e possuam estimadores de variância consistentes, conforme requerido para a obtenção da distribuição assintótica dos estimadores MPV. Os pesos mais usados são os pesos básicos do estimador de Horvitz-Thompson para totais, dados pelo inverso das probabilidades de inclusão dos indivíduos, ou seja \\(w_i = \\pi_i^{-1}\\). Tais pesos satisfazem essas condições sempre que \\(\\pi_i &gt; 0\\) e \\(\\pi_{ij} &gt; 0 \\quad \\forall\\ i,j \\in U\\) e algumas condições adicionais de regularidade são satisfeitas, ver por exemplo a Seção 1.3 de Wayne A. Fuller (2009). Assim, um procedimento padrão para ajustar um modelo paramétrico regular \\(f ( \\mathbf{y}; \\boldsymbol{\\theta} )\\) pelo método da Máxima Pseudo-Verossimilhança seria dado pelos passos indicados a seguir. Resolver \\[ \\sum \\limits_{i\\in s} w_i \\, \\mathbf{u}_i ( \\boldsymbol{\\theta} ) = \\mathbf{0} \\quad \\tag{5.13} \\] e calcular o estimador pontual \\(\\boldsymbol{\\widehat{\\theta}}_{MPV}\\) do parâmetro \\(\\boldsymbol{\\theta}\\) no modelo \\(f ( \\mathbf{y; \\boldsymbol{\\theta}} )\\) ou do pseudo-parâmetro \\(\\boldsymbol{\\theta}_U\\) correspondente. Calcular a matriz de variância estimada \\[ \\widehat{V}_p \\left( \\boldsymbol{\\widehat{\\theta}}_{MPV} \\right) = \\left[ \\widehat{J} \\left( \\boldsymbol{\\widehat{\\theta}}_{MPV} \\right) \\right]^{-1} \\widehat{V}_p \\left[ \\sum \\limits_{i\\in s} w_i \\, \\mathbf{u}_i \\left( \\boldsymbol{\\widehat{\\theta}}_{MPV} \\right) \\right] \\left[ \\widehat{J} \\left( \\boldsymbol{\\widehat{\\theta}}_{MPV} \\right) \\right]^{-1} \\quad \\tag{5.14} \\] Quando os pesos básicos tipo Horvitz-Thompson de um plano amostral probabilístico são usados, isto é, \\(w_i = d_i = 1 / \\pi_i\\), temos os componentes do estimador de variância em (5.14) dados por: \\[ \\widehat{V}_p \\left[ \\sum \\limits_{i \\in s} d_i \\, \\mathbf{u}_i \\left( \\boldsymbol{\\widehat{\\theta}}_{HT} \\right) \\right] = \\sum \\limits_{i \\in s} \\sum \\limits_{j \\in s} \\left( d_i d_j - d_{ij} \\right) \\mathbf{u}_i \\left( \\boldsymbol{\\widehat{\\theta}}_{HT} \\right) \\mathbf{u}_j \\left( \\boldsymbol{\\widehat{\\theta}}_{HT} \\right) \\quad \\tag{5.15} \\] onde \\(d_{ij} = 1 / \\pi_{ij}\\) e \\[ \\widehat{J} \\left( \\boldsymbol{\\widehat{\\theta}}_{HT} \\right) = \\left. \\frac{\\partial \\mathbf{\\widehat{T}} \\left( \\boldsymbol{\\theta} \\right)} {\\partial \\boldsymbol{\\theta}} \\right| _{\\boldsymbol{\\theta} = \\boldsymbol{\\widehat{\\theta}}_{HT}} = \\sum \\limits_{i \\in s} d_i \\left. \\frac{\\partial \\mathbf{u}_i ( \\boldsymbol{\\theta} )} {\\partial \\boldsymbol{\\theta}} \\right| _{\\boldsymbol{\\theta} = \\boldsymbol{\\widehat{\\theta}}_{HT}} \\quad \\tag{5.16} \\] Quando pesos calibrados \\(w_i = d_i g_i\\) são usados na estimação pontual dos parâmetros, é necessário ajustar o estimador de variância definido em (5.15). Supondo que um vetor de variáveis auxiliares \\(\\mathbf{x}\\) está disponível para uso no processo de calibração dos pesos, e seguindo Deville e Särndal (1992), os fatores de calibração \\(g_i\\) são calculados minimizando a função \\[ G = \\sum _\\limits{i \\in s} g \\left( d_i, w_i \\right) \\] sujeito à restrição \\[ \\sum _\\limits{i \\in s} w_i \\, \\mathbf{x}_i = \\sum _\\limits{i \\in U} \\mathbf{x}_i \\] onde \\(g(.)\\) é uma função medindo a distância entre os pesos básicos \\(d_i\\) e os pesos calibrados \\(w_i = d_i g_i\\). Deville e Särndal (1992) apresentam uma variedade de propostas para tais funções de distância que geram distintos tipos de pesos calibrados. Sob as condições de regularidade enunciadas, os estimadores de calibração para totais são consistentes e normalmente distribuídos para grandes amostras. Veja o Capítulo 13 de P. L. N. Silva et al. (2020) para uma discussão mais detalhada e acessível sobre estimadores de calibração. Se pesos de calibração forem usados, P. L. N. Silva (1996) mostrou que o estimador de variância adequado para o miolo da expressão (5.14) é dado por: \\[ \\widehat{V}_p \\left[ \\sum \\limits_{i \\in s} d_i g_i \\, \\mathbf{u}_i \\left( \\boldsymbol{\\widehat{\\theta}}_C \\right) \\right] = \\sum \\limits_{i \\in s} \\sum \\limits_{j \\in s} \\left( d_i d_j - d_{ij} \\right) g_i \\, \\left[ \\mathbf{u}_i \\left( \\boldsymbol{\\widehat{\\theta}}_C \\right) - \\mathbf{x_i}^{\\prime} \\widehat{\\mathbf{B}} \\right] g_j \\, \\left[ \\mathbf{u}_j \\left( \\boldsymbol{\\widehat{\\theta}}_C \\right) - \\mathbf{x_j}^{\\prime} \\widehat{\\mathbf{B}} \\right] \\quad \\tag{5.17} \\] onde \\(\\boldsymbol{\\widehat{\\theta}}_C\\) é a solução de (5.13) quando os pesos de calibração \\(w_i = d_i g_i\\) são usados, e \\[ \\widehat{\\mathbf{B}} = \\left( \\sum \\limits_{i \\in s} d_i \\, \\mathbf{x_i} \\, \\mathbf{x_i}^{\\prime} \\right)^{-1} \\left( \\sum \\limits_{i \\in s} d_i \\, \\mathbf{x_i} \\, y_i \\right) \\] Usar \\(\\boldsymbol{\\widehat{\\theta}}_{HT}\\) e \\(\\widehat{V}_p \\left( \\boldsymbol{\\widehat{\\theta}}_{HT} \\right)\\) para calcular regiões ou intervalos de confiança e/ou estatísticas de teste baseadas na distribuição normal e utilizá-las para fazer inferência sobre os componentes de \\(\\boldsymbol{\\theta}\\). \\iffalse{} Observação. No Método de Máxima Pseudo-Verossimilhança, os pesos amostrais são incorporados na análise através das equações de estimação dos parâmetros (5.7) e através das equações de estimação da matriz de covariância dos estimadores (5.14)-(5.16). \\iffalse{} Observação. O plano amostral é também incorporado no método de estimação MPV através da expressão para a variância do total dos escores sob o plano amostral (5.15), onde as propriedades do plano amostral estão resumidas nas probabilidades de inclusão de primeira e segunda ordem, por sua vez incorporadas através dos pesos \\(d_i\\) e \\(d_{ij}\\) respectivamente. \\iffalse{} Observação. Sob probabilidades de seleção iguais, os pesos \\(d_i\\) serão constantes e o estimador pontual \\(\\widehat{\\theta}_{HT}\\) será idêntico ao estimador de Máxima Verossimilhança - MV ordinário para uma amostra de observações IID com distribuição \\(f \\left( \\mathbf{y}; \\boldsymbol{\\theta} \\right)\\). Entretanto, o mesmo não ocorre em se tratando da variância do estimador \\(\\widehat{\\theta}_{HT}\\), que difere da variância sob o modelo do estimador usual de MV. O estimador de variância aqui descrito será consistente para a variância do estimador sob planos amostrais complexos, enquanto o estimador de variância ingênuo correspondente ao método MV será geralmente enviesado. Vantagens do procedimento de MPV O procedimento MPV proporciona estimativas baseadas no plano amostral para a variância assintótica dos estimadores dos parâmetros, as quais são razoavelmente simples de calcular e são consistentes sob condições de regularidade usuais quanto ao plano amostral e à especificação do modelo. Mesmo quando o estimador pontual de MPV coincide com o estimador usual de Máxima Verossimilhança, a estimativa da variância obtida pelo procedimento de MPV pode ser preferível aos estimadores usuais da variância baseados no modelo, que ignoram o plano amostral. O procedimento MPV fornece estimativas robustas, no sentido de que em muitos casos a quantidade \\(\\boldsymbol{\\theta}_U\\) da população finita permanece um alvo válido para inferência, mesmo quando o modelo especificado por \\(f \\left( \\mathbf{y}; \\boldsymbol{\\theta} \\right)\\) não proporciona uma descrição adequada para a distribuição das variáveis de pesquisa na população ou quando as hipóteses de independência e idêntica distribuição para as observações amostrais não se mostram adequadas. Desvantagens do procedimento de MPV O procedimento de estimação MPV requer conhecimento de informações detalhadas sobre as unidades da amostra, tais como pertinência a estratos e conglomerados ou unidades primárias de amostragem, e suas probabilidades de inclusão ou pesos. Tais informações nem sempre estão disponíveis para usuários de dados de pesquisas amostrais, seja por razões operacionais ou devido às regras de proteção do sigilo de informações individuais. As propriedades dos estimadores MPV para pequenas amostras não são conhecidas. Este problema pode não ser importante em análises que usam os dados de pesquisas feitas pelas agências produtoras de estatísticas oficiais, desde que em tais análises seja utilizada a amostra inteira, ou no caso de subdomínios estudados separadamente, que as amostras usadas sejam suficientemente grandes nestes domínios. Mas pode tornar-se um problema relevante quando as amostras de interesse para a análise são pequenas e a teoria assintótica não pode ser aplicada. Outra dificuldade é que métodos usuais de diagnóstico de ajuste de modelos (tais como gráficos de resíduos) e outros procedimentos da inferência clássica (tais como testes estatísticos de Razões de Verossimilhança) não podem ser utilizados sem ajustes. Mais informações sobre este assunto estão disponíveis no capítulo ??. 5.5 Robustez do procedimento MPV Nesta seção vamos examinar a questão da robustez dos estimadores obtidos pelo procedimento MPV. É essa robustez que justifica o emprego desses estimadores frente aos estimadores usuais de MV pois, nas situações práticas da análise de dados amostrais complexos, as hipóteses usuais de observações IID para os dados amostrais raramente são verificadas. Vamos agora analisar com mais detalhes a terceira abordagem para a inferência analítica. Nela, postulamos um modelo como na primeira abordagem e a inferência é direcionada aos parâmetros do modelo. Porém, em vez de acharmos um estimador ótimo sob o modelo, achamos um estimador na classe dos estimadores consistentes para a QDPC, onde a consistência é referida à distribuição de aleatorização do estimador. Por que usar a QDPC? A resposta é exatamente para obter maior robustez. Para entender porque essa abordagem oferece maior robustez, vamos considerar dois casos. Caso 1: o modelo para a população é adequado. Então quando \\(N \\rightarrow \\infty\\) a QDPC \\(\\boldsymbol{\\theta}_U\\) converge para o parâmetro \\(\\boldsymbol{\\theta}\\), isto é, \\(\\boldsymbol{\\theta}_U - \\boldsymbol{\\theta} \\rightarrow \\mathbf{0}\\) em probabilidade, segundo a distribuição de probabilidades do modelo \\(M\\). Se \\(\\boldsymbol{\\widehat{\\theta}}_{MPV}\\) for consistente, então quando \\(n \\rightarrow \\infty\\) temos que \\(\\boldsymbol{\\widehat{\\theta}}_{MPV} - \\boldsymbol{\\theta}_U \\rightarrow \\mathbf{0}\\) em probabilidade, segundo a distribuição de aleatorização \\(p\\). Juntando essas condições obtemos que \\[ \\boldsymbol{\\widehat{\\theta}}_{MPV} \\stackrel{P}{\\rightarrow} \\boldsymbol{\\theta} \\] em probabilidade segundo a mistura \\(Mp\\). Esse resultado segue porque \\[ \\begin{eqnarray*} \\boldsymbol{\\widehat{\\theta}}_{MPV} - \\boldsymbol{\\theta} &amp;=&amp; (\\boldsymbol{\\widehat{\\theta}}_{MPV}- \\boldsymbol{\\theta}_U) + \\left( \\boldsymbol{\\theta}_U - \\boldsymbol{\\theta} \\right) \\\\ &amp;=&amp; O_{p} (n^{-1/2}) + O_{p} (N^{-1/2}) = O_{p}(n^{-1/2}) \\end{eqnarray*} \\] Caso 2: o modelo para a população não é válido. Nesse caso, o parâmetro \\(\\boldsymbol{\\theta}\\) do modelo não tem interpretação substantiva significante, porém a QDPC \\(\\boldsymbol{\\theta}_U\\) é uma quantidade definida na população finita (real) com interpretação clara, independente da validade do modelo. Como \\(\\boldsymbol{\\widehat{\\theta}}_{MPV}\\) é consistente para a QDPC \\(\\boldsymbol{\\theta}_U\\), a inferência baseada no procedimento MPV segue válida para este pseudo-parâmetro, independente da inadequação do modelo para a população. Skinner (1989a), página 81, discute essa situação, mostrando que \\(\\boldsymbol{\\theta}_U\\) pode ainda ser um alvo válido para inferência mesmo quando o modelo \\(f \\left( \\mathbf{y}; \\boldsymbol{\\theta} \\right)\\) especificado para a população é inadequado, ao menos no sentido de que \\(f \\left( \\mathbf{y}; \\boldsymbol{\\theta}_U \\right)\\) forneceria a melhor aproximação possível (em certo sentido) para o verdadeiro modelo \\(h \\left( \\mathbf{y}; \\boldsymbol{\\eta}\\right)\\) que gera as observações populacionais. Skinner (1989a) reconhece que a melhor aproximação possível entre um conjunto de aproximações ruins ainda poderia ser uma aproximação ruim, e portanto, que a escolha do elenco de modelos especificados pela distribuição \\(f \\left( \\mathbf{y}; \\boldsymbol{\\theta} \\right)\\) deve seguir os cuidados necessários para garantir que esta escolha forneça uma aproximação razoável da realidade. \\iffalse{} Observação. Consistência referente à distribuição de aleatorização. Consistência na teoria clássica tem a ver com comportamento limite de um estimador quando o tamanho da amostra cresce, isto é, quando \\(n \\rightarrow \\infty\\). No caso de populações finitas, temos que considerar o que ocorre quando crescem o tamanho da amostra e também o tamanho da população, isto é, quando \\(n \\rightarrow \\infty\\) e \\(N \\rightarrow \\infty\\). Neste caso, é preciso definir a maneira pela qual \\(N \\uparrow\\) e \\(n \\uparrow\\) preservando a estrutura do plano amostral. Para evitar um desvio indesejado que a discussão deste problema traria, vamos supor que \\(N \\uparrow\\) e \\(n \\uparrow\\) de uma forma bem definida. Os leitores interessados poderão consultar: Särndal et al. (1992), página 166, e Wayne A. Fuller (2009), Seção 1.3. 5.6 Desvantagens da inferência de aleatorização Se o modelo postulado diretamente para descrever os dados amostrais for correto, o uso de estimadores ponderados pode resultar em perda substancial de eficiência quando comparado com o estimador ótimo (por exemplo, o de MV) sob o modelo. Em geral, a perda de eficiência aumenta quanto menor for o tamanho da amostra e quanto maior for a variação dos pesos. Há casos onde a ponderação é a única alternativa. Por exemplo, se os dados disponíveis já estão na forma de estimativas amostrais ponderadas, então o uso de pesos é inevitável. Um exemplo clássico é discutido a seguir. Exemplo 5.2 Análise secundária de tabelas de contingência. A pesquisa Canada Health Survey usa um plano amostral estratificado com vários estágios de seleção. Nessa pesquisa, a estimativa de contagem na cela \\(k\\) de uma tabela de contingência qualquer é dada por \\[ \\widehat{N}_k = \\sum_{a} \\left( N_a / \\widehat{N}_a \\right) \\left[ \\sum_{h} \\sum_{i} \\sum_{j} w_{hij} Y_{ka (hij)} \\right] = \\sum_{a} \\left( N_a / \\widehat{N}_a \\right) \\widehat{N}_{ka} \\] onde \\(Y_{ka (hij)} = 1\\) se a \\(j\\)-ésima unidade da UPA \\(i\\) do estrato \\(h\\) pertence à \\(k\\)-ésima cela e ao \\(a\\)-ésimo grupo de idade-sexo, e \\(0\\) (zero) caso contrário; \\(N_{a} / \\widehat{N}_a\\) são fatores de ajustamento de pós-estratificação que usam contagens censitárias \\(N_{a}\\) de idade-sexo para diminuir as variâncias dos estimadores. Quando as contagens expandidas \\(\\widehat{N}_k\\) são usadas, os testes de homogeneidade e de qualidade de ajuste de modelos loglineares baseados em amostragem Multinomial e Poisson independentes não são mais válidos. A estatística clássica \\(X^2\\) não tem mais distribuição \\(\\chi^2\\) e sim uma soma ponderada \\(\\sum_k \\delta_k X_k\\) de variáveis \\(X_k\\) IID com distribuição \\(\\chi^2 (1)\\). Esse exemplo será rediscutido com mais detalhes na Seção ??. A importância desse exemplo é ilustrar que mesmo quando o usuário pensa estar livre das complicações causadas pelo plano amostral e pesos, ele precisa estar atento à forma como foram gerados os dados que pretende modelar ou analisar, sob pena de realizar inferências incorretas. Este exemplo tem também grande importância prática, pois um grande número de pesquisas domiciliares por amostragem produz como principal resultado conjuntos de tabelas com contagens e proporções, as quais foram obtidas mediante ponderação pelas agências produtoras das informações. Este é o caso, por exemplo, da PNAD, da PNAD Contínua, da amostra do Censo Demográfico e de inúmeras outras pesquisas do IBGE e de agências estatísticas congêneres. 5.7 Laboratório de R Usar função svymle da library survey, Lumley (2021), para incluir exemplo de estimador MPV? Possibilidade: explorar o exemplo 2.1? "],["referências.html", "Referências", " Referências Bickel, P. J. e Doksum, K. A. (1977). Mathematical Statistics: Basic Ideas and Selected Topics. Holden-Day. Binder, D. A. (1983). On the variances of asymptotically normal estimators from complex surveys. International Statistical Review, 51, 279292. Binder, D. A.; Kovar, J. G.; Kumar, S.; Paton, D. e Baaren, A. V. (1987). Analytic uses of survey data: a review. In I. B. MacNeil e G. J. Umphrey (Orgs.), Applied Probability, Stochastic Processes and Sampling Theory (p. 243264). John Wiley &amp; Sons. Bishop, Y. M. M.; Fienberg, S. E. e Holland, P. W. (1975). Discrete Multivariate Analysis: Theory and Practice. The MIT Press. Brewer, K. R. W. (1963). Ratio estimation and finite populations: Some results deducible from the assumption of an underlying stochastic process. The Australian Journal of statistics, 5(3). Casella, G. e Berger, R. L. (2010). Inferência Estatística. Cengage Learning. Cassel, C. M.; Särndal, C. E. e Wretman, J. H. (1977). Foundations of Inference in Survey Sampling. John Wiley &amp; Sons. Chambers, R. L. e Skinner, C. J. (Orgs.). (2003). Analysis of Survey Data. John Wiley &amp; Sons. Chambless, L. E. e Boyle, K. E. (1985). Maximum likelihood methods for complex sample data: logistic regression and discrete proportional hazards models. Communications in Statistics - Theory and Methods, 14(6), 13771392. Cochran, W. G. (1977). Sampling Techniques (3rd ed, p. 428). John Wiley &amp; Sons. Cox, D. R. e Hinkley, D. V. (1974). Theoretical Statistics. Chapman &amp; Hall. Deming, W. E. (1956). On simplifications of sampling design through replication with equal probabilities and without stages. Journal of the American Statistical Association, 51, 2453. Deville, J. C. e Särndal, C. E. (1992). Calibration estimators in survey sampling. Journal of the American Statistical Association, 87, 376382. Fuller, W. A. (1975). Regression analysis for sample survey. Sankhy C, 37, 117132. Fuller, Wayne A. (1987). Measurement Error Models (p. 440). John Wiley &amp; Sons Inc. Fuller, Wayne A. (2009). Sampling Statistics. John Wiley. Garthwaite, P. H.; Jollife, I. T. e Jones, B. (1995). Statistical Inference. Prentice Hall. Haggard, E. A. (1958). Intraclass Correlation and the Analysis of Variance. Dryden Press. Hansen, M. H.; Hurwitz, W. N. e Madow, W. G. (1953). Sample Survey Methods and Theory. John Wiley &amp; Sons. Heeringa, S. G.; West, B. T. e Berglund, P. A. (2010). Applied Survey Data Analysis. Taylor &amp; Francis. Disponível em: https://books.google.com.br/books?id=QNmIvnTLlxcC (Acesso em 1/12/2021) Hidiroglou, M.; Rao, J. e Yung, W. (1999). Variance computation for complex surveys using estimating equations. In S. S. of Canada (Org.), Proceedings of the Survey Methods Section, Annual Meeting. Hidiroglou, M.; Rao, J. e Yung, W. (2000). Variance estimation and quasi-score tests for complex surveys using estimating equations. In A. S. Association (Org.), Proceedings of the Survey Research Methods Section, Joint Statistical Meetings (p. 112119). IBGE. (1981). Metodologia da Pesquisa Nacional por Amostra de Domicílios na Década de 70 (Série Relatórios Metodológicos nº 1). IBGE. IBGE. (1985). Amostra de Uso Público do Censo Demográfico de 1980 - Metodologia e Manual do Usuário. IBGE. IBGE. (2021). Sobre a alteração do método de calibração dos fatores de expansão da PNAD Contínua . Instituto Brasileiro de Geografia e Estatística - IBGE; IBGE, Diretoria de Pesquisas. Disponível em: https://biblioteca.ibge.gov.br/index.php/biblioteca-catalogo?view=detalhes&amp;id=2101882 (Acesso em 28/11/2021) Johnson, R. A. e Wichern, D. W. (1988). Applied Multivariate Statistical Analysis. Prentice Hall. Kalton, G. (1983a). Compensating for missing survey data. The University of Michigan, Institute for Social Research, Survey Research Center. Kalton, G. (1983b). Models in the practice of survey sampling. International Statistical Review, 51, 175188. Kish, L. (1965). Survey Sampling. John Wiley &amp; Sons. Lehtonen, R. e Pahkinen, E. J. (1995). Practical Methods for Design and Analysis of Complex Surveys. John Wiley &amp; Sons. Leote, R. M. D. (1996). Um perfil sócio-econômico das pessoas ocupadas no setor informal na área urbana do Rio de Janeiro (nº 2). IBGE, Escola Nacional de Ciências Estatísticas. Little, R. J. A. e Rubin, D. B. (2002). Statistical Analysis with Missing Data (2nd edition, p. 375). John Wiley &amp; Sons. Lumley, T. (2006). Analysis of complex survey samples. Journal of Statistical Software, 9(1), 119. Lumley, T. (2010). Complex Surveys: A Guide to Analysis Using R (p. 276). John Wiley &amp; Sons. Lumley, T. (2021). survey: Analysis of Complex Survey Samples. Disponível em: https://CRAN.R-project.org/package=survey R package version &gt;3.5.0, (Acesso em 1/12/2021) Magalhães, M. N. e Lima, A. C. P. (2015). Noções de Probabilidade e Estatística (7ª edição, 3ª reimpressão revista). Edusp - Editora da Universidade de São Paulo. Mahalanobis, P. C. (1939). A sample survey of the acreage under jute in Bengal. Sankhya, 4, 511531. Mahalanobis, P. C. (1944). On large-scale sample surveys. Philosophical Transactions of the Royal Society of London B, 231, 329451. Montanari, G. E. (1987). Post-sampling efficient QR-prediction in large-sample surveys. International Statistical Review, 55, 191202. Nathan, G. e Holt, D. (1980). The effect of survey design on regression analysis. Journal of the Royal Statistical Society B, 42, 377386. NIC.br. (2020). Pesquisa Sobre o Uso das Tecnologias da Informação e da Comunicação no Brasil (p. 344). Disponível em: https://cetic.br/media/docs/publicacoes/2/20201123121817/tic_dom_2019_livro_eletronico.pdf (Acesso em 1/12/2021) Pessoa, Djalma G. C. e Silva, P. L. N. (1998). Análise de dados amostrais complexos (p. 170). Associação Brasileira de Estatística. Pessoa, D. G. C.; Silva, P. L. N. e Duarte, R. P. N. (1997). Análise estatística de dados de pesquisas por amostragem: problemas no uso de pacotes padrões. Revista Brasileira de Estatística, 33, 4457. Pfeffermann, D. (1993). The role of sampling weights when modelling survey data. International Statistical Review, 61, 317337. Pfeffermann, D. e Nathan, G. (1981). Regression analysis of data from complex samples. Journal of the American Statistical Association, 76, p. 681689. Quenoille, M. H. (1949). Problems in plane sampling. Annals of Mathematical Statistics, 20, p. 355375. Quenoille, M. H. (1956). Notes on bias in estimation. Biometrika, 43, 353360. Rao, J. N. K.; Wu, C. F. J. e Yue, K. (1992). Some recent work on resampling methods for complex surveys. Survey Methodology, 18(2), 209217. Roberts, G.; Rao, J. N. K. e Kumar, S. (1987). Logistic Regression Analysis of Sample Survey Data. Biometrika, 74(1), 112. Royall, R. M. (1970). On finite population sampling theory under certain linear regression models. Biometrika, 57(2), 377387. Rubin, D. B. (1987). Multiple Imputation for Nonresponse in Surveys. John Wiley &amp; Sons. Särndal, C. E.; Swensson, B. e Wretman, J. H. (1992). Model Assisted Survey Sampling. Springer-Verlag. Schafer, J. L. (1997). Analysis of Incomplete Multivariate Data (p. 430). Chapman &amp; Hall / CRC. Shah, B. V.; Folsom, R. E.; LaVange, L. M.; Wheeless, S. C.; Boyle, K. E. e Williams, R. L. (1993). Statistical Methods and Mathematical Algorithms Used in SUDAAN. Silva, P. L. do N.; Pessoa, D. G. C. e Lila, M. F. (2002). Análise estatística de dados da PNAD: incorporando a estrutura do plano amostral. Ciência e Saúde Coletiva, 7(4), 659670. Silva, P. L. N. (1996). Utilizing Auxiliary Information for Estimation and Analysis in Sample Surveys [Tese de doutorado]. University of Southampton, Department of Social Statistics. Silva, P. L. N.; Bianchini, Z. M. e Dias, A. J. R. (2020). Amostragem: teoria e prática usando R. Disponível em: https://amostragemcomr.github.io/livro/ (Acesso em 1/12/2021) Silva, P. L. N. e Moura, F. A. S. (1990). Efeitos de conglomeração da malha setorial do censo demográfico 80 (Série Textos para Discussão nº 32). IBGE, Diretoria de Pesquisas. Skinner, C. J. (1989a). Domain Means, Regression and Multivariate Analysis. In Analysis of Complex Surveys (p. 5987). John Wiley &amp; Sons. Skinner, C. J. (1989b). Introduction to Part A. In Analysis of Complex Surveys (p. 2357). John Wiley &amp; Sons. Skinner, C. J.; Holt, D. e Smith, T. M. F. (Orgs.). (1989). Analysis of Complex Surveys. John Wiley &amp; Sons. Sudman, S. (1976). Applied Sampling. Academic Press. Sugden, R. A. e Smith, T. M. F. (1984). Ignorable and informative designs in survey sampling inference. Biometrika, 71, 495506. Thompson, S. K. (1992). Sampling. John Wiley &amp; Sons. Tillé, Y. e Matei, A. (2016). sampling: Survey Sampling. Disponível em: https://CRAN.R-project.org/package=sampling R package version 2.8 US Bureau of Labour Statistics. (2020). Consumer price index - Handbook of methods (p. 67). US Bureau of Labour Statistics. Valliant, R.; Dorfman, A. H. e Royall, R. M. (2000). Finite population sampling and inference: a prediction approach. Westat. (1996). A Users Guide to WesVarPc, version 2.0. Westat, Inc. Wolter, K. M. (1985). Introduction to Variance Estimation. Springer-Verlag. Wolter, K. M. (2007). Introduction to Variance Estimation (Second, p. 428). Springer-Verlag. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
