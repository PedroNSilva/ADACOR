# Ajuste de Modelos Paramétricos {#capC5}

## Introdução {#secC5N1}
<div style="text-align: justify">

Nos primórdios do uso moderno de pesquisas por amostragem, os dados obtidos eram usados principalmente para estimar funções simples dos valores das variáveis de interesse nas populações finitas, tais como totais, médias, razões etc. Isto caracterizava o uso dos dados dessas pesquisas para *inferência descritiva*. Nas últimas décadas, os dados de pesquisas amostrais têm sido cada vez mais utilizados também para examinar associações, ajustar modelos, testar hipóteses etc. *Inferências analíticas* como estas, quando baseadas em dados de pesquisas amostrais, são aquelas que envolvem a estimação de parâmetros de modelos denominados *de superpopulação* @kalton1983b; @binder1987. 

Quando os valores *amostrais* das variáveis da pesquisa podem ser considerados como realizações de vetores aleatórios independentes e identicamente distribuídos (IID), modelos podem ser especificados, ajustados, testados e reformulados usando procedimentos estatísticos padrões como os apresentados, por exemplo, em @bickel1977 e @garthwaite1995. Neste caso, métodos e sistemas estatísticos padrões podem ser usados para executar os cálculos de estimativas de parâmetros e medidas de precisão correspondentes, bem como o diagnóstico e a verificação da adequação das hipóteses dos modelos ajustados.

Na prática das pesquisas amostrais, contudo, as hipóteses de observações IID para os dados amostrais são raramente adequadas. Com maior frequência, modelos alternativos com hipóteses mais complexas e/ou estimadores especiais devem ser considerados a fim de acomodar aspectos da estrutura da população e/ou do plano amostral empregado para obter os dados. Além disso, com frequência estão disponíveis informações sobre variáveis auxiliares, utilizadas ou não na especificação do plano amostral, que podem ser incorporadas com proveito na estimação dos parâmetros ou na própria formulação dos modelos de interesse.

Os exemplos apresentados no Capítulo \@ref(epa) demonstram claramente a inadequação de ignorar o plano amostral ao efetuar análises de dados obtidos com pesquisas amostrais. Os valores dos EPAs calculados, tanto para estimadores de medidas descritivas tais como médias e totais, como para estatísticas analíticas usadas em testes de hipóteses e os correspondentes efeitos nos níveis de significância reais, revelam que ignorar o plano amostral pode levar a decisões erradas e a avaliações inadequadas da precisão das estimativas.

Embora as medidas propostas no Capítulo \@ref(epa) para os efeitos de plano amostral sirvam para avaliar o impacto de ignorar o plano amostral nas inferências descritivas ou mesmo analíticas baseadas em dados amostrais, elas não resolvem o problema de como incorporar o plano amostral nessas análises. No caso das inferências descritivas usuais para médias, totais e proporções, o assunto é amplamente tratado na literatura de amostragem e o interessado em maiores detalhes pode consultar livros clássicos como @Cochran1977 e @SSW1992, ou mais recentes como e @Silva2020. Já os métodos requeridos para inferências analíticas só foram consolidados em livro pela primeira vez em @SHS1989. Este capítulo apresenta um dos métodos centrais disponíveis para ajuste de modelos paramétricos regulares considerando dados amostrais complexos, baseado no trabalho de @binder1983. Antes de descrever esse método, entretanto, fazemos breve discussão sobre o papel dos pesos na análise de dados amostrais, considerando o trabalho de @Pfeff1993.

Primeiramente, porém, fazemos uma revisão sucinta do método de Máxima Verossimilhança (MV) para ajustar modelos dentro da abordagem de modelagem clássica, necessária para compreensão adequada do material subsequente. Essa revisão não pretende ser exaustiva ou detalhada, mas tão somente recordar os principais resultados aqui requeridos. Para uma discussão mais detalhada do método de Máxima Verossimilhança para estimação em modelos paramétricos regulares ver, por exemplo, @garthwaite1995.

## Método de Máxima Verossimilhança (MV) {#secC5N2}
<div style="text-align: justify">

Seja $\mathbf y_i = \left( y_{i1}, \ldots, y_{iR} \right)'$ um vetor $Q \times 1$ dos valores das variáveis de interesse observados para a unidade $i$ da amostra, que supomos que é gerado por um vetor aleatório $\mathbf{Y}_i$, para $i=1, \ldots, n$, onde $n$ é o tamanho da amostra. Suponha que os vetores aleatórios $\mathbf Y_i$, para $i=1, \ldots, n$, são independentes e identicamente distribuídos (IID) com distribuição comum $f(\mathbf y ; \boldsymbol{\theta})$, onde $\boldsymbol{\theta} = \left( \theta_1, \ldots, \theta_K \right)^{\prime}$ é um vetor $K \times 1$ de parâmetros desconhecidos de interesse. Sob essas hipóteses, a verossimilhança amostral é dada por 

$$
l_s \left( \boldsymbol{\theta} \right) = \prod \limits_{i=1}^{n} f \left( \mathbf y_i ; \boldsymbol{\theta} \right) 
$$ 
e a correspondente log-verossimilhança é igual a

$$
L_s \left( \boldsymbol{\theta} \right) = \sum_{i=1}^n \log \left[ f \left( \mathbf y_i ; \boldsymbol{\theta} \right) \right] 
$$

O método da *Máxima Verossimilhança* para ajustar modelos requer encontrar o valor do parâmetro $\boldsymbol{\theta}$ que maximize a verossimilhança amostral $l_s \left( \boldsymbol{\theta} \right)$. Tal valor para esse parâmetro seria então o *mais verossímil* capaz de ter gerado os dados observados. Maximizar a função $l_s \left( \boldsymbol{\theta} \right)$ é equivalente a maximizar seu logaritmo $L_s \left( \boldsymbol{\theta} \right)$, o que pode ser tentado por métodos analíticos, calculando as derivadas parciais de $L_s \left( \boldsymbol{\theta} \right)$ com relação a cada componente de $\boldsymbol{\theta}$ e igualando a $0$, obtendo assim um sistema de equações de estimação dadas por:

$$
\partial L_s \left( \boldsymbol{\theta} \right) / \partial \boldsymbol{\theta} = \sum_{i=1}^n \mathbf u_i \left( \boldsymbol{\theta} \right) = \mathbf{0} 
$$

onde $\mathbf u_i \left( \boldsymbol{\theta} \right) = \partial \log \left[ f \left( \mathbf y_i; \boldsymbol{\theta} \right) \right] / \partial \boldsymbol{\theta}$ é o vetor de dimensão $K \times 1$ dos escores da unidade $i$.

Sob condições de regularidade - ver por exemplo @cox1974 p. 281 - a solução $\boldsymbol{\widehat{\theta}}$ deste sistema de equações é o *Estimador de Máxima Verossimilhança (EMV)* de $\boldsymbol{\theta}$. 

A variância assintótica do estimador $\boldsymbol{\widehat{\theta}}$ sob o modelo adotado, denominado aqui abreviadamente modelo $M$, é dada por 

$$
V_M \left( \boldsymbol{\widehat{\theta}} \right) \simeq \left[ J \left( \boldsymbol{\theta} \right) \right]^{-1}
$$

e um estimador consistente dessa variância é dado por 

$$
\widehat V_M \left( \boldsymbol{\widehat{\theta}} \right) = \left[ J \left( \boldsymbol{\widehat{\theta}} \right) \right]^{-1} 
$$

onde 
$$
J \left( \boldsymbol{\theta} \right) = \sum \limits_{i=1}^{n} \partial \mathbf u_i \left( \boldsymbol{\theta} \right) / \partial \boldsymbol{\theta} 
$$
e 

$$
J \left( \boldsymbol{\widehat{\theta}} \right) = \left. J \left( \boldsymbol{\theta} \right) \right| _{\boldsymbol{\theta = \widehat{\theta}}} 
$$

## Ponderação de Dados Amostrais {#secC5N3}
<div style="text-align: justify">

O papel da ponderação na *análise de dados amostrais* ainda é alvo de controvérsia entre os estatísticos e outros analistas. Apesar de incorporada comumente na *inferência descritiva*, não há concordância plena com respeito a seu uso na *inferência analítica*, havendo um espectro de opiniões entre dois extremos. Num extremo estão os *modelistas*, que consideram o uso de pesos irrelevante, desde que o modelo formulado e ajustado seja o modelo correto, e no outro os *amostristas*, que incorporam pesos em qualquer análise, como estratégia para obter robustez. Uma discussão mais ampla do tema é apresentada na seção @ref(secC5N5).

```{example, label= "pnad"}
Uso analítico dos dados da Pesquisa Nacional por Amostra de Domicílios (PNAD)
```

A título de ilustração, consideremos uma pesquisa com uma amostra complexa como a da PNAD do IBGE, que emprega uma amostra de domicílios estratificada e conglomerada em dois ou três estágios, tendo como unidades primárias de amostragem (UPAs) os municípios ou os setores censitários, que são estratificados segundo as unidades da federação (UFs) e regiões menores dentro das UFs - ver @IBGE1981, p. 67 e também @Silva2002.

A seleção de municípios dentro de cada estrato é feita com probabilidades desiguais, proporcionais ao tamanho, havendo inclusive municípios incluídos na amostra com certeza (chamados de municípios auto-representativos, que nesse caso, se tornam estratos para a seleção de setores censitários como UPAs nesses municípios). Da mesma forma, a seleção de setores censitários (unidades secundárias de amostragem ou USAs) dentro de cada município é feita com probabilidades proporcionais ao número de domicílios em cada setor segundo o último censo disponível. Dentro de cada setor, a seleção de domicílios é feita por amostragem sistemática simples (portanto, com equiprobabilidade). Todas as pessoas moradoras em cada domicílio da amostra são pesquisadas.

A amostra de domicílios e de pessoas dentro de cada estrato é *autoponderada*, isto é, tal que todos os domicílios e pessoas dentro de um mesmo estrato têm igual probabilidade de inclusão na amostra e, em consequência, igual peso amostral básico. Entretanto, as probabilidades de inclusão (e consequentemente os pesos) variam bastante entre as várias regiões de pesquisa. A Tabela \@ref(tab:tabC5N1) revela como variavam essas probabilidades de seleção entre as regiões cobertas pela amostra da PNAD na década de 1990 - ver também @Silva2002. Como se pode observar, tais probabilidades de inclusão chegavam a ser $5$ vezes maiores para a região metropolitana (RM) de Belém do que para domicílios de São Paulo (RM ou interior) e, portanto, variação semelhante será observada também nos pesos amostrais básicos.


```{r, echo=FALSE, label=tabC5N1}
suppressMessages(library(kableExtra))

l1=c('RM de Belém','1/150')
l2=c('RMs de Fortaleza, Recife, Salvador, Porto Alegre e Distrito Federal','1/200')
l3=c('RMs de Belo Horizonte e Curitiba','1/250')
l4=c('Rondônia, Acre, Amazonas, Roraima, Amapá,Tocantins, Sergipe, Mato Grosso do Sul, Mato Grosso e Goiás','1/300')
l5=c('Pará','1/350')
l6=c('RM do Rio de Janeiro, Piauí, Ceará, Rio Grande do Norte, Paraíba, Pernambuco, Alagoas, Bahia, Minas Gerais, Espírito Santo e Rio de Janeiro','1/500')
l7=c('Paraná, Santa Catarina, Rio Grande do Sul','1/550')
l8=c('RM de São Paulo, Maranhão, São Paulo','1/750')

tabela=as.data.frame(t(data.frame(l1,l2,l3,l4,l5,l6,l7,l8)))

names(tabela) <- c('Região da pesquisa','Probabilidade de seleção')

knitr::kable(tabela,align= "lc",format.args= list(big.mark = '.',dec=','),escape = F, booktabs=T,
caption= "$\\text{Probabilidades de seleção da amostra da PNAD da década de 1990 segundo regiões}$", row.names=FALSE,)%>% 
kable_styling(full_width = F,latex_options = 'HOLD_position') %>% column_spec(column=1,width='14cm')%>% column_spec(column=2,width='2.5cm')
```

Se $\pi_i$representa a probabilidade de inclusão na amostra do $i$-ésimo domicílio da população, $i = 1, \ldots, N$, então 

$$
\pi_i = \pi_{munic\acute{\imath}pio \left| estrato \right. } \times \pi_{setor \left| munic\acute{\imath}pio\right.} \times \pi_{domic\acute{\imath}lio \left| setor\right. } 
$$
Isto é, a probabilidade global de inclusão de um domicílio (e consequentemente de todas as pessoas nele moradoras) é dada pelo produto das probabilidades condicionais de inclusão nos vários estágios de amostragem.

A estimação do total populacional $Y$ de uma variável de pesquisa $y$ num dado estrato usando os dados da PNAD era feita rotineiramente com estimadores ponderados de tipo razão $\widehat Y_R = \widehat Y_{HT} \, X \, / \, \widehat X_{HT} = \sum_{i\in s} w_i^R y_i$ (tal como definidos por \@ref(eq:estpa15), com pesos dados por $w_i^R = \pi_i^{-1} X \, / \, \widehat{X}_{HT}$, ver \@ref(eq:estpa17), onde $X$ é o total da população no estrato obtido por métodos demográficos de projeção populacional utilizado como variável auxiliar, e $\widehat X_{HT}$ e $\widehat Y_{HT}$ são os estimadores tipo Horvitz-Thompson de $X$ e $Y$ respectivamente. 

Para estimar para conjuntos de estratos basta somar as estimativas para cada estrato incluído no conjunto. Para estimar médias e proporções, os pesos são também incorporados da forma apropriada. No caso, a estimação de médias é feita usando estimadores ponderados da forma $\overline y^R = \sum_{i\in s} w_i^R y_i / {\sum_{i \in s} w_i^R}$ e a estimação de proporções é caso particular da estimação de médias quando a variável de pesquisa $y$ é do tipo indicador (isto é, só toma valores $1$ e $0$).

Estimadores ponderados (como por exemplo os usados na PNAD) são preferidos pelos praticantes de amostragem por sua simplicidade e por serem não viciados (ao menos aproximadamente) com respeito à distribuição de aleatorização induzida pela seleção da amostra, independentemente dos valores assumidos pelas variáveis de pesquisa na população. Já para a modelagem de relações entre variáveis de pesquisa, o uso dos pesos induzidos pelo planejamento amostral, embora já frequente, ainda não é aceito sem controvérsia.

Um exemplo de modelagem desse tipo com dados da PNAD em que os pesos e o desenho amostral não foram considerados na análise é encontrado em @Leote1996. Essa autora empregou modelos de regressão logística para traçar um perfil socioeconômico da mão-de-obra empregada no mercado de trabalho informal urbano no Rio de Janeiro, usando dados do suplemento sobre trabalho da PNAD de 1990. Todos os ajustes efetuados ignoraram os pesos e o plano amostral da pesquisa. O problema foi revisitado por @Pessoa1997, quando então esses aspectos foram devidamente incorporados na análise. Um resumo desse trabalho é discutido no Capítulo \@ref(modreg).

Vamos supor que haja interesse em explicar uma determinada variável de pesquisa $y$ usando algumas outras variáveis de pesquisa num vetor de preditores $\mathbf z$. Seria natural indagar se, como no caso do total e da média, os pesos amostrais poderiam desempenhar algum papel na estimação dos parâmetros do modelo (linear) de regressão considerado. Uma possibilidade de incluir os pesos seria estimar os coeficientes da regressão por:

$$
\boldsymbol{\widehat{\beta}}_w = \left( \sum_{i \in s} w_i \mathbf z_i^{\prime} \mathbf z_i \right)^{-1} \sum_{i \in s} w_i \mathbf z_i^{\prime} y_i = \left( \mathbf Z_s^{\prime} \mathbf W_s \mathbf Z_s \right)^{-1} \mathbf Z_s^{\prime} \mathbf W_s \mathbf Y_s \quad (\#eq:eqC5N1)
$$

em lugar do estimador de mínimos quadrados ordinários (MQO) dado por 

$$
\boldsymbol{\widehat{\beta}} = \left( \sum_{i \in s} \mathbf z_i^{\prime} \mathbf z_i \right)^{-1} \sum_{i \in s} \mathbf z_i^{\prime } y_i = \left(\mathbf Z_s^{\prime} \mathbf Z_s \right)^{-1} \mathbf Z_s^{\prime} \mathbf Y_s \quad (\#eq:eqC5N2)
$$
onde $w_i = \pi_i^{-1}$, $y_i$ é o valor da variável resposta e $\mathbf z_i$ é o vetor de preditores para a observação $i$, $\mathbf Z_s$ e $\mathbf Y_s$ são respectivamente a matriz e vetor com os valores amostrais dos preditores $\mathbf z_i$ e resposta $y_i$, e $\mathbf W_s = diag \left \{ w_i ; i \in s \right \}$ é a matriz diagonal com os pesos amostrais.

Não é possível justificar o estimador $\boldsymbol{\widehat{\beta}}$ em \@ref(eq:eqC5N1) com base em um critério de otimalidade, tal como ocorre com os estimadores usuais de Máxima Verossimilhança ou de Mínimos Quadrados Ordinários (MQO), caso a abordagem clássica de supor observações IID fosse adotada para os dados da amostra usada para ajustar o modelo.

De um ponto de vista formal (matemático), o estimador $\boldsymbol{\widehat{\beta}}_w$ em \@ref(eq:eqC5N1) é equivalente ao estimador de Mínimos Quadrados Ponderados (MQP) com pesos $w_i$. Entretanto, esses estimadores diferem de maneira acentuada. Os estimadores de MQP são usualmente considerados quando o modelo de regressão é heteroscedástico, isto é, quando os erros têm variâncias desiguais. Neste caso, os pesos adequados seriam dados pelos inversos das variâncias dos erros correspondentes a cada uma das observações e, portanto, em geral diferentes dos pesos iguais aos inversos das correspondentes probabilidades de inclusão na amostra. Além desta diferença de interpretação do papel dos pesos no estimador, outro aspecto em que os dois estimadores diferem de forma acentuada é na estimação da correspondente precisão, com o estimador MQP acoplado a um estimador de variância baseado no modelo e o estimador $\boldsymbol{\widehat{\beta}}_w$ acoplado a estimadores de variância que incorporam o planejamento amostral e os pesos amostrais ásicos, como se verá mais adiante.

O estimador $\boldsymbol{\widehat{\beta}}_w$ foi proposto formalmente por @fuller1975, que o concebeu como uma função de estimadores de totais populacionais. A mesma ideia subsidiou vários outros autores que estudaram a estimação de coeficientes de regressão partindo de dados amostrais complexos, tais como @NH1980, @PfeffNat1981. Uma revisão abrangente da literatura existente sobre estimação de parâmetros em modelos de regressão linear com dados amostrais complexos pode ser encontrada no capítulo 6 de @Silva1996.

Apesar dessas dificuldades, será que é possível justificar o uso de pesos amostrais na inferência baseada em modelos? Se for o caso, sob que condições? Seria possível desenvolver diretrizes para o uso de pesos em *inferência analítica* partindo de dados amostrais complexos? A resposta para essas perguntas é afirmativa, ao menos quando a questão da robustez da inferência é relevante. Em inferências analíticas partindo de dados amostrais complexos, os pesos podem ser usados para proteger:


1. contra *planos amostrais não-ignoráveis*, que poderiam introduzir ou causar *vícios*;

2. contra a *má especificação do modelo*. 


A *robustez dos procedimentos* que incorporam pesos é obtida pela mudança de foco da inferência para *quantidades da população finita*, que definem parâmetros-alvo alternativos aos parâmetros do modelo de superpopulação, conforme já discutido na Seção \@ref(modelsuperpop).

A questão da construção dos pesos para uso na inferência não será tratada neste texto, usando-se sempre como peso básico o inverso da probabilidade de inclusão de cada unidade na amostra. É possível utilizar pesos de outro tipo como, por exemplo, aqueles de razão empregados na estimação da PNAD, ou pesos decorrentes de estimadores de regressão ou de calibração, como os atualmente empregados na PNAD Contínua do IBGE. Para esses casos, há que fazer alguns ajustes da teoria aqui exposta para estimação de variâncias conforme discutido no capítulo 6 de @Silva1996 ou em @hidiroglou1999 e @hidiroglou2000.

Há várias formas alternativas de incorporar os pesos amostrais no processo de inferência. A principal que será adotada ao longo deste texto será o método de *Máxima Pseudo-Verossimilhança*, que descrevemos na próxima seção. Este método foi desenvolvido por @binder1983, embora só tenha recebido esta denominação mais tarde, em @SHS1989. Apesar disso, as ideias de @binder1983 foram inicialmente expandidas por artigos como @Chambless1985 e @Roberts1987.


## Método de Máxima Pseudo-Verossimilhança {#secC5N4}
<div style="text-align: justify">

Suponha que os vetores observados $\mathbf{y}_{i}$ das variáveis de pesquisa das unidades $i \in U$ são gerados por vetores aleatórios $\mathbf{Y}_{i}$. Suponha também que $\mathbf{Y}_{1}, \ldots, \mathbf{Y}_{N}$ são IID com densidade $f \left( \mathbf{y}, \boldsymbol{\theta} \right)$. Se os dados de todas as unidades da população finita $U$ fossem conhecidos, as funções de verossimilhança e de log-verossimilhança *populacionais* seriam dadas respectivamente por 

$$
l_{U} \left( \boldsymbol{\theta} \right) = \prod \limits_{i\in U} f \left( \mathbf{y}_{i}; \boldsymbol{\theta} \right) \quad (\#eq:eqC5N3)
$$
e 

$$
L_{U} \left( \boldsymbol{\theta} \right) = \sum_{i\in U} \log \left[ f \left( \mathbf{y}_{i}; \boldsymbol{\theta} \right) \right] \quad (\#eq:eqC5N4)
$$

Para maximizar a verossimilhança com respeito a $\boldsymbol{\theta}$, sob condições de regularidade usuais, as equações de estimação *populacionais* correspondentes são dadas por: 

$$
\sum_{i\in U} \mathbf{u}_{i} \left( \boldsymbol{\theta} \right) = \mathbf{0} \quad (\#eq:eqC5N5)
$$
com 

$$
\mathbf{u}_{i} \left( \boldsymbol{\theta} \right) = \partial \log \left[ f \left( \mathbf{y}_{i}; \boldsymbol{\theta} \right) \right] / \partial \boldsymbol{\theta} \quad (\#eq:eqC5N6)
$$
denotando o vetor $K \times 1$ de escores da unidade $i \in U$.

Sob as condições de regularidade indicadas em @cox1974, p. 281, a solução $\boldsymbol{\theta}_{U}$ deste sistema de equações é o *Estimador de Máxima Verossimilhança* de $\boldsymbol{\theta}$ no caso de um *censo*. Podemos considerar $\boldsymbol{\theta}_{U}$ como uma *Quantidade Descritiva Populacional Correspondente* - QDPC - a $\boldsymbol{\theta}$, no sentido definido por @Pfeff1993, sobre a qual se deseja fazer inferências com base em informações da amostra. Essa definição da QDPC $\boldsymbol{\theta}_{U}$ pode ser generalizada para contemplar outras abordagens de inferência além da abordagem clássica baseada em maximização da verossimilhança aqui considerada. Basta para isso especificar outra função de perda ou critério a otimizar e então definir a QDPC como a solução ótima segundo essa nova função de perda. Tal generalização, discutida em @Pfeff1993, não será aqui considerada para manter a simplicidade.

A QDPC $\boldsymbol{\theta}_{U}$ definida implicitamente com base em \@ref(eq:eqC5N5) não é calculável a menos que um *censo* seja realizado na população $U$. Entretanto, desempenha papel fundamental nessa abordagem inferencial, por constituir-se num *pseudo-parâmetro*, eleito como alvo da inferência num esquema que incorpora o planejamento amostral. Isto se justifica porque, sob certas condições de regularidade, $\boldsymbol{\theta}_{U} - \boldsymbol{\theta } = o_{p} \left( 1 \right)$. Como em pesquisas por amostragem o tamanho da população é geralmente grande, um estimador adequado para $\boldsymbol{\theta}_{U}$ será geralmente adequado também para $\boldsymbol{\theta}$.

Seja $\mathbf{T} = \sum_{i\in U} \mathbf{u}_i \left( \boldsymbol{\theta} \right)$ a soma dos vetores de escores na população, o qual é um vetor de totais populacionais. Para estimar este vetor de totais, podemos então usar um estimador linear ponderado da forma $\mathbf{\widehat{T}} = \sum_{i \in s} w_i \, \mathbf{u}_i ( \boldsymbol{\theta} )$, ver Capítulo \@ref(planamo), onde $w_i$ são pesos amostrais definidos adequadamente. Com essa notação, podemos agora obter um estimador para $\boldsymbol{\theta}_{U}$ resolvendo o sistema de equações obtido igualando o estimador $\mathbf{\widehat{T}}$ do total $\mathbf{T}$ a zero.

```{definition}
O estimador de Máxima Pseudo-Verossimilhança (MPV) $\boldsymbol{\widehat{\theta}}_{MPV}$ de $\boldsymbol{\theta}_U$ (e consequentemente de $\boldsymbol{\theta}$) será a solução das equações de estimação (ou de Pseudo-Verossimilhança) dadas por 

$$
\mathbf{\widehat{T}} = \sum_{i\in s} w_{i} \mathbf{u}_i ( \boldsymbol{\theta} ) = \mathbf{0} \quad (\#eq:eqC5N7)
$$
```

Através da linearização de Taylor, ver Seção \@ref(taylor), considerando os resultados de @binder1983, podemos obter a variância de aleatorização assintótica do estimador $\boldsymbol{\widehat{\theta}}_{MPV}$ e seu estimador correspondente, dados respectivamente por: 

$$
V_{p} \left( \boldsymbol{\widehat{\theta}}_{MPV} \right) \simeq \left[ J ( \boldsymbol{\theta}_{U} ) \right]^{-1} V_{p} \left[ \sum_{i\in s} w_i \, \mathbf{u}_i ( \boldsymbol{\theta}_U ) \right] \left[ J ( \boldsymbol{\theta}_U ) \right]^{-1} \quad (\#eq:eqC5N8)
$$
e 

$$
\widehat{V}_{p} \left( \boldsymbol{\widehat{\theta}}_{MPV} \right) = \left[ \widehat{J} \left( \boldsymbol{\widehat{\theta}}_{MPV} \right) \right]^{-1} \widehat{V}_{p} \left[ \sum_{i\in s} w_i \, \mathbf{u}_{i} \left( \boldsymbol{\widehat{\theta}}_{MPV} \right) \right] \left[ \widehat{J} \left( \boldsymbol{\widehat{\theta}}_{MPV} \right) \right]^{-1} \quad (\#eq:eqC5N9)
$$
onde

$$
J ( \boldsymbol{\theta}_U ) = \left. \frac{\partial \mathbf{T} ( \boldsymbol{\theta} ) } {\partial \boldsymbol{\theta}} \right| _{\boldsymbol{\theta = \theta}_{U}} = \sum_{i\in U} \left. \frac{\partial \mathbf{u}_i ( \boldsymbol{\theta} ) } {\partial  \boldsymbol{\theta} } \right| _{\boldsymbol{\theta = \theta}_U} \quad (\#eq:eqC5N10)
$$

e

$$
\widehat{J} \left( \boldsymbol{\widehat{\theta}}_{MPV} \right) = \left. \frac{\partial \mathbf{\widehat{T}} ( \boldsymbol{\theta} ) } {\partial \boldsymbol{\theta}} \right| _{\boldsymbol{\theta = \widehat{\theta}}_{MPV}} = \sum_{i\in s} w_i \, \left. \frac{\partial \mathbf{u}_i ( \boldsymbol{\theta} ) } {\partial \boldsymbol{\theta}} \right| _{\boldsymbol{\theta = \widehat{\theta}}_{MPV}} \quad (\#eq:eqC5N11)
$$

Note que $V_p \left[ \sum_{i \in s} w_i \, \mathbf{u}_i ( \boldsymbol{\theta}_U ) \right]$ é a matriz de variância (de aleatorização) do estimador do total populacional dos escores e $\widehat{V}_p \left[ \sum_{i \in s} w_i \, \mathbf{u}_i \left( \boldsymbol{\widehat{\theta}}_{MPV} \right) \right]$ é um estimador consistente para esta variância. @binder1983 mostrou também que a distribuição assintótica de $\boldsymbol{\widehat{\theta}}_{MPV}$ é Normal Multivariada, isto é, que 

$$
\left[ \widehat{V}_p \left( \boldsymbol{\widehat{\theta}}_{MPV} \right) \right]^{-1/2} \left( \boldsymbol{\widehat{\theta}}_{MPV} - \boldsymbol{\theta}_U \right) \sim  \mathbf{NM} \left( \mathbf{0}; \mathbf{I} \right) \quad (\#eq:eqC5N12)
$$
o que fornece uma base para a inferência sobre $\boldsymbol{\theta}_U$ (ou $\boldsymbol{\theta}$) usando amostras grandes, como as habitualmente empregadas nas pesquisas amostrais cujos dados se busca analisar.

Muitos modelos paramétricos podem ser ajustados resolvendo-se as equações de Pseudo-Verossimilhança \@ref(eq:eqC5N7), satisfeitas algumas condições de regularidade enunciadas no apêndice de @binder1983 e revistas em @Silva1996, p. 126. Entretanto, os estimadores de MPV não serão únicos, já que existem diversas maneiras de se definir os pesos $w_i$. 

Não há restrições quanto aos tipos de planos amostrais e estimadores de totais considerados, contanto que sejam capazes de fornecer estimativas consistentes para totais. Os pesos $w_i$ devem ser tais que os estimadores de total em \@ref(eq:eqC5N7) sejam assintoticamente normais e não-viciados, e possuam estimadores de variância consistentes, conforme requerido para a obtenção da distribuição assintótica dos estimadores MPV. Os pesos mais usados são os pesos básicos do estimador de Horvitz-Thompson para totais, dados pelo inverso das probabilidades de inclusão dos indivíduos, ou seja $w_i = \pi_i^{-1}$. Tais pesos satisfazem essas condições sempre que $\pi_i > 0$ e $\pi_{ij} > 0 \quad \forall i,j \in U$ e algumas condições adicionais de regularidade são satisfeitas, ver por exemplo a seção 1.3 de @Fuller2009.

Assim, um procedimento padrão para ajustar um modelo paramétrico regular $f ( \mathbf{y}; \boldsymbol{\theta} )$ pelo método da Máxima Pseudo-Verossimilhança seria dado pelos passos indicados a seguir.


1.  Resolver 

$$
\sum\limits_{i\in s} w_i \, \mathbf{u}_i ( \boldsymbol{\theta} ) = \mathbf{0} \quad (\#eq:eqC5N13)
$$ 
e calcular o estimador pontual $\boldsymbol{\widehat{\theta}}_{MPV}$ do parâmetro $\boldsymbol{\theta}$ no modelo $f ( \mathbf{y; \boldsymbol{\theta}} )$ ou do pseudo-parâmetro $\boldsymbol{\theta}_U$ correspondente.

2.  Calcular a matriz de variância estimada 

$$
\widehat{V}_p \left( \boldsymbol{\widehat{\theta}}_{MPV} \right) = \left[ \widehat{J} \left( \boldsymbol{\widehat{\theta}}_{MPV} \right) \right]^{-1} \widehat{V}_p \left[ \sum \limits_{i\in s} w_i \, \mathbf{u}_i \left( \boldsymbol{\widehat{\theta}}_{MPV} \right) \right] \left[ \widehat{J} \left( \boldsymbol{\widehat{\theta}}_{MPV} \right) \right]^{-1} \quad (\#eq:eqC5N14)
$$

Quando os pesos básicos tipo Horvitz-Thompson de um plano amostral probabilístico são usados, isto é, $w_i = d_i = 1 / \pi_i$, temos os componentes do estimador de variância em \@ref(eq:eqC5N14) dados por:

$$
\widehat{V}_p \left[ \sum \limits_{i \in s} d_i \, \mathbf{u}_i \left( \boldsymbol{\widehat{\theta}}_{HT} \right) \right] = \sum \limits_{i \in s} \sum \limits_{j \in s} \left( d_i d_j - d_{ij} \right) \mathbf{u}_i \left( \boldsymbol{\widehat{\theta}}_{HT} \right) \mathbf{u}_j \left( \boldsymbol{\widehat{\theta}}_{HT} \right) \quad (\#eq:eqC5N15)
$$
onde $d_{ij} = 1 / \pi_{ij}$ e 

$$
\widehat{J} \left( \boldsymbol{\widehat{\theta}}_{HT} \right) = \left. \frac{\partial \mathbf{\widehat{T}} \left( \boldsymbol{\theta} \right)} {\partial \boldsymbol{\theta}} \right| _{\boldsymbol{\theta} = \boldsymbol{\widehat{\theta}}_{HT}} = \sum \limits_{i \in s} d_i \left. \frac{\partial \mathbf{u}_i ( \boldsymbol{\theta} )} {\partial \boldsymbol{\theta}} \right| _{\boldsymbol{\theta} = \boldsymbol{\widehat{\theta}}_{HT}} \quad (\#eq:eqC5N16)
$$

3. Usar $\boldsymbol{\widehat{\theta}}_{HT}$ e $\widehat{V}_p \left( \boldsymbol{\widehat{\theta}}_{HT} \right)$ para calcular regiões ou intervalos de confiança e/ou estatísticas de teste baseadas na distribuição normal e utilizá-las para fazer inferência sobre os componentes de $\boldsymbol{\theta}$.


```{remark, label="obsC5N1" }
No Método de Máxima Pseudo-Verossimilhança, os pesos amostrais são incorporados na análise através das equações de estimação dos parâmetros \@ref(eq:eqC5N7) e através das equações de estimação da matriz de covariância dos estimadores \@ref(eq:eqC5N14)-\@ref(eq:eqC5N16).
```


```{remark, label="obsC5N2"}
O plano amostral é também incorporado no método de estimação MPV através da expressão para a variância do total dos escores sob o plano amostral \@ref(eq:eqC5N15), onde as propriedades do plano amostral estão resumidas nas probabilidades de inclusão de primeira e segunda ordem, por sua vez incorporadas através dos pesos $d_i$ e $d_{ij}$ respectivamente.
```

```{remark, label= "obsC5N3"}
Sob probabilidades de seleção iguais, os pesos $d_i}$ serão constantes e o estimador pontual $\widehat{\theta}_{HT}$ será idêntico ao estimador de Máxima Verossimilhança (MV) ordinário para uma amostra de observações IID com distribuição $f \left( \mathbf{y}; \boldsymbol{\theta} \right)$. Entretanto, o mesmo não ocorre em se tratando da variância do estimador \widehat{\theta}_{HT}}$, que difere da variância sob o modelo do estimador usual de MV. O estimador de variância aqui descrito será consistente para a variância do estimador sob planos amostrais complexos, enquanto o estimador de variância ingênuo correspondente ao método MV será geralmente enviesado. \medskip 
```

Quando pesos calibrados $w_i = d_i g_i$ são usados na estimação pontual dos parâmetros, é necessário ajustar o estimador de variância definido em \@ref(eq:eqC5N15). Supondo que um vetor de variáveis auxiliares $\mathbf{x}$ está disponível para uso no processo de calibração dos pesos, e seguindo @Deville1992, os fatores de calibração $g_i$ são calculados minimizando a função

$$
G = \sum _\limits{i \in s} g \left( d_i, w_i \right)
$$
sujeito à restrição

$$
\sum _\limits{i \in s} w_i \, \mathbf{x}_i = \sum _\limits{i \in U} \mathbf{x}_i
$$
onde $g(.)$ é uma função medindo a distância entre os pesos básicos $d_i$ e os pesos calibrados $w_i = d_i g_i$. @Deville1992 apresenta uma variedade de propostas para tais funções de distância que geram distintos tipos de pesos calibrados. Sob as condições de regularidade enunciadas, os estimadores de calibração para totais são consistentes e normalmente distribuídos para grandes amostras. Veja o capítulo 13 de @Silva2020 para uma discussão mais detalhada e acessível sobre estimadores de calibração.

Se pesos de calibração forem usados, @Silva1996 mostrou que o estimador de variância adequado para o miolo da expressão \@ref(eq:eqC5N14) é dado por:

$$
\widehat{V}_p \left[ \sum \limits_{i \in s} d_i g_i \, \mathbf{u}_i \left( \boldsymbol{\widehat{\theta}}_C \right) \right] = \sum \limits_{i \in s} \sum \limits_{j \in s} \left( d_i d_j - d_{ij} \right) g_i \, \left[ \mathbf{u}_i \left( \boldsymbol{\widehat{\theta}}_C \right) - \mathbf{x_i}^{\prime} \widehat{\mathbf{B}} \right] g_j \, \left[ \mathbf{u}_j \left( \boldsymbol{\widehat{\theta}}_C \right) - \mathbf{x_j}^{\prime} \widehat{\mathbf{B}} \right] \quad (\#eq:eqC5N17)
$$

onde $\boldsymbol{\widehat{\theta}}_C$ é a solução de \@ref(eq:eqC5N13) quando os pesos de calibração $w_i = d_i g_i$ são usados, e 

$$
\widehat{\mathbf{B}} = \left( \sum \limits_{i \in s} d_i \, \mathbf{x_i} \, \mathbf{x_i}^{\prime} \right)^{-1} \left( \sum \limits_{i \in s} d_i \, \mathbf{x_i} \, y_i \right)
$$


**Vantagens do procedimento de MPV**

O procedimento MPV proporciona estimativas *baseadas no plano amostral* para a variância assintótica dos estimadores dos parâmetros, as quais são razoavelmente simples de calcular e são consistentes sob condições de regularidade usuais quanto ao plano amostral e à especificação do modelo. Mesmo quando o estimador pontual de MPV coincide com o estimador usual de Máxima Verossimilhança, a estimativa da variância obtida pelo procedimento de MPV pode ser preferível aos estimadores usuais da variância baseados no modelo, que ignoram o plano amostral.

O procedimento MPV fornece estimativas *robustas*, no sentido de que em muitos casos a quantidade $\boldsymbol{\theta}_U$ da população finita permanece um alvo válido para inferência, mesmo quando o modelo especificado por $f \left( \mathbf{y}; \boldsymbol{\theta} \right)$ não proporciona uma descrição adequada para a distribuição das variáveis de pesquisa na população ou quando as hipóteses de independência e idêntica distribuição para as observações amostrais não se mostram adequadas.

**Desvantagens do método de MPV**

O procedimento de estimação MPV requer conhecimento de informações detalhadas sobre as unidades da amostra, tais como pertinência a estratos e conglomerados ou unidades primárias de amostragem, e suas probabilidades de inclusão ou pesos. Tais informações nem sempre estão disponíveis para usuários de dados de pesquisas amostrais, seja por razões operacionais ou devido às regras de proteção do sigilo de informações individuais.

As propriedades dos estimadores MPV para pequenas amostras não são conhecidas. Este problema pode não ser importante em análises que usam os dados de pesquisas feitas pelas agências produtoras de estatísticas oficiais, desde que em tais análises seja utilizada a amostra inteira, ou no caso de subdomínios estudados separadamente, que as amostras usadas sejam suficientemente grandes nestes domínios. Mas pode tornar-se um problema relevante quando as amostras de interesse para a análise são pequenas e a teoria assintótica não pode ser aplicada.

Outra dificuldade é que métodos usuais de diagnóstico de ajuste de modelos (tais como gráficos de resíduos) e outros procedimentos da inferência clássica (tais como testes estatísticos de Razões de Verossimilhança) não podem ser utilizados sem ajustes. Mais informações sobre este assunto estão disponíveis no capítulo \@ref(capC8).

## Robustez do Procedimento MPV {#secC5N5}
<div style="text-align: justify">

Nesta seção vamos examinar a questão da robustez dos estimadores obtidos pelo procedimento MPV. É essa robustez que justifica o emprego desses estimadores frente aos estimadores usuais de MV pois, nas situações práticas da análise de dados amostrais complexos, as hipóteses usuais de observações IID para os dados amostrais raramente são verificadas.

Vamos agora analisar com mais detalhes a terceira abordagem para a inferência analítica. Nela, postulamos um modelo como na primeira abordagem e a inferência é direcionada aos parâmetros do modelo. Porém, em vez de acharmos um estimador ótimo sob o modelo, achamos um estimador na classe dos estimadores consistentes para a QDPC, onde a consistência é referida à distribuição de aleatorização do estimador. Por que usar a QDPC? A resposta é exatamente para obter maior robustez. Para entender porque essa abordagem oferece maior robustez, vamos considerar dois casos.


-  Caso 1: o modelo para a população é adequado.

Então quando $N \rightarrow \infty$ a QDPC $\boldsymbol{\theta}_U$ converge para o parâmetro $\boldsymbol{\theta}$, isto é, $\boldsymbol{\theta}_U - \boldsymbol{\theta} \rightarrow \mathbf{0}$ em probabilidade, segundo a distribuição de probabilidades do modelo $M$. Se $\boldsymbol{\widehat{\theta}}_{MPV}$ for consistente, então quando $n \rightarrow \infty$ temos que $\boldsymbol{\widehat{\theta}}_{MPV} - \boldsymbol{\theta}_U \rightarrow \mathbf{0}$ em probabilidade, segundo a distribuição de aleatorização $p$. Juntando essas condições obtemos que

$$
\boldsymbol{\widehat{\theta}}_{MPV} \stackrel{P}{\rightarrow} \boldsymbol{\theta} 
$$

em probabilidade segundo a mistura $Mp$. Esse resultado segue porque
$$
\begin{eqnarray*}
\boldsymbol{\widehat{\theta}}_{MPV} - \boldsymbol{\theta} &=& (\boldsymbol{\widehat{\theta}}_{MPV}- \boldsymbol{\theta}_U) + \left( \boldsymbol{\theta}_U - \boldsymbol{\theta} \right) \\
&=& O_{p} (n^{-1/2}) + O_{p} (N^{-1/2}) = O_{p}(n^{-1/2}) 
\end{eqnarray*}
$$
- Caso 2: o modelo para a população não é válido.


Nesse caso, o parâmetro $\boldsymbol{\theta}$ do modelo não tem interpretação substantiva significante, porém a QDPC $\boldsymbol{\theta}_U$ é uma quantidade definida na população finita (real) com interpretação clara, independente da validade do modelo. Como $\boldsymbol{\widehat{\theta}}_{MPV}$ é consistente para a QDPC $\boldsymbol{\theta}_U$, a inferência baseada no procedimento MPV segue válida para este pseudo-parâmetro, independente da inadequação do modelo para a população.

@Sk1989b, p. 81, discute essa situação, mostrando que $\boldsymbol{\theta}_U$ pode ainda ser um alvo válido para inferência mesmo quando o modelo $f \left( \mathbf{y}; \boldsymbol{\theta} \right)$ especificado para a população é inadequado, ao menos no sentido de que $f \left( \mathbf{y}; \boldsymbol{\theta}_U \right)$ forneceria a *melhor aproximação possível* (em certo sentido) para o verdadeiro modelo $h \left( \mathbf{y}; \boldsymbol{\eta}\right)$ que gera as observações populacionais. @Sk1989b reconhece que a *melhor aproximação possível* entre um conjunto de aproximações ruins ainda poderia ser uma aproximação ruim, e portanto, que a escolha do elenco de modelos especificados pela distribuição $f \left( \mathbf{y}; \boldsymbol{\theta} \right)$ deve seguir os cuidados necessários para garantir que esta escolha forneça uma aproximação razoável da realidade.

```{remark, label="obs44"}
Consistência referente à distribuição de aleatorização.
```

Consistência na teoria clássica tem a ver com comportamento limite de um estimador quando o tamanho da amostra cresce, isto é, quando $n \rightarrow \infty$. No caso de populações finitas, temos que considerar o que ocorre quando crescem o tamanho da amostra e também o tamanho da população, isto é, quando $n \rightarrow \infty$ e $N \rightarrow \infty$. Neste caso, é preciso definir a maneira pela qual $N \uparrow$ e $n \uparrow$ preservando a estrutura do plano amostral. Para evitar um desvio indesejado que a discussão deste problema traria, vamos supor que $N \uparrow$ e $n \uparrow$ de uma forma bem definida. Os leitores interessados poderão consultar: @SSW1992, p. 166, e @Fuller2009, Seção 1.3.

## Desvantagens da Inferência de Aleatorização {#secC5N6}
<div style="text-align: justify">

Se o modelo postulado diretamente para descrever os dados amostrais for correto, o uso de estimadores ponderados pode resultar em perda substancial de eficiência quando comparado com o estimador ótimo (por exemplo, o de MV) sob o modelo. Em geral, a perda de eficiência aumenta quanto menor for o tamanho da amostra e quanto maior for a variação dos pesos. Há casos onde a ponderação é a única alternativa. Por exemplo, se os dados disponíveis já estão na forma de estimativas amostrais ponderadas, então o uso de pesos é inevitável. Um exemplo clássico é discutido a seguir.

```{example,label="Analisec"}
Análise secundária de tabelas de contingência.
```

A pesquisa *Canada Health Survey* usa um plano amostral estratificado com vários estágios de seleção. Nessa pesquisa, a estimativa de contagem na cela $k$ de uma tabela de contingência qualquer é dada por 

$$
\widehat{N}_k = \sum_{a} \left( N_a / \widehat{N}_a \right) \left[ \sum_{h} \sum_{i} \sum_{j} w_{hij} Y_{ka (hij)} \right] = \sum_{a} \left( N_a / \widehat{N}_a \right) \widehat{N}_{ka} 
$$

onde $Y_{ka (hij)} = 1$ se a $j$-ésima unidade da UPA $i$ do estrato $h$ pertence à $k$-ésima cela e ao $a$-ésimo grupo de idade-sexo, e $0$ (zero) caso contrário;

$N_{a} / \widehat{N}_a$ são fatores de ajustamento de pós-estratificação que usam contagens censitárias $N_{a}$ de idade-sexo para diminuir as variâncias dos estimadores.

Quando as contagens *expandidas* $\widehat{N}_k$ são usadas, os testes de homogeneidade e de qualidade de ajuste de modelos loglineares baseados em amostragem Multinomial e Poisson independentes não são mais válidos. A estatística clássica $X^2$ não tem mais distribuição $\chi^2$ e sim uma soma ponderada $\sum_k \delta_k X_k$ de variáveis $X_k$ IID com distribuição $\chi^2 (1)$. Esse exemplo será rediscutido com mais detalhes na Seção \@ref(raoscott).

A importância desse exemplo é ilustrar que mesmo quando o usuário pensa estar livre das complicações causadas pelo plano amostral e pesos, ele precisa estar atento à forma como foram gerados os dados que pretende modelar ou analisar, sob pena de realizar inferências incorretas. Este exemplo tem também grande importância prática, pois um grande número de pesquisas domiciliares por amostragem produz como principal resultado conjuntos de tabelas com contagens e proporções, as quais foram obtidas mediante ponderação pelas agências produtoras das informações. Este é o caso, por exemplo, da PNAD, da PNAD Contínua, da amostra do Censo Demográfico e de inúmeras outras pesquisas do IBGE e de agências estatísticas congêneres.

## Laboratório de R {#secC5N7}
<div style="text-align: justify">

Usar função *svymle* da library *survey*, @R-survey, para incluir exemplo de estimador MPV?

Possibilidade: explorar o exemplo 2.1?

